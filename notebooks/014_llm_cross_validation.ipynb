{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import prompt_utils\n",
    "import os\n",
    "import random\n",
    "\n",
    "# vicuna \n",
    "# with rules classification only (0.76)\n",
    "vicuna_with_rules_classification_only_path = \"../data/vicuna_4bit/generic_prompt_with_rules_only_classification/\"\n",
    "vicuna_with_rules_classification_only_func = prompt_utils.get_vicuna_prompt_with_rules_only_classification\n",
    "\n",
    "# OA LLAMA\n",
    "# Classification Only V03 (0.81)\n",
    "# 1 pos 1 neg (0.79)\n",
    "oa_classification_only_v03_path = \"../data/openassistant_llama_30b_4bit/generic_prompt_without_context_only_classification_v03/\"\n",
    "oa_classification_only_v03_func = prompt_utils.get_openassistant_llama_30b_4bit_without_context_only_classification_v03\n",
    "oa_1pos_1neg_path_path = \"../data/openassistant_llama_30b_4bit/generic_prompt_few_shot_prompt_only_classification_1_pos_1_neg_example/\"\n",
    "oa_1pos_1neg_path_func = prompt_utils.get_openassistant_llama_30b_4bit_few_shot_prompt_only_classification_1_pos_1_neg_example\n",
    "\n",
    "# Text Davinci\n",
    "# Elaboration First V02 (0.94)\n",
    "davinci_elaboration_first_v02_path = \"../data/openai_text_davinci_003/generic_prompt_without_context_elaboration_first_v02/\"\n",
    "davinci_elaboration_first_v02_func = prompt_utils.get_openai_prompt_without_context_elaboration_first_v02\n",
    "\n",
    "# Define a list of filenames to load\n",
    "labeled_data_filename = \"../data/labeled_data/generic_test_0.json\"\n",
    "\n",
    "dfs = []\n",
    "with open(labeled_data_filename) as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data[\"train\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"test\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"valid\"])\n",
    "dfs.append(df)\n",
    "df_all = pd.concat(dfs)\n",
    "all_labels = [\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \n",
    "              \"Government/Public\", \"Health\", \"Immigration/Integration\", \n",
    "              \"Justice/Crime\", \"Labor/Employment\", \n",
    "              \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
    "\n",
    "balanced_dfs = prompt_utils.generate_binary_balanced_dfs(all_labels, df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change output_folder, models_to_test_names, and model_funcs to match the models you want to test\n",
    "output_folder = vicuna_with_rules_classification_only_path\n",
    "models_to_test_names = [\"generic_prompt_with_rules_classification_only\"]\n",
    "model_funcs = [vicuna_with_rules_classification_only_func]\n",
    "rules = True\n",
    "\n",
    "for model_name, model_func in zip(models_to_test_names, model_funcs):\n",
    "\n",
    "    for cross_validation_idx in range(1,5):\n",
    "\n",
    "        print(\"Starting with model: \" + model_name)\n",
    "        print(\"----------------------------------\")\n",
    "        df_all_tmp = df_all.copy()\n",
    "\n",
    "        df_all_tmp['normalized_tweet'] = None\n",
    "        normalized_tweets_db = {}\n",
    "        output_folder_tmp = f\"{output_folder}{model_name}/\"\n",
    "\n",
    "        if not os.path.exists(output_folder_tmp):\n",
    "            os.makedirs(output_folder_tmp)\n",
    "\n",
    "        for idx, label in enumerate(all_labels):\n",
    "\n",
    "            sample_df = balanced_dfs[idx]\n",
    "\n",
    "            print(\"Starting requesting for label: \" + label + \"\\n\")\n",
    "\n",
    "            new_column_name = f'{label}_pred'\n",
    "            df_all_tmp[new_column_name] = None\n",
    "            request_params = prompt_utils.get_base_request_params()\n",
    "\n",
    "            i = 0\n",
    "            for index, row in tqdm(sample_df.iterrows(), total=sample_df.shape[0]):\n",
    "\n",
    "                tweet_text = prompt_utils.normalize_tweet_simplified(row['text'])\n",
    "                df_all_tmp.loc[lambda df: df['id'] == row[\"id\"], 'normalized_tweet'] = tweet_text\n",
    "\n",
    "                pos_example_tweet = prompt_utils.get_positive_example(sample_df, label, row[\"text\"])\n",
    "                neg_example_tweet = prompt_utils.get_negative_example(sample_df, label, row[\"text\"])\n",
    "\n",
    "                pos_example_tweet = prompt_utils.normalize_tweet_simplified(pos_example_tweet)\n",
    "                neg_example_tweet = prompt_utils.normalize_tweet_simplified(neg_example_tweet)\n",
    "\n",
    "                # select the function based on model_func and generate the prompt\n",
    "                if '1_pos_example' in model_func.__name__:\n",
    "                    prompt, followup = model_func(tweet_text, label, pos_example_tweet)\n",
    "                elif '1_neg_example' in model_func.__name__:\n",
    "                    prompt, followup = model_func(tweet_text, label, neg_example_tweet)\n",
    "                elif '1_random_example' in model_func.__name__:\n",
    "                    example_tweet = random.choice([pos_example_tweet, neg_example_tweet])\n",
    "                    example_tweet_label = 1 if example_tweet == pos_example_tweet else 0\n",
    "                    prompt, followup = model_func(tweet_text, label, example_tweet, example_tweet_label)\n",
    "                elif '_random_example' in model_func.__name__:\n",
    "                    n = int(model_func.__name__.split(\"_\")[0])\n",
    "                    examples = prompt_utils.get_random_examples(sample_df, label, row[\"text\"], n) #set number of examples here\n",
    "                    prompt, followup = model_func(tweet_text, label, examples)\n",
    "                elif '1_pos_1_neg_example' in model_func.__name__:\n",
    "                    prompt, followup = model_func(tweet_text, label, pos_example_tweet, neg_example_tweet)\n",
    "                else:\n",
    "                    if rules:\n",
    "                        prompt, followup, request_params = model_func(tweet_text, label, prompt_utils.RULES[idx], request_params)\n",
    "                    else:\n",
    "                        prompt, followup, request_params = model_func(tweet_text, label, request_params)\n",
    "\n",
    "                request_params[\"stopping_strings\"] = [\"### Human:\", \"Human:\", \"###\"]\n",
    "                response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "\n",
    "                # TODO: if followup is needed for a second call, manually adjust how the response is parsed to followup with a second prompt\n",
    "                if followup != \"\":\n",
    "                    response = prompt_utils.get_response(request_params, followup + response, \"\")\n",
    "\n",
    "                # Save the response in the 'api_results' column\n",
    "                df_all_tmp.loc[lambda df: df['id'] == row[\"id\"], new_column_name] = response\n",
    "                \n",
    "                i+=1\n",
    "                # Save the DataFrame to a CSV file every 100 steps\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    output_path = os.path.join(output_folder_tmp, 'generic_test_0.csv')\n",
    "                    df_all_tmp.to_csv(output_path, index=False)\n",
    "                    print(f\"Saved progress at index {index}\")\n",
    "                    print(\"Sample Tweet: \", tweet_text)\n",
    "                    print(\"Sample Annotation: \", response)\n",
    "\n",
    "            # Save the final DataFrame to a CSV file\n",
    "            output_path = os.path.join(output_folder_tmp, 'generic_test_0.csv')\n",
    "            df_all_tmp.to_csv(output_path, index=False)\n",
    "\n",
    "        # Save the request_params as a JSON file in the output folder\n",
    "        with open(os.path.join(output_folder_tmp, 'request_params.json'), 'w') as f:\n",
    "            json.dump(request_params, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
