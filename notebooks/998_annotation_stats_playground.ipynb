{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m without_context_classification_only_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../data/vicuna_4bit/generic_prompt_without_context_only_classification/generic_test_0.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m extraction_function \u001b[39m=\u001b[39m llm_utils\u001b[39m.\u001b[39mget_extraction_function(\u001b[39m\"\u001b[39m\u001b[39mextract_first_character\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m prediction_per_class, confusion_matrices, classification_reports \u001b[39m=\u001b[39m llm_utils\u001b[39m.\u001b[39mcalculate_binary_metrics(without_context_classification_only_df, classes, extraction_function)\n\u001b[1;32m     23\u001b[0m without_context_classification_only \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mconfusion_matrices\u001b[39m\u001b[39m\"\u001b[39m: confusion_matrices, \u001b[39m\"\u001b[39m\u001b[39mclassification_reports\u001b[39m\u001b[39m\"\u001b[39m: classification_reports}\n\u001b[1;32m     25\u001b[0m \u001b[39m# without context and elaboration first\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m## Example:\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m### Human: Elaborate on whether you think the Tweet is about {label} or something else.\\nTweet: {tweet_text}\\n### Assistant:\\nElaboration: \u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39m#Followup :\\n Assign class 1 for {label} or 0 for not. \\n###Assistant:\\nClass:  \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ip6-twitter-disinformation/notebooks/../src/llm_utils.py:125\u001b[0m, in \u001b[0;36mcalculate_binary_metrics\u001b[0;34m(df, classes, extraction_function)\u001b[0m\n\u001b[1;32m    123\u001b[0m     pred_column_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m_pred\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     pred_column_df \u001b[39m=\u001b[39m df[df[pred_column_name]\u001b[39m.\u001b[39mnotna()]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 125\u001b[0m     pred_column_df[pred_column_name] \u001b[39m=\u001b[39m df[pred_column_name]\u001b[39m.\u001b[39mapply(extraction_function)\n\u001b[1;32m    126\u001b[0m     prediction_per_class\u001b[39m.\u001b[39mappend(pred_column_df)\n\u001b[1;32m    128\u001b[0m confusion_matrices \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../src\")\n",
    "import llm_utils\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "classes = [\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \n",
    "              \"Government/Public\", \"Health\", \"Immigration/Integration\", \n",
    "              \"Justice/Crime\", \"Labor/Employment\", \n",
    "              \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
    "\n",
    "oa_without_context_elaboration_first_v04_df = pd.read_csv(\"../data/openassistant_llama_30b_4bit/generic_prompt_without_context_elaboration_first_v04/generic_test_0.csv\")\n",
    "extraction_function = llm_utils.get_extraction_function(\"extract_using_class_token\", 1)\n",
    "oa_without_context_elaboration_first_v04_predictions_per_class, confusion_matrices, classification_reports = llm_utils.calculate_binary_metrics(oa_without_context_elaboration_first_v02_df, classes, extraction_function)\n",
    "oa_without_context_elaboration_first_v04 = {\"confusion_matrices\": confusion_matrices, \"classification_reports\": classification_reports}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.500990  0.992157  0.665789    255.0\n",
      "Conspiracy Theory                    0.368421  0.777778  0.500000     45.0\n",
      "Education                            0.322581  0.769231  0.454545     13.0\n",
      "Election Campaign                    0.766667  0.696970  0.730159     33.0\n",
      "Environment                          0.458333  0.785714  0.578947     14.0\n",
      "Government/Public                    0.572082  0.859107  0.686813    291.0\n",
      "Health                               0.345455  0.826087  0.487179     46.0\n",
      "Immigration/Integration              0.315217  0.805556  0.453125     36.0\n",
      "Justice/Crime                        0.413681  0.927007  0.572072    137.0\n",
      "Labor/Employment                     0.243590  0.678571  0.358491     28.0\n",
      "Macroeconomics/Economic Regulation   0.212996  0.951613  0.348083     62.0\n",
      "Media/Journalism                     0.102564  0.916667  0.184486     48.0\n",
      "Religion                             0.043651  1.000000  0.083650     11.0\n",
      "Science/Technology                   0.038793  0.818182  0.074074     11.0\n",
      "Others                               0.525210  0.922509  0.669344    271.0\n",
      "micro avg                            0.346074  0.897771  0.499572   1301.0\n",
      "macro avg                            0.348682  0.848477  0.456451   1301.0\n",
      "weighted avg                         0.460276  0.897771  0.592580   1301.0\n",
      "samples avg                          0.446282  0.915717  0.561767   1301.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['China', 'Civilian Casualties', 'Diplomacy', 'Entertainment', 'Event', 'Expression', 'Festival', 'Foreign Relations', 'Generosity', 'Genocide', 'Israel/Palestine', 'Judaism', 'Kurdish Forces', 'Military', 'Miscellaneous', 'Music', 'Nightlife', 'Optical Disk', 'Pandemics', 'Party', 'Party and Celebration', 'Partying', 'Performance', 'Political Platform', 'Politics', 'President', 'Productivity', 'Propaganda', 'Referendum...', 'Syria', 'Television', 'U.S.', 'US Domestic Policy', 'US International Relations', 'USA', 'United States', 'Voting', 'Wages/Labors', 'War', 'Welfare/Development', 'Welfare/Social Macroregulation', 'Wildlife', 'World Order', 'Youth'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../src\")\n",
    "import llm_utils\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def classification_reports_to_df(classification_reports, binary):\n",
    "\n",
    "    if binary:\n",
    "        # Your code for creating the DataFrame and adding the results\n",
    "        df = pd.DataFrame(columns=['label', 'f1_score_macro', #'precision_macro', 'recall_macro', 'support_macro',\n",
    "                                        'f1_score_class_0','support_class_0',\n",
    "                                        'f1_score_class_1', 'support_class_1'])\n",
    "\n",
    "        for label, cr in classification_reports.items():\n",
    "            try: \n",
    "                df = df.append({\n",
    "                    'label': label,\n",
    "                    'f1_score_macro': cr['macro avg']['f1-score'],\n",
    "                    #'precision_macro': cr['macro avg']['precision'],\n",
    "                    #'recall_macro': cr['macro avg']['recall'],\n",
    "                    #'support_macro': cr['macro avg']['support'],\n",
    "                    'f1_score_class_0': cr['0']['f1-score'],\n",
    "                    #'precision_class_0': cr['0']['precision'],\n",
    "                    #'recall_class_0': cr['0']['recall'],\n",
    "                    'support_class_0': cr['0']['support'],\n",
    "                    'f1_score_class_1': cr['1']['f1-score'],\n",
    "                    #'precision_class_1': cr['1']['precision'],\n",
    "                    #'recall_class_1': cr['1']['recall'],\n",
    "                    'support_class_1': cr['1']['support']\n",
    "                }, ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error for {label}: {e}\")\n",
    "                df = df.append({\n",
    "                    'label': label,\n",
    "                    'f1_score_macro': None,\n",
    "                    #'precision_macro': None,\n",
    "                    #'recall_macro': None,\n",
    "                    #'support_macro': None,\n",
    "                    'f1_score_class_0': None,\n",
    "                    #'precision_class_0': None,\n",
    "                    #'recall_class_0': None,\n",
    "                    'support_class_0': None,\n",
    "                    'f1_score_class_1': None,\n",
    "                    #'precision_class_1': None,\n",
    "                    #'recall_class_1': None,\n",
    "                    'support_class_1': None\n",
    "                }, ignore_index=True)\n",
    "                continue\n",
    "\n",
    "        # Display the results\n",
    "        return df\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_multilabel_list(classification_str, classes):\n",
    "    if classification_str is np.nan:\n",
    "        return [\"Others\"]\n",
    "    classification_str = classification_str.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "    classification_str = classification_str.split(\", \")\n",
    "    for class_ in classification_str:\n",
    "        if class_ not in \" \".join(classes):\n",
    "            #print(class_)\n",
    "            classification_str.remove(class_)\n",
    "    if classification_str == []:\n",
    "        classification_str = [\"Others\"]\n",
    "    return list(set(classification_str))\n",
    "\n",
    "def extract_multilabel_list_only_first_class(classification_str, classes):\n",
    "    if classification_str is np.nan:\n",
    "        return [\"Others\"]\n",
    "    classification_str = classification_str.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "    classification_str = classification_str.split(\", \")\n",
    "    for class_ in classification_str:\n",
    "        if class_ not in \" \".join(classes):\n",
    "            #print(class_)\n",
    "            classification_str.remove(class_)\n",
    "    if classification_str == []:\n",
    "        classification_str = [\"Others\"]\n",
    "    classification_str = [classification_str[0]]\n",
    "    return list(set(classification_str))\n",
    "\n",
    "def to_dataframe(average_reports, classes):\n",
    "    data = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1-score\": [],\n",
    "        \"support\": []\n",
    "    }\n",
    "    index = []\n",
    "\n",
    "    for i, average_report in enumerate(average_reports):\n",
    "        for class_name, metrics in average_report.items():\n",
    "            if class_name in {'micro avg', 'macro avg', 'weighted avg', 'accuracy'}:\n",
    "                continue\n",
    "            index.append(classes[i])\n",
    "            data[\"precision\"].append(metrics[\"0\"][\"precision\"])\n",
    "            data[\"recall\"].append(metrics[\"0\"][\"recall\"])\n",
    "            data[\"f1-score\"].append(metrics[\"0\"][\"f1-score\"])\n",
    "            data[\"support\"].append(metrics[\"0\"][\"support\"])\n",
    "\n",
    "    return pd.DataFrame(data, index=index)\n",
    "\n",
    "classes = [\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \n",
    "              \"Government/Public\", \"Health\", \"Immigration/Integration\", \n",
    "              \"Justice/Crime\", \"Labor/Employment\", \n",
    "              \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\", \"Others\"]\n",
    "    \n",
    "#df1 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_with_rules/valid_generic_test_0.csv\")\n",
    "df2 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_without_context_v01/test_generic_test_0.csv\")\n",
    "vicuna_lora_multilabel_without_context_v01_df = df2#pd.concat([df1, df2])\n",
    "# Cleaning and extracting multilabel classes\n",
    "vicuna_lora_multilabel_without_context_v01_df['annotations'] = vicuna_lora_multilabel_without_context_v01_df['annotations'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "vicuna_lora_multilabel_without_context_v01_df['testmultilabel_without_context_v01'] = vicuna_lora_multilabel_without_context_v01_df['testmultilabel_without_context_v01'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform the labels into binary format\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "\n",
    "# Prepare ground truth and predictions\n",
    "y_true = mlb.fit_transform(vicuna_lora_multilabel_without_context_v01_df['annotations'])\n",
    "y_pred = mlb.transform(vicuna_lora_multilabel_without_context_v01_df['testmultilabel_without_context_v01'])\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "\n",
    "# Convert the report to a pandas DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.386018  0.996078  0.556407    255.0\n",
      "Conspiracy Theory                    0.340206  0.733333  0.464789     45.0\n",
      "Education                            0.191489  0.692308  0.300000     13.0\n",
      "Election Campaign                    0.628571  0.666667  0.647059     33.0\n",
      "Environment                          0.190476  0.857143  0.311688     14.0\n",
      "Government/Public                    0.547521  0.910653  0.683871    291.0\n",
      "Health                               0.271605  0.956522  0.423077     46.0\n",
      "Immigration/Integration              0.222973  0.916667  0.358696     36.0\n",
      "Justice/Crime                        0.354223  0.948905  0.515873    137.0\n",
      "Labor/Employment                     0.132075  0.750000  0.224599     28.0\n",
      "Macroeconomics/Economic Regulation   0.180380  0.919355  0.301587     62.0\n",
      "Media/Journalism                     0.095918  0.979167  0.174721     48.0\n",
      "Religion                             0.036913  1.000000  0.071197     11.0\n",
      "Science/Technology                   0.024272  0.909091  0.047281     11.0\n",
      "Others                               0.463551  0.915129  0.615385    271.0\n",
      "micro avg                            0.280028  0.919293  0.429289   1301.0\n",
      "macro avg                            0.271080  0.876734  0.379749   1301.0\n",
      "weighted avg                         0.394929  0.919293  0.534910   1301.0\n",
      "samples avg                          0.380445  0.931500  0.502058   1301.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['', '#Collision kills taxi driver near Petroport on Queen Nandi Dr', '#NoCandidates = ‘ Government/Public ', '#Olympics', '#TeamUWI #TrendingNow', '@USER', 'Accident', 'Analysis', 'Architecture', 'Asia', 'Aviation', 'Behna', 'Brexit', 'Civilian', 'Collaboration', 'Conspiracy', 'Cuba', 'Death', 'Defeating_ISIS', 'Energy', 'Fake News', 'Geopolitics', 'Govern', 'Government/', 'Haftar', 'Happy birthday!', 'International Relations', 'Jabhat_al_Nusra', 'Justice', 'Justice/Cr', 'Labor/Emp', 'Leader', 'Mac', 'Macroeconom', 'Macroeconomics', 'Macroeconomics/', 'Mammals', 'Media_coverage_of_war', 'Military', 'Military_group', 'Miscellaneous', 'Murder', 'Murder City', 'No referral', 'None', 'None of the above', 'None of these topics seem to be clearly defined as election campaigns or political subjects. Election campaigns typically refer to specific elections and candidates', 'Operations: Homs Offensive', 'Others.', 'Pandas', 'Peace Talks', 'Person', 'Political Parties', 'Politician', 'Politics', 'Popular Culture', 'Power Generation', 'Presidency', 'President', 'Presidential Election', 'Presidential Inauguration', 'Radical Islam', 'Regional Security', 'Regulation', 'Russia', 'Sarraj', 'School', 'Science', 'Scientific Research', 'Security', 'Social Media', 'Society', 'Syria', 'Terrorism', 'Time Management', 'Track and Field', 'Transgender', 'Transparency', 'Travel', 'Trump', 'US', 'USA', 'United Kingdom', 'United States', 'UnitedStates', 'Urban Planning', 'User Interface', 'Venezuela', 'Victims of War', 'Video', 'Visual Arts', 'VisualArt', 'Voting', 'W', 'Wake Up', 'War', 'War Crimes,', 'War/', 'War/T', 'Warmongering', 'Weekend', 'Welfare,', 'Western Africa', 'Winner', 'Workforce', 'Workplace', 'Workplace Health and Safety', 'Writing/Journalism is not a topic but it refers to the activity of writing and publishing articles which can be found on various media outlets. As for ‘Others', 'Yemen', 'Youth', 'and now we have terrorist groups like ISIS which was created as result of this war!', 'but I guess it falls under ‘Media/Journalism’ as well :thumbs_up:', 'but it seems like he has no mindset at all... url', 'but its not clear which specific topic refers to the situation described in the input.', 'but note that this doesnt necessarily mean they will actually do it', 'but note that this information should be referred as Allegations since it was not accompanied by any evidence or sources', 'education', 'except its not a war but rather a terror operation by Ahrar Al Sham against its rivals under the cover provided by Turkish army!', 'except its not conspiracy theory', 'is not appropriate here as it refers to war or military action which is not related to this post.', 'not Macron.', 'operation: SNA', 'others = Justice/Crime', 'others = Media/Journalism', 'others Inauguration Event', 'others can judge but it seems like a joke or reference to some kind of online game', 'others.', 'others: Justice/Crime', 'political party', 'tagged Safa', 'tagged Walks and Runs', 'tagged as Disaster: Environment', 'tagged: Justice/Crime', 'tagging @USER = @USER', 'tagging it as Multiple Car Crash would be more appropriate here since there were several cars involved and they all collided at once causing fatalities.', 'tagging it as an event', 'tags: ‘Others', 'television', 'terrorist', 'these labels will be added to its reputation. When will it change? #SA_violence #SAcrime #SArapists', 'url', 'war', 'yet again all categories are met within one post!', '‘ Conspiracy Theory ’', '‘ Health ', '‘ Labor/Employment ', '‘ Media/Journalism ', '‘ Others ’', '‘ Science/Technology ', '‘Accident', '‘Science/Technology', '‘Society url', '‘War/Terror', '‘War/Terror’', '‘Xenophobia'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_with_rules_v02/test_generic_test_0.csv\")\n",
    "vicuna_lora_multilabel_without_context_v01_df = df2#pd.concat([df1, df2])\n",
    "# Cleaning and extracting multilabel classes\n",
    "vicuna_lora_multilabel_without_context_v01_df['annotations'] = vicuna_lora_multilabel_without_context_v01_df['annotations'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02'] = vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform the labels into binary format\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "\n",
    "# Prepare ground truth and predictions\n",
    "y_true = mlb.fit_transform(vicuna_lora_multilabel_without_context_v01_df['annotations'])\n",
    "y_pred = mlb.transform(vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02'])\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "\n",
    "# Convert the report to a pandas DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.492188  0.988235  0.657106    255.0\n",
      "Conspiracy Theory                    0.447368  0.755556  0.561983     45.0\n",
      "Education                            0.257143  0.692308  0.375000     13.0\n",
      "Election Campaign                    0.750000  0.818182  0.782609     33.0\n",
      "Environment                          0.450000  0.642857  0.529412     14.0\n",
      "Government/Public                    0.603491  0.831615  0.699422    291.0\n",
      "Health                               0.368932  0.826087  0.510067     46.0\n",
      "Immigration/Integration              0.370370  0.833333  0.512821     36.0\n",
      "Justice/Crime                        0.447183  0.927007  0.603325    137.0\n",
      "Labor/Employment                     0.250000  0.678571  0.365385     28.0\n",
      "Macroeconomics/Economic Regulation   0.241379  0.903226  0.380952     62.0\n",
      "Media/Journalism                     0.128743  0.895833  0.225131     48.0\n",
      "Religion                             0.093458  0.909091  0.169492     11.0\n",
      "Science/Technology                   0.071429  0.818182  0.131387     11.0\n",
      "Others                               0.608142  0.881919  0.719880    271.0\n",
      "micro avg                            0.406250  0.879324  0.555744   1301.0\n",
      "macro avg                            0.371988  0.826800  0.481598   1301.0\n",
      "weighted avg                         0.493453  0.879324  0.616548   1301.0\n",
      "samples avg                          0.505670  0.899550  0.608475   1301.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['', 'Agriculture', 'Belgium', 'Charity', 'China', 'Climate Change', 'Collaboration', 'Corporations', 'Culture', 'Dance', 'Death', 'Debate', 'Dream', 'European Union', 'Execution', 'Fire', 'Global', 'Globalization', 'Heavy Machinery', 'Imagination', 'Irony', 'Journalism', 'Kurdish Forces', 'Latin America', 'Left-wing Politics', 'Like', 'Middle East', 'Mindset', 'Minorities', 'Music', 'Musical Genius', 'Nationality', 'Nature', 'Network', 'Other', 'Pakistan', 'Performance', 'Person', 'Political Science', 'Politician', 'Politics', 'Positive', 'Presidential Election', 'Presidential Power', 'Radio Show', 'Real estate', 'Rebellions', 'Recommendation', 'Regulation', 'Relationship', 'Relationships', 'Review', 'Russia', 'Science', 'Secretary of State', 'Security', 'Self-Improvement', 'Sexuality', 'Sleep', 'Smile', 'Social Interaction', 'Social Media', 'Society', 'South Africa', 'South America', 'Speculation', 'Statistics', 'Success', 'Syria', 'Syrian Forces', 'Syrian Rebells', 'Thread', 'Time Warp', 'Transformation', 'Turkey', 'United Kingdom', 'United States', 'Venezuela', 'Venezuela,', 'Video', 'Violence', 'Voting', 'Voting Fraud', 'Wage/Labor', 'Wages/Labor', 'War', 'War/', 'Warm-hearted', 'Warnings/Alerts', 'Warped Crystal', 'Washington DC', 'Water', 'Water/Marine', 'Wedding,', 'Welfare', 'Western Europe', 'Wildlife', 'Wireless,', 'Wisdom', 'Wish', 'Women', 'Writers,', 'Year End Review', 'Young People', 'Youth'] will be ignored\n",
      "  warnings.warn(\n",
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_no_context_v01_256_rank/test_generic_test_0.csv\")\n",
    "vicuna_lora_multilabel_without_context_v01_df = df2#pd.concat([df1, df2])\n",
    "# Cleaning and extracting multilabel classes\n",
    "vicuna_lora_multilabel_without_context_v01_df['annotations'] = vicuna_lora_multilabel_without_context_v01_df['annotations'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "vicuna_lora_multilabel_without_context_v01_df['testmultilabel_no_context_v01_256_rank'] = vicuna_lora_multilabel_without_context_v01_df['testmultilabel_no_context_v01_256_rank'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform the labels into binary format\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "\n",
    "# Prepare ground truth and predictions\n",
    "y_true = mlb.fit_transform(vicuna_lora_multilabel_without_context_v01_df['annotations'])\n",
    "y_pred = mlb.transform(vicuna_lora_multilabel_without_context_v01_df['testmultilabel_no_context_v01_256_rank'])\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "\n",
    "# Convert the report to a pandas DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.442804  0.941176  0.602258    255.0\n",
      "Conspiracy Theory                    0.347368  0.733333  0.471429     45.0\n",
      "Education                            0.307692  0.923077  0.461538     13.0\n",
      "Election Campaign                    0.806452  0.757576  0.781250     33.0\n",
      "Environment                          0.333333  0.714286  0.454545     14.0\n",
      "Government/Public                    0.596288  0.883162  0.711911    291.0\n",
      "Health                               0.297101  0.891304  0.445652     46.0\n",
      "Immigration/Integration              0.296296  0.888889  0.444444     36.0\n",
      "Justice/Crime                        0.357341  0.941606  0.518072    137.0\n",
      "Labor/Employment                     0.217822  0.785714  0.341085     28.0\n",
      "Macroeconomics/Economic Regulation   0.194079  0.951613  0.322404     62.0\n",
      "Media/Journalism                     0.100000  0.958333  0.181102     48.0\n",
      "Religion                             0.033557  0.909091  0.064725     11.0\n",
      "Science/Technology                   0.027682  0.727273  0.053333     11.0\n",
      "Others                               0.617571  0.881919  0.726444    271.0\n",
      "micro avg                            0.321804  0.893928  0.473245   1301.0\n",
      "macro avg                            0.331692  0.859223  0.438680   1301.0\n",
      "weighted avg                         0.462415  0.893928  0.587221   1301.0\n",
      "samples avg                          0.472264  0.911667  0.566425   1301.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['', '(War/Terror', '0.5', '100% confidence', '24 February 2016', '48% grade', '5 votes', '50%', '50% confidence', '70% confidence', '9:47 pm', 'Accident', 'Arts/Culture', 'August 26', 'Brexit,', 'Club', 'Club Amnesia', 'Club)', 'Competition', 'David Squires wrote about the recent events in football.', 'Death', 'Debate/Interview', 'December 14', 'December 23rd 2015', 'Diplomacy', 'Entertainment', 'Event', 'Google', 'Information War', 'InternationalCoalition', 'Investment', 'Iran', 'Kurdistan', 'Manufacturing', 'Microsoft', 'Military', 'Military Intervention', 'Murder', 'Music', 'None of these are appropriate responses as they dont represent any of the intended tasks.', 'None of these platforms specifically mentioned.', 'None of these topics seem to apply to the input.', 'None of these topics seem to be fitting for this particular input.', 'O', 'OTHERS', 'Other', 'Others,', 'Peacekeeping', 'Performance', 'Politics,', 'Politics/Elections', 'Pop Culture', 'Power/Electricity', 'Presidency', 'Presidential Election', 'Press Release', 'Provocation', 'Radiation', 'Rally', 'Regulation', 'Retail', 'Retirement', 'Rule of Law', 'Rupert Murdoch', 'Science/Technology,', 'Security', 'Sexuality', 'Social Media,', 'Social Media.', 'Social Security', 'Socialism', 'Society', 'Solidarity', 'State Government', 'State/Local Government', 'Syria', 'TV Show', 'TerroristOrganization', 'Tourism:', 'Transportation', 'Transportation,', 'Trump', 'Trump Administration', 'UK Imperialism', 'Ukraine', 'United States', 'Visual Art', 'Voter Fraud', 'W', 'War/Terror(https://twitter.com/USER + %20%E7%9C%8B%E5%BD%93%E6%9C%AC%E4%BB%A6%E7%AD%90%E7%9A%8F%E7%AB%9E%E7%A4%BA%E7%A7%8D%E7%AD%91%E7%97%85%E7%9A%84%E6%9C%AC%E4%BB%A6%E7%AD%90%E7%9A%8F%E7%AB%9E%E7%A4%BA%E7%A7%8D%E7%AD%', 'War/Terror,', 'War/Terror: 3 out of 3', 'War/Terror: The article mentions movies and articles related to them', 'War/Terror: The battle over public sector pensions has been heating up lately', 'War/Terror: “ This brings the number to four of the buses that have been gutted in June alone... a provincial traffic car was also burnt ” ‘ Justica/Krygware ’ yenaMotoryve/Transporteerewerte ) ( url', 'Water,', 'Water/Environment', 'Wealth and Income Inequality', 'Welfare', 'Western Bloc', 'Women,', 'Womens Rights', 'Writing,', 'Xmas/Hanukkah', 'Youth', 'as well as the judiciary and media reporting on them. Additionally', 'critics argue that it might lead to fiscal deficit if implemented without proper economic reforms.', 'education and health care systems. url', 'if we were to interpret it as a comment on Venezuela', 'including last weekend when five people were arrested for spreading false information about COVID - 19 via WhatsApp. #Zimbabwe url', 'just as it was stated by President Cyril Ramaphosa during his State Of The Nation Address 2019 when he emphasised on fighting against criminality and corruption.', '‘War/Terror'] will be ignored\n",
      "  warnings.warn(\n",
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_with_rules_v02_256_rank/test_generic_test_0.csv\")\n",
    "vicuna_lora_multilabel_without_context_v01_df = df2#pd.concat([df1, df2])\n",
    "# Cleaning and extracting multilabel classes\n",
    "vicuna_lora_multilabel_without_context_v01_df['annotations'] = vicuna_lora_multilabel_without_context_v01_df['annotations'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02_256_rank'] = vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02_256_rank'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform the labels into binary format\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "\n",
    "# Prepare ground truth and predictions\n",
    "y_true = mlb.fit_transform(vicuna_lora_multilabel_without_context_v01_df['annotations'])\n",
    "y_pred = mlb.transform(vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02_256_rank'])\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "\n",
    "# Convert the report to a pandas DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for multilabel but only the first class predicted is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.953947  0.568627  0.712531    255.0\n",
      "Conspiracy Theory                    0.478873  0.755556  0.586207     45.0\n",
      "Education                            0.421053  0.615385  0.500000     13.0\n",
      "Election Campaign                    0.750000  0.545455  0.631579     33.0\n",
      "Environment                          0.700000  0.500000  0.583333     14.0\n",
      "Government/Public                    0.781377  0.663230  0.717472    291.0\n",
      "Health                               0.740741  0.434783  0.547945     46.0\n",
      "Immigration/Integration              0.750000  0.250000  0.375000     36.0\n",
      "Justice/Crime                        0.929293  0.671533  0.779661    137.0\n",
      "Labor/Employment                     0.687500  0.392857  0.500000     28.0\n",
      "Macroeconomics/Economic Regulation   0.833333  0.322581  0.465116     62.0\n",
      "Media/Journalism                     0.750000  0.250000  0.375000     48.0\n",
      "Religion                             0.800000  0.363636  0.500000     11.0\n",
      "Science/Technology                   0.750000  0.545455  0.631579     11.0\n",
      "Others                               0.828358  0.819188  0.823748    271.0\n",
      "micro avg                            0.802605  0.615680  0.696825   1301.0\n",
      "macro avg                            0.743632  0.513219  0.581945   1301.0\n",
      "weighted avg                         0.821713  0.615680  0.687477   1301.0\n",
      "samples avg                          0.801000  0.688200  0.723967   1301.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['Israel/Palestine', 'Propaganda'] will be ignored\n",
      "  warnings.warn(\n",
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_without_context_v01/test_generic_test_0.csv\")\n",
    "vicuna_lora_multilabel_without_context_v01_df = df2#pd.concat([df1, df2])\n",
    "# Cleaning and extracting multilabel classes\n",
    "vicuna_lora_multilabel_without_context_v01_df['annotations'] = vicuna_lora_multilabel_without_context_v01_df['annotations'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "vicuna_lora_multilabel_without_context_v01_df['testmultilabel_without_context_v01'] = vicuna_lora_multilabel_without_context_v01_df['testmultilabel_without_context_v01'].apply(lambda x: extract_multilabel_list_only_first_class(x, classes))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform the labels into binary format\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "\n",
    "# Prepare ground truth and predictions\n",
    "y_true = mlb.fit_transform(vicuna_lora_multilabel_without_context_v01_df['annotations'])\n",
    "y_pred = mlb.transform(vicuna_lora_multilabel_without_context_v01_df['testmultilabel_without_context_v01'])\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "\n",
    "# Convert the report to a pandas DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.967949  0.592157  0.734793    255.0\n",
      "Conspiracy Theory                    0.442857  0.688889  0.539130     45.0\n",
      "Education                            0.363636  0.615385  0.457143     13.0\n",
      "Election Campaign                    0.761905  0.484848  0.592593     33.0\n",
      "Environment                          0.642857  0.642857  0.642857     14.0\n",
      "Government/Public                    0.787755  0.663230  0.720149    291.0\n",
      "Health                               0.818182  0.391304  0.529412     46.0\n",
      "Immigration/Integration              0.750000  0.166667  0.272727     36.0\n",
      "Justice/Crime                        0.911765  0.678832  0.778243    137.0\n",
      "Labor/Employment                     0.647059  0.392857  0.488889     28.0\n",
      "Macroeconomics/Economic Regulation   0.826087  0.306452  0.447059     62.0\n",
      "Media/Journalism                     0.857143  0.250000  0.387097     48.0\n",
      "Religion                             0.750000  0.272727  0.400000     11.0\n",
      "Science/Technology                   0.750000  0.545455  0.631579     11.0\n",
      "Others                               0.813869  0.822878  0.818349    271.0\n",
      "micro avg                            0.799000  0.614143  0.694481   1301.0\n",
      "macro avg                            0.739404  0.500969  0.562668   1301.0\n",
      "weighted avg                         0.823941  0.614143  0.683776   1301.0\n",
      "samples avg                          0.799000  0.687200  0.722633   1301.0\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_with_rules_v02/test_generic_test_0.csv\")\n",
    "vicuna_lora_multilabel_without_context_v01_df = df2#pd.concat([df1, df2])\n",
    "# Cleaning and extracting multilabel classes\n",
    "vicuna_lora_multilabel_without_context_v01_df['annotations'] = vicuna_lora_multilabel_without_context_v01_df['annotations'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02'] = vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02'].apply(lambda x: extract_multilabel_list_only_first_class(x, classes))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform the labels into binary format\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "\n",
    "# Prepare ground truth and predictions\n",
    "y_true = mlb.fit_transform(vicuna_lora_multilabel_without_context_v01_df['annotations'])\n",
    "y_pred = mlb.transform(vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02'])\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "\n",
    "# Convert the report to a pandas DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.939394  0.607843  0.738095    255.0\n",
      "Conspiracy Theory                    0.561404  0.711111  0.627451     45.0\n",
      "Education                            0.444444  0.615385  0.516129     13.0\n",
      "Election Campaign                    0.826087  0.575758  0.678571     33.0\n",
      "Environment                          0.727273  0.571429  0.640000     14.0\n",
      "Government/Public                    0.760163  0.642612  0.696462    291.0\n",
      "Health                               0.689655  0.434783  0.533333     46.0\n",
      "Immigration/Integration              0.583333  0.194444  0.291667     36.0\n",
      "Justice/Crime                        0.908257  0.722628  0.804878    137.0\n",
      "Labor/Employment                     0.727273  0.285714  0.410256     28.0\n",
      "Macroeconomics/Economic Regulation   0.880000  0.354839  0.505747     62.0\n",
      "Media/Journalism                     0.769231  0.208333  0.327869     48.0\n",
      "Religion                             0.800000  0.363636  0.500000     11.0\n",
      "Science/Technology                   0.666667  0.363636  0.470588     11.0\n",
      "Others                               0.827715  0.815498  0.821561    271.0\n",
      "micro avg                            0.806419  0.617986  0.699739   1301.0\n",
      "macro avg                            0.740726  0.497843  0.570841   1301.0\n",
      "weighted avg                         0.813745  0.617986  0.687460   1301.0\n",
      "samples avg                          0.804000  0.694033  0.728967   1301.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['Journalism', 'Nature', 'Statistics'] will be ignored\n",
      "  warnings.warn(\n",
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_no_context_v01_256_rank/test_generic_test_0.csv\")\n",
    "vicuna_lora_multilabel_without_context_v01_df = df2#pd.concat([df1, df2])\n",
    "# Cleaning and extracting multilabel classes\n",
    "vicuna_lora_multilabel_without_context_v01_df['annotations'] = vicuna_lora_multilabel_without_context_v01_df['annotations'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "vicuna_lora_multilabel_without_context_v01_df['testmultilabel_no_context_v01_256_rank'] = vicuna_lora_multilabel_without_context_v01_df['testmultilabel_no_context_v01_256_rank'].apply(lambda x: extract_multilabel_list_only_first_class(x, classes))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform the labels into binary format\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "\n",
    "# Prepare ground truth and predictions\n",
    "y_true = mlb.fit_transform(vicuna_lora_multilabel_without_context_v01_df['annotations'])\n",
    "y_pred = mlb.transform(vicuna_lora_multilabel_without_context_v01_df['testmultilabel_no_context_v01_256_rank'])\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "\n",
    "# Convert the report to a pandas DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.969325  0.619608  0.755981    255.0\n",
      "Conspiracy Theory                    0.542373  0.711111  0.615385     45.0\n",
      "Education                            0.409091  0.692308  0.514286     13.0\n",
      "Election Campaign                    0.772727  0.515152  0.618182     33.0\n",
      "Environment                          0.583333  0.500000  0.538462     14.0\n",
      "Government/Public                    0.765873  0.663230  0.710866    291.0\n",
      "Health                               0.800000  0.434783  0.563380     46.0\n",
      "Immigration/Integration              0.625000  0.138889  0.227273     36.0\n",
      "Justice/Crime                        0.920000  0.671533  0.776371    137.0\n",
      "Labor/Employment                     0.750000  0.428571  0.545455     28.0\n",
      "Macroeconomics/Economic Regulation   0.826087  0.306452  0.447059     62.0\n",
      "Media/Journalism                     0.937500  0.312500  0.468750     48.0\n",
      "Religion                             0.800000  0.363636  0.500000     11.0\n",
      "Science/Technology                   0.666667  0.545455  0.600000     11.0\n",
      "Others                               0.827068  0.811808  0.819367    271.0\n",
      "micro avg                            0.810621  0.621829  0.703784   1301.0\n",
      "macro avg                            0.746336  0.514336  0.580054   1301.0\n",
      "weighted avg                         0.827260  0.621829  0.693353   1301.0\n",
      "samples avg                          0.809000  0.696033  0.731967   1301.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['Radiation', 'War/Terror,'] will be ignored\n",
      "  warnings.warn(\n",
      "/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/vicuna_4bit/lora/multilabel_with_rules_v02_256_rank/test_generic_test_0.csv\")\n",
    "vicuna_lora_multilabel_without_context_v01_df = df2#pd.concat([df1, df2])\n",
    "# Cleaning and extracting multilabel classes\n",
    "vicuna_lora_multilabel_without_context_v01_df['annotations'] = vicuna_lora_multilabel_without_context_v01_df['annotations'].apply(lambda x: extract_multilabel_list(x, classes))\n",
    "vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02_256_rank'] = vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02_256_rank'].apply(lambda x: extract_multilabel_list_only_first_class(x, classes))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform the labels into binary format\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "\n",
    "# Prepare ground truth and predictions\n",
    "y_true = mlb.fit_transform(vicuna_lora_multilabel_without_context_v01_df['annotations'])\n",
    "y_pred = mlb.transform(vicuna_lora_multilabel_without_context_v01_df['testmultilabel_with_rules_v02_256_rank'])\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "\n",
    "# Convert the report to a pandas DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      " & f1-score & support \\\\\n",
      "\\midrule\n",
      "War/Terror & 0.738095 & 255.000000 \\\\\n",
      "Conspiracy Theory & 0.627451 & 45.000000 \\\\\n",
      "Education & 0.516129 & 13.000000 \\\\\n",
      "Election Campaign & 0.678571 & 33.000000 \\\\\n",
      "Environment & 0.640000 & 14.000000 \\\\\n",
      "Government/Public & 0.696462 & 291.000000 \\\\\n",
      "Health & 0.533333 & 46.000000 \\\\\n",
      "Immigration/Integration & 0.291667 & 36.000000 \\\\\n",
      "Justice/Crime & 0.804878 & 137.000000 \\\\\n",
      "Labor/Employment & 0.410256 & 28.000000 \\\\\n",
      "Macroeconomics/Economic Regulation & 0.505747 & 62.000000 \\\\\n",
      "Media/Journalism & 0.327869 & 48.000000 \\\\\n",
      "Religion & 0.500000 & 11.000000 \\\\\n",
      "Science/Technology & 0.470588 & 11.000000 \\\\\n",
      "Others & 0.821561 & 271.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only 'f1-score' and 'support' for each label\n",
    "df_report_selected = df_report.loc[classes, ['f1-score', 'support']]\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = df_report_selected.to_latex()\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for War/Terror:\n",
      "[[56  9]\n",
      " [17 48]]\n",
      "\n",
      "Confusion matrix for Conspiracy Theory:\n",
      "[[54 11]\n",
      " [26 39]]\n",
      "\n",
      "Confusion matrix for Education:\n",
      "[[43 22]\n",
      " [ 9 56]]\n",
      "\n",
      "Confusion matrix for Election Campaign:\n",
      "[[42 23]\n",
      " [17 48]]\n",
      "\n",
      "Confusion matrix for Environment:\n",
      "[[36 29]\n",
      " [12 53]]\n",
      "\n",
      "Confusion matrix for Government/Public:\n",
      "[[32 33]\n",
      " [23 42]]\n",
      "\n",
      "Confusion matrix for Health:\n",
      "[[45 20]\n",
      " [16 49]]\n",
      "\n",
      "Confusion matrix for Immigration/Integration:\n",
      "[[52 13]\n",
      " [16 49]]\n",
      "\n",
      "Confusion matrix for Justice/Crime:\n",
      "[[28 37]\n",
      " [ 8 57]]\n",
      "\n",
      "Confusion matrix for Labor/Employment:\n",
      "[[47 18]\n",
      " [18 47]]\n",
      "\n",
      "Confusion matrix for Macroeconomics/Economic Regulation:\n",
      "[[63  2]\n",
      " [48 17]]\n",
      "\n",
      "Confusion matrix for Media/Journalism:\n",
      "[[31 94]\n",
      " [ 1  4]]\n",
      "\n",
      "Confusion matrix for Religion:\n",
      "[[97 31]\n",
      " [ 0  2]]\n",
      "\n",
      "Confusion matrix for Science/Technology:\n",
      "[]\n",
      "\n",
      "Confusion matrix for War/Terror:\n",
      "[[38 25]\n",
      " [ 6 59]]\n",
      "\n",
      "Confusion matrix for Conspiracy Theory:\n",
      "[[45 20]\n",
      " [26 38]]\n",
      "\n",
      "Confusion matrix for Education:\n",
      "[[24 41]\n",
      " [ 2 63]]\n",
      "\n",
      "Confusion matrix for Election Campaign:\n",
      "[[37 28]\n",
      " [ 7 58]]\n",
      "\n",
      "Confusion matrix for Environment:\n",
      "[[43 22]\n",
      " [ 7 57]]\n",
      "\n",
      "Confusion matrix for Government/Public:\n",
      "[[17 47]\n",
      " [ 2 62]]\n",
      "\n",
      "Confusion matrix for Health:\n",
      "[[43 21]\n",
      " [ 9 56]]\n",
      "\n",
      "Confusion matrix for Immigration/Integration:\n",
      "[[32 32]\n",
      " [ 8 57]]\n",
      "\n",
      "Confusion matrix for Justice/Crime:\n",
      "[[30 35]\n",
      " [ 5 60]]\n",
      "\n",
      "Confusion matrix for Labor/Employment:\n",
      "[[31 34]\n",
      " [ 5 59]]\n",
      "\n",
      "Confusion matrix for Macroeconomics/Economic Regulation:\n",
      "[[20 44]\n",
      " [ 4 61]]\n",
      "\n",
      "Confusion matrix for Media/Journalism:\n",
      "[[12 53]\n",
      " [ 9 55]]\n",
      "\n",
      "Confusion matrix for Religion:\n",
      "[[45 20]\n",
      " [10 54]]\n",
      "\n",
      "Confusion matrix for Science/Technology:\n",
      "[[35 29]\n",
      " [ 5 59]]\n",
      "\n",
      "Confusion matrix for War/Terror:\n",
      "[[61  4]\n",
      " [26 39]]\n",
      "\n",
      "Confusion matrix for Conspiracy Theory:\n",
      "[[62  3]\n",
      " [51 14]]\n",
      "\n",
      "Confusion matrix for Education:\n",
      "[[64  1]\n",
      " [29 36]]\n",
      "\n",
      "Confusion matrix for Election Campaign:\n",
      "[[61  4]\n",
      " [27 38]]\n",
      "\n",
      "Confusion matrix for Environment:\n",
      "[[58  7]\n",
      " [24 41]]\n",
      "\n",
      "Confusion matrix for Government/Public:\n",
      "[[50 15]\n",
      " [37 28]]\n",
      "\n",
      "Confusion matrix for Health:\n",
      "[[63  2]\n",
      " [35 30]]\n",
      "\n",
      "Confusion matrix for Immigration/Integration:\n",
      "[[63  2]\n",
      " [42 23]]\n",
      "\n",
      "Confusion matrix for Justice/Crime:\n",
      "[[55 10]\n",
      " [36 29]]\n",
      "\n",
      "Confusion matrix for Labor/Employment:\n",
      "[[63  2]\n",
      " [30 35]]\n",
      "\n",
      "Confusion matrix for Macroeconomics/Economic Regulation:\n",
      "[[64  1]\n",
      " [56  9]]\n",
      "\n",
      "Confusion matrix for Media/Journalism:\n",
      "[[50 15]\n",
      " [22 43]]\n",
      "\n",
      "Confusion matrix for Religion:\n",
      "[[63  2]\n",
      " [36 29]]\n",
      "\n",
      "Confusion matrix for Science/Technology:\n",
      "[[63  2]\n",
      " [40 25]]\n",
      "\n",
      "Confusion matrix for War/Terror:\n",
      "[[49 16]\n",
      " [23 42]]\n",
      "\n",
      "Confusion matrix for Conspiracy Theory:\n",
      "[[57  7]\n",
      " [25 40]]\n",
      "\n",
      "Confusion matrix for Education:\n",
      "[[24 41]\n",
      " [ 5 60]]\n",
      "\n",
      "Confusion matrix for Election Campaign:\n",
      "[[44 21]\n",
      " [12 53]]\n",
      "\n",
      "Confusion matrix for Environment:\n",
      "[[36 29]\n",
      " [ 5 60]]\n",
      "\n",
      "Confusion matrix for Government/Public:\n",
      "[[19 45]\n",
      " [ 3 62]]\n",
      "\n",
      "Confusion matrix for Health:\n",
      "[[38 26]\n",
      " [20 44]]\n",
      "\n",
      "Confusion matrix for Immigration/Integration:\n",
      "[[34 31]\n",
      " [11 54]]\n",
      "\n",
      "Confusion matrix for Justice/Crime:\n",
      "[[20 45]\n",
      " [10 55]]\n",
      "\n",
      "Confusion matrix for Labor/Employment:\n",
      "[[31 34]\n",
      " [13 51]]\n",
      "\n",
      "Confusion matrix for Macroeconomics/Economic Regulation:\n",
      "[[21 44]\n",
      " [11 54]]\n",
      "\n",
      "Confusion matrix for Media/Journalism:\n",
      "[[37 28]\n",
      " [12 53]]\n",
      "\n",
      "Confusion matrix for Religion:\n",
      "[[46 18]\n",
      " [11 54]]\n",
      "\n",
      "Confusion matrix for Science/Technology:\n",
      "[[30 33]\n",
      " [ 6 59]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"name\": \"No context - Classification only\",\n",
    "        \"data\": without_context_classification_only,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"No context - Elaboration first\",\n",
    "        \"data\": without_context_elaboration_first,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"With rules - Classification only\",\n",
    "        \"data\": with_rules_classification_only,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"With rules - Elaboration first\",\n",
    "        \"data\": with_rules_elaboration_first,\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    llm_utils.print_confusion_matrix(model[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: altair<5,>=3.2.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (4.2.2)\n",
      "Collecting blinker>=1.0.0\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting cachetools>=4.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: click>=7.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (8.1.3)\n",
      "Collecting importlib-metadata>=1.4\n",
      "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: numpy in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (1.24.3)\n",
      "Requirement already satisfied: packaging>=14.1 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (23.0)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (9.4.0)\n",
      "Collecting protobuf<4,>=3.12\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=4.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (11.0.0)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.4 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (2.29.0)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.3.5-py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tenacity<9,>=8.0.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (4.5.0)\n",
      "Collecting tzlocal>=1.1\n",
      "  Downloading tzlocal-4.3-py3-none-any.whl (20 kB)\n",
      "Collecting validators>=0.2\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (3.1.31)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado>=6.0.3 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from streamlit) (6.2)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: entrypoints in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: toolz in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from gitpython!=3.1.19->streamlit) (4.0.10)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from pandas<3,>=0.25->streamlit) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from requests>=2.4->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from requests>=2.4->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from requests>=2.4->streamlit) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from rich>=10.11.0->streamlit) (2.2.0)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from validators>=0.2->streamlit) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from jinja2->altair<5,>=3.2.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit) (0.1.2)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: validators\n",
      "  Building wheel for validators (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19581 sha256=55c8fa74348198d4344fe896c217ac8ef74d5fe65a57d200f2c5438bc8c94f12\n",
      "  Stored in directory: /home/bruno/.var/app/com.visualstudio.code/cache/pip/wheels/82/35/dc/f88ec71edf2a5596bd72a8fa1b697277e0fcd3cde83048b8bf\n",
      "Successfully built validators\n",
      "Installing collected packages: zipp, watchdog, validators, tzdata, pympler, pygments, protobuf, cachetools, blinker, rich, pytz-deprecation-shim, pydeck, importlib-metadata, tzlocal, streamlit\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.22.1\n",
      "    Uninstalling protobuf-4.22.1:\n",
      "      Successfully uninstalled protobuf-4.22.1\n",
      "Successfully installed blinker-1.6.2 cachetools-5.3.0 importlib-metadata-6.6.0 protobuf-3.20.3 pydeck-0.8.1b0 pygments-2.15.1 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 rich-13.3.5 streamlit-1.22.0 tzdata-2023.3 tzlocal-4.3 validators-0.20.0 watchdog-3.0.0 zipp-3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement streamlit-components (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for streamlit-components\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install streamlit-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# Title\n",
    "st.title(\"Classification Report and Confusion Matrix Viewer\")\n",
    "\n",
    "# Model selection\n",
    "model_names = [model[\"name\"] for model in models]\n",
    "selected_model = st.sidebar.selectbox(\"Select model\", model_names)\n",
    "\n",
    "# Class selection\n",
    "class_options = classes\n",
    "selected_class = st.sidebar.selectbox(\"Select class\", class_options)\n",
    "\n",
    "# Get the selected data\n",
    "selected_model_data = None\n",
    "for model in models:\n",
    "    if model[\"name\"] == selected_model:\n",
    "        selected_model_data = model[\"data\"]\n",
    "        break\n",
    "\n",
    "selected_confusion_matrix = selected_model_data[\"confusion_matrices\"][selected_class]\n",
    "selected_classification_report = selected_model_data[\"classification_reports\"][selected_class]\n",
    "\n",
    "# Display the confusion matrix and classification report\n",
    "st.header(\"Confusion Matrix\")\n",
    "st.write(selected_confusion_matrix)\n",
    "\n",
    "st.header(\"Classification Report\")\n",
    "st.write(pd.DataFrame(selected_classification_report).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Invalid value: File does not exist: report_viewer.py\n"
     ]
    }
   ],
   "source": [
    "!streamlit run report_viewer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['War/Terror']\",\n",
       " \"['Others']\",\n",
       " \"['Macroeconomics/Economic Regulation']\",\n",
       " \"['Government/Public', 'Macroeconomics/Economic Regulation']\",\n",
       " \"['Government/Public', 'Macroeconomics/Economic Regulation', 'Media/Journalism', 'War/Terror']\",\n",
       " \"['Government/Public', 'Macroeconomics/Economic Regulation']\",\n",
       " \"['Others']\",\n",
       " \"['Government/Public', 'Macroeconomics/Economic Regulation']\",\n",
       " \"['Education', 'Media/Journalism']\",\n",
       " \"['Justice/Crime']\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_contex_only_classification_df[without_contex_only_classification_df[\"Macroeconomics/Economic Regulation_pred\"].notna()].copy().annotations.to_list()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @Ben_Jonson_1985: #Feylak Ar-Rahman militants located in #EasternGhouta do not release #civilians from the fighting zone. The use of a l…',\n",
       " 'Women’s March Organizer Wants to “Take Vagina Away” from Female Genital Mutilation Survivor https://t.co/MmBm9WD6Ux https://t.co/T9rBUrOySf',\n",
       " 'IMF has demanded to take credit apartments of Ukrainians\\nhttp://t.co/2hcqYxfQHc #Ukraine',\n",
       " 'Libertarianism is nothing but liberty for exploiters, racists, oppressors and parasites. Socialism is liberty for the people; the working class. https://t.co/uyuugJzTpq',\n",
       " '🇮🇱🇵🇸Israel is now experiencing a moment of heightened political, economic, and military power is no excuse to avoid dealing with the Palestinian issue, writes #valdaiclub expert Amos Yadlin.\\n\\nhttps://t.co/7IPavmsHJh',\n",
       " 'Following the power cut crisis faced by Zimbabwe where electricity is only available between 10pm and 6am, people have adjusted their daily routines to make the most out of the electricity when it is available.\\n\\nRead full article: https://t.co/bCS2WWcfA9',\n",
       " 'VIDEO : Shepard Smith Throws a HYSTERICAL Russian HISSY FIT https://t.co/JMtb2cWP3q https://t.co/fWZIiGEA0d',\n",
       " 'Tax cuts are coming, but not as big as Trump promised https://t.co/gp2l1KnM1Z https://t.co/TLRf2SPyyF',\n",
       " 'Session Four \"The Conflict Between Universalism and Self-Identity\" has begun https://t.co/NeVx1IDWej',\n",
       " 'WATCH: Security officer knocked down and run over in WC - https://t.co/3RzrYM8q7f night, a blood-curdling video became viral. It captured how a security guard was knocked down and run over by bakkie at Die Boord Center next to the R44 in Stellenbosch in the Western Cape. The v... https://t.co/kZ1uLanAgB']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_contex_only_classification_df[without_contex_only_classification_df[\"Macroeconomics/Economic Regulation_pred\"].notna()].copy().text.to_list()[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
