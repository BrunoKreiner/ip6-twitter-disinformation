{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Define a list of filenames to load\n",
    "filenames = [\"../data/labeled_data/generic_test_0.json\"]\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_valid = pd.DataFrame()\n",
    "\n",
    "# Load all JSON data and concatenate into one DataFrame\n",
    "for filename in filenames:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    df_train = pd.DataFrame(data[\"train\"])\n",
    "    df_test = pd.DataFrame(data[\"test\"])\n",
    "    df_valid = pd.DataFrame(data[\"valid\"])\n",
    "\n",
    "def normalizeToken(token):\n",
    "    lowercased_token = token.lower()\n",
    "    if token.startswith(\"@\"):\n",
    "        return \"@USER\"\n",
    "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "        return \"[url]\"\n",
    "    elif len(token) == 1:\n",
    "        return demojize(token)\n",
    "    else:\n",
    "        if token == \"’\":\n",
    "            return \"'\"\n",
    "        elif token == \"…\":\n",
    "            return \"...\"\n",
    "        else:\n",
    "            return token\n",
    "    \n",
    "def normalizeTweet(tweet):\n",
    "    tokens = TweetTokenizer().tokenize(tweet.replace(\"’\", \"'\"))\n",
    "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
    "\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"n 't\", \"n't\")\n",
    "            .replace(\"ca n't\", \"can't\")\n",
    "            .replace(\"ai n't\", \"ain't\")\n",
    "    )\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"p . m .\", \"pm\")\n",
    "            .replace(\"p . m\", \"pm\")\n",
    "            .replace(\"a . m .\", \"am\")\n",
    "            .replace(\"a . m\", \"am\")\n",
    "    )\n",
    "    return \" \".join(normTweet.split())\n",
    "\n",
    "def api(prompt):\n",
    "    import requests\n",
    "\n",
    "# For local streaming, the websockets are hosted without ssl - http://\n",
    "HOST = 'http://127.0.0.1:5000'\n",
    "URI = f'{HOST}/api/v1/generate'\n",
    "\n",
    "# For reverse-proxied streaming, the remote will likely host with ssl - https://\n",
    "# URI = 'https://your-uri-here.trycloudflare.com/api/v1/generate'\n",
    "\n",
    "def get_response(request_params, prompt, context):\n",
    "    request_params['prompt'] = prompt\n",
    "    request_params['context'] = context\n",
    "\n",
    "    response = requests.post(URI, json=request_params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()['results'][0]['text']\n",
    "        #print(prompt + result)\n",
    "        return result\n",
    "    else:\n",
    "    \tprint(response)\n",
    "\n",
    "def get_base_request_params(max_new_tokens = 200, stopping_strings = []):\n",
    "    return {\n",
    "        'prompt': None,\n",
    "        'context': None,\n",
    "        'max_new_tokens': 200,\n",
    "        'do_sample': True,\n",
    "        'temperature': 0.7,\n",
    "        'top_p': 0.1,\n",
    "        'typical_p': 1,\n",
    "        'repetition_penalty': 1.2,\n",
    "        'encoder_repetition_penalty': 1.0,\n",
    "        'top_k': 40,\n",
    "        'min_length': 0,\n",
    "        'no_repeat_ngram_size': 0,\n",
    "        'num_beams': 1,\n",
    "        'penalty_alpha': 0,\n",
    "        'length_penalty': 1,\n",
    "        'early_stopping': False,\n",
    "        'seed': -1,\n",
    "        #'add_bos_token': True,\n",
    "        #'truncation_length': 2048,\n",
    "        #'ban_eos_token': False,\n",
    "        #'skip_special_tokens': True,\n",
    "        'stopping_strings': stopping_strings\n",
    "    }\n",
    "\n",
    "def get_vicuna_multi_label_v01(tweet_text):\n",
    "    instruction = \"Assign multilabel labels to the following tweet. Choose out of the following list of labels where \\\"Others\\\" is only assigned if no other label fits: [\\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\", \\\"Others\\\"]\"\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{tweet_text}\\n\\n### Response:\\n\"\n",
    "    return prompt, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>962251540617670661</td>\n",
       "      <td>GRU_202012</td>\n",
       "      <td>RT @Kasman62: After his injury for fifth time ...</td>\n",
       "      <td>[War/Terror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>898277432922263552</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>RT BGEEZ: dncchuckschumernancypelosimsnbccnn h...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>966214616601841664</td>\n",
       "      <td>GRU_202012</td>\n",
       "      <td>RT @LinaArabii: Russian presence in the Black ...</td>\n",
       "      <td>[Media/Journalism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1303856635668987905</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @brianmixologist: Am disappointed in the an...</td>\n",
       "      <td>[Election Campaign]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462250037972840449</td>\n",
       "      <td>IRA_202012</td>\n",
       "      <td>RT @CMCL1979: Why do those those ghastly nativ...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>847754640972070912</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>Stocks: 5 things to know before the bell https...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1038043813267296256</td>\n",
       "      <td>GRU_202012</td>\n",
       "      <td>September 4, 2018 #Syrian air defense units re...</td>\n",
       "      <td>[War/Terror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1030464264748728320</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @xJ57jjSHWvX9mAMmhv7fVaVzxe13bBfCZuGZaBNucL...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1020843977669586945</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @HowweEnt: Dj Shiru To Thrill His Fans http...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>883376409502199808</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>BREAKING VIDEO : 70 Injured in Chaotic G20 Rio...</td>\n",
       "      <td>[Government/Public, Justice/Crime]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id       campaign_name  \\\n",
       "0     962251540617670661          GRU_202012   \n",
       "1     898277432922263552  VENEZUELA_201901_2   \n",
       "2     966214616601841664          GRU_202012   \n",
       "3    1303856635668987905         UGANDA_0621   \n",
       "4     462250037972840449          IRA_202012   \n",
       "..                   ...                 ...   \n",
       "795   847754640972070912  VENEZUELA_201901_2   \n",
       "796  1038043813267296256          GRU_202012   \n",
       "797  1030464264748728320         UGANDA_0621   \n",
       "798  1020843977669586945         UGANDA_0621   \n",
       "799   883376409502199808  VENEZUELA_201901_2   \n",
       "\n",
       "                                                  text  \\\n",
       "0    RT @Kasman62: After his injury for fifth time ...   \n",
       "1    RT BGEEZ: dncchuckschumernancypelosimsnbccnn h...   \n",
       "2    RT @LinaArabii: Russian presence in the Black ...   \n",
       "3    RT @brianmixologist: Am disappointed in the an...   \n",
       "4    RT @CMCL1979: Why do those those ghastly nativ...   \n",
       "..                                                 ...   \n",
       "795  Stocks: 5 things to know before the bell https...   \n",
       "796  September 4, 2018 #Syrian air defense units re...   \n",
       "797  RT @xJ57jjSHWvX9mAMmhv7fVaVzxe13bBfCZuGZaBNucL...   \n",
       "798  RT @HowweEnt: Dj Shiru To Thrill His Fans http...   \n",
       "799  BREAKING VIDEO : 70 Injured in Chaotic G20 Rio...   \n",
       "\n",
       "                            annotations  \n",
       "0                          [War/Terror]  \n",
       "1                              [Others]  \n",
       "2                    [Media/Journalism]  \n",
       "3                   [Election Campaign]  \n",
       "4                              [Others]  \n",
       "..                                  ...  \n",
       "795                            [Others]  \n",
       "796                        [War/Terror]  \n",
       "797                            [Others]  \n",
       "798                            [Others]  \n",
       "799  [Government/Public, Justice/Crime]  \n",
       "\n",
       "[800 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model: generic_prompt_few_shot_prompt_only_classification_3_random_example\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [03:03,  6.59s/it]"
     ]
    }
   ],
   "source": [
    "models_to_test_names = [\"generic_prompt_few_shot_prompt_only_classification_3_random_example\"]\n",
    "model_funcs = [get_vicuna_multi_label_v01]\n",
    "dataframes = [df_valid, df_test]\n",
    "dataframes_names = [\"valid\", \"test\"]\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "\n",
    "    for model_name, model_func in zip(models_to_test_names, model_funcs):\n",
    "        print(\"Starting with model: \" + model_name)\n",
    "        print(\"----------------------------------\")\n",
    "        df_tmp = df.copy()\n",
    "        df_tmp[\"prompt\"] = \"\"\n",
    "        df_tmp[\"context\"] = \"\"\n",
    "        new_column_name = dataframes_names[i] + model_name\n",
    "        output_folder = f\"../data/vicuna_4bit/lora/{model_name}/\"\n",
    "\n",
    "        for idx, row in tqdm(df_tmp.iterrows(), total=df_tmp.shape[0]):\n",
    "\n",
    "            tweet_text = normalizeTweet(row[\"text\"])\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], 'normalized_tweet'] = tweet_text\n",
    "\n",
    "            prompt, context = model_func(tweet_text)\n",
    "            df_tmp.at[idx, \"prompt\"] = prompt\n",
    "            df_tmp.at[idx, \"context\"] = context\n",
    "\n",
    "            request_params = get_base_request_params()\n",
    "            request_params[\"stopping_strings\"] = [\"\\n\", \"### Human:\", \"Human:\", \"###\"]\n",
    "            response = get_response(request_params, prompt, \"\")\n",
    "\n",
    "            # Save the response in the 'api_results' column\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], new_column_name] = response\n",
    "            if (i + 1) % 100 == 0:\n",
    "                output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "                df_tmp.to_csv(output_path, index=False)\n",
    "                print(f\"Saved progress at index {idx}\")\n",
    "                print(\"Sample Tweet: \", tweet_text)\n",
    "                print(\"Sample Annotation: \", response)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "        df_tmp.to_csv(output_path, index=False)        \n",
    "            # Save the request_params as a JSON file in the output folder\n",
    "        with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "            json.dump(request_params, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
