{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Define a list of filenames to load\n",
    "filenames = [\"../data/labeled_data/generic_test_0.json\"]\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_valid = pd.DataFrame()\n",
    "\n",
    "# Load all JSON data and concatenate into one DataFrame\n",
    "for filename in filenames:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    df_train = pd.DataFrame(data[\"train\"])\n",
    "    df_test = pd.DataFrame(data[\"test\"])\n",
    "    df_valid = pd.DataFrame(data[\"valid\"])\n",
    "\n",
    "def normalizeToken(token):\n",
    "    lowercased_token = token.lower()\n",
    "    if token.startswith(\"@\"):\n",
    "        return \"@USER\"\n",
    "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "        return \"[url]\"\n",
    "    elif len(token) == 1:\n",
    "        return demojize(token)\n",
    "    else:\n",
    "        if token == \"’\":\n",
    "            return \"'\"\n",
    "        elif token == \"…\":\n",
    "            return \"...\"\n",
    "        else:\n",
    "            return token\n",
    "    \n",
    "def normalizeTweet(tweet):\n",
    "    tokens = TweetTokenizer().tokenize(tweet.replace(\"’\", \"'\"))\n",
    "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
    "\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"n 't\", \"n't\")\n",
    "            .replace(\"ca n't\", \"can't\")\n",
    "            .replace(\"ai n't\", \"ain't\")\n",
    "    )\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"p . m .\", \"pm\")\n",
    "            .replace(\"p . m\", \"pm\")\n",
    "            .replace(\"a . m .\", \"am\")\n",
    "            .replace(\"a . m\", \"am\")\n",
    "    )\n",
    "    return \" \".join(normTweet.split())\n",
    "\n",
    "def api(prompt):\n",
    "    import requests\n",
    "\n",
    "# For local streaming, the websockets are hosted without ssl - http://\n",
    "HOST = 'http://127.0.0.1:5000'\n",
    "URI = f'{HOST}/api/v1/generate'\n",
    "\n",
    "# For reverse-proxied streaming, the remote will likely host with ssl - https://\n",
    "# URI = 'https://your-uri-here.trycloudflare.com/api/v1/generate'\n",
    "\n",
    "def get_response(request_params, prompt, context):\n",
    "    request_params['prompt'] = prompt\n",
    "    request_params['context'] = context\n",
    "\n",
    "    response = requests.post(URI, json=request_params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()['results'][0]['text']\n",
    "        #print(prompt + result)\n",
    "        return result\n",
    "    else:\n",
    "    \tprint(response)\n",
    "\n",
    "def get_base_request_params(max_new_tokens = 200, stopping_strings = []):\n",
    "    return {\n",
    "        'prompt': None,\n",
    "        'context': None,\n",
    "        'max_new_tokens': 200,\n",
    "        'do_sample': True,\n",
    "        'temperature': 0.7,\n",
    "        'top_p': 0.1,\n",
    "        'typical_p': 1,\n",
    "        'repetition_penalty': 1.2,\n",
    "        'encoder_repetition_penalty': 1.0,\n",
    "        'top_k': 40,\n",
    "        'min_length': 0,\n",
    "        'no_repeat_ngram_size': 0,\n",
    "        'num_beams': 1,\n",
    "        'penalty_alpha': 0,\n",
    "        'length_penalty': 1,\n",
    "        'early_stopping': False,\n",
    "        'seed': -1,\n",
    "        #'add_bos_token': True,\n",
    "        #'truncation_length': 2048,\n",
    "        #'ban_eos_token': False,\n",
    "        #'skip_special_tokens': True,\n",
    "        'stopping_strings': stopping_strings\n",
    "    }\n",
    "\n",
    "def get_vicuna_multi_label_v01(tweet_text):\n",
    "    instruction = \"Assign multilabel labels to the following tweet. Choose out of the following list of labels where \\\"Others\\\" is only assigned if no other label fits: [\\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\", \\\"Others\\\"]\"\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{tweet_text}\\n\\n### Response:\\n\"\n",
    "    return prompt, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>962251540617670661</td>\n",
       "      <td>GRU_202012</td>\n",
       "      <td>RT @Kasman62: After his injury for fifth time ...</td>\n",
       "      <td>[War/Terror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>898277432922263552</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>RT BGEEZ: dncchuckschumernancypelosimsnbccnn h...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>966214616601841664</td>\n",
       "      <td>GRU_202012</td>\n",
       "      <td>RT @LinaArabii: Russian presence in the Black ...</td>\n",
       "      <td>[Media/Journalism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1303856635668987905</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @brianmixologist: Am disappointed in the an...</td>\n",
       "      <td>[Election Campaign]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462250037972840449</td>\n",
       "      <td>IRA_202012</td>\n",
       "      <td>RT @CMCL1979: Why do those those ghastly nativ...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>847754640972070912</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>Stocks: 5 things to know before the bell https...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1038043813267296256</td>\n",
       "      <td>GRU_202012</td>\n",
       "      <td>September 4, 2018 #Syrian air defense units re...</td>\n",
       "      <td>[War/Terror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1030464264748728320</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @xJ57jjSHWvX9mAMmhv7fVaVzxe13bBfCZuGZaBNucL...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1020843977669586945</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @HowweEnt: Dj Shiru To Thrill His Fans http...</td>\n",
       "      <td>[Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>883376409502199808</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>BREAKING VIDEO : 70 Injured in Chaotic G20 Rio...</td>\n",
       "      <td>[Government/Public, Justice/Crime]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id       campaign_name  \\\n",
       "0     962251540617670661          GRU_202012   \n",
       "1     898277432922263552  VENEZUELA_201901_2   \n",
       "2     966214616601841664          GRU_202012   \n",
       "3    1303856635668987905         UGANDA_0621   \n",
       "4     462250037972840449          IRA_202012   \n",
       "..                   ...                 ...   \n",
       "795   847754640972070912  VENEZUELA_201901_2   \n",
       "796  1038043813267296256          GRU_202012   \n",
       "797  1030464264748728320         UGANDA_0621   \n",
       "798  1020843977669586945         UGANDA_0621   \n",
       "799   883376409502199808  VENEZUELA_201901_2   \n",
       "\n",
       "                                                  text  \\\n",
       "0    RT @Kasman62: After his injury for fifth time ...   \n",
       "1    RT BGEEZ: dncchuckschumernancypelosimsnbccnn h...   \n",
       "2    RT @LinaArabii: Russian presence in the Black ...   \n",
       "3    RT @brianmixologist: Am disappointed in the an...   \n",
       "4    RT @CMCL1979: Why do those those ghastly nativ...   \n",
       "..                                                 ...   \n",
       "795  Stocks: 5 things to know before the bell https...   \n",
       "796  September 4, 2018 #Syrian air defense units re...   \n",
       "797  RT @xJ57jjSHWvX9mAMmhv7fVaVzxe13bBfCZuGZaBNucL...   \n",
       "798  RT @HowweEnt: Dj Shiru To Thrill His Fans http...   \n",
       "799  BREAKING VIDEO : 70 Injured in Chaotic G20 Rio...   \n",
       "\n",
       "                            annotations  \n",
       "0                          [War/Terror]  \n",
       "1                              [Others]  \n",
       "2                    [Media/Journalism]  \n",
       "3                   [Election Campaign]  \n",
       "4                              [Others]  \n",
       "..                                  ...  \n",
       "795                            [Others]  \n",
       "796                        [War/Terror]  \n",
       "797                            [Others]  \n",
       "798                            [Others]  \n",
       "799  [Government/Public, Justice/Crime]  \n",
       "\n",
       "[800 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model: generic_prompt_few_shot_prompt_only_classification_3_random_example\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:08<2:15:57,  8.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m request_params \u001b[39m=\u001b[39m get_base_request_params()\n\u001b[1;32m     27\u001b[0m request_params[\u001b[39m\"\u001b[39m\u001b[39mstopping_strings\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m### Human:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mHuman:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m###\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m response \u001b[39m=\u001b[39m get_response(request_params, prompt, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[39m# Save the response in the 'api_results' column\u001b[39;00m\n\u001b[1;32m     31\u001b[0m df_tmp\u001b[39m.\u001b[39mloc[\u001b[39mlambda\u001b[39;00m df: df[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m row[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m], new_column_name] \u001b[39m=\u001b[39m response\n",
      "Cell \u001b[0;32mIn[2], line 84\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(request_params, prompt, context)\u001b[0m\n\u001b[1;32m     81\u001b[0m request_params[\u001b[39m'\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m prompt\n\u001b[1;32m     82\u001b[0m request_params[\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m context\n\u001b[0;32m---> 84\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(URI, json\u001b[39m=\u001b[39mrequest_params)\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m     87\u001b[0m     result \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url, data\u001b[39m=\u001b[39mdata, json\u001b[39m=\u001b[39mjson, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     r\u001b[39m.\u001b[39mcontent\n\u001b[1;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread(amt\u001b[39m=\u001b[39mamt, decode_content\u001b[39m=\u001b[39mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_to_test_names = [\"multilabel_without_context_v01\"]\n",
    "model_funcs = [get_vicuna_multi_label_v01]\n",
    "dataframes = [df_test]\n",
    "dataframes_names = [\"test\"]\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "\n",
    "    for model_name, model_func in zip(models_to_test_names, model_funcs):\n",
    "        print(\"Starting with model: \" + model_name)\n",
    "        print(\"----------------------------------\")\n",
    "        df_tmp = df.copy()\n",
    "        df_tmp[\"prompt\"] = \"\"\n",
    "        df_tmp[\"context\"] = \"\"\n",
    "        new_column_name = dataframes_names[i] + model_name\n",
    "        output_folder = f\"../data/vicuna_4bit/lora/{model_name}/\"\n",
    "\n",
    "        for idx, row in tqdm(df_tmp.iterrows(), total=df_tmp.shape[0]):\n",
    "\n",
    "            tweet_text = normalizeTweet(row[\"text\"])\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], 'normalized_tweet'] = tweet_text\n",
    "\n",
    "            prompt, context = model_func(tweet_text)\n",
    "            df_tmp.at[idx, \"prompt\"] = prompt\n",
    "            df_tmp.at[idx, \"context\"] = context\n",
    "\n",
    "            request_params = get_base_request_params()\n",
    "            request_params[\"stopping_strings\"] = [\"\\n\", \"### Human:\", \"Human:\", \"###\"]\n",
    "            response = get_response(request_params, prompt, \"\")\n",
    "\n",
    "            # Save the response in the 'api_results' column\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], new_column_name] = response\n",
    "            if (i + 1) % 100 == 0:\n",
    "                output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "                df_tmp.to_csv(output_path, index=False)\n",
    "                print(f\"Saved progress at index {idx}\")\n",
    "                print(\"Sample Tweet: \", tweet_text)\n",
    "                print(\"Sample Annotation: \", response)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "        df_tmp.to_csv(output_path, index=False)        \n",
    "            # Save the request_params as a JSON file in the output folder\n",
    "        with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "            json.dump(request_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "df_tmp.to_csv(output_path, index=False)        \n",
    "    # Save the request_params as a JSON file in the output folder\n",
    "with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "    json.dump(request_params, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
