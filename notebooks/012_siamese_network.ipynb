{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/bruno/.var/app/com.visualstudio.code/cache/torch/sentence_transformers/vinai_bertweet-large. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/bruno/.var/app/com.visualstudio.code/cache/torch/sentence_transformers/vinai_bertweet-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Processing batches:   0%|          | 0/22 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'sentence_transformers.readers.InputExample.InputExample'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 207\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(embeddings)\n\u001b[1;32m    206\u001b[0m \u001b[39m# Get the embeddings for the labeled data\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m train_embeddings \u001b[39m=\u001b[39m get_bert_embeddings(train_dataloader)\n\u001b[1;32m    208\u001b[0m val_embeddings \u001b[39m=\u001b[39m get_bert_embeddings(val_dataloader)\n\u001b[1;32m    210\u001b[0m \u001b[39m# Calculate cosine similarity between embeddings\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 197\u001b[0m, in \u001b[0;36mget_bert_embeddings\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m    195\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    196\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(dataloader, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing batches\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    198\u001b[0m         input_ids \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    199\u001b[0m         attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    204\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    148\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m--> 150\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'sentence_transformers.readers.InputExample.InputExample'>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict\n",
    "\n",
    "from tabulate import tabulate\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your provided classes and functions: MultiLabelDataCollator, TweetDataset, etc.\n",
    "class MultiLabelDataCollator(DataCollatorWithPadding):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__(tokenizer)\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, torch.Tensor]]):\n",
    "        batch = super().__call__(features)\n",
    "        batch[\"labels\"] = torch.stack([feature[\"label\"] for feature in features])\n",
    "        return batch\n",
    "        \n",
    "    @staticmethod\n",
    "    def loss(logits, labels):\n",
    "        # Use BCEWithLogitsLoss for multi-label classification\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        return loss_fct(logits, labels.float())\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= 0.5)] = 1\n",
    "\n",
    "    report = classification_report(labels, y_pred, labels=range(len(classes)), output_dict=True)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": np.mean(predictions == labels),\n",
    "        \"micro_precision\": report[\"micro avg\"][\"precision\"],\n",
    "        \"micro_recall\": report[\"micro avg\"][\"recall\"],\n",
    "        \"micro_f1\": report[\"micro avg\"][\"f1-score\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, x, y, mlb, tokenizer):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mlb = mlb\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 128\n",
    "        self.encoded_tweets = self.preprocess_text(self.x)\n",
    "        \n",
    "    @staticmethod\n",
    "    def normalizeToken(token):\n",
    "        lowercased_token = token.lower()\n",
    "        if token.startswith(\"@\"):\n",
    "            return \"@USER\"\n",
    "        elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "            return \"HTTPURL\"\n",
    "        elif len(token) == 1:\n",
    "            return demojize(token)\n",
    "        else:\n",
    "            if token == \"’\":\n",
    "                return \"'\"\n",
    "            elif token == \"…\":\n",
    "                return \"...\"\n",
    "            else:\n",
    "                return token\n",
    "    \n",
    "    def normalizeTweet(self, tweet):\n",
    "        tokens = TweetTokenizer().tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
    "        normTweet = \" \".join([self.normalizeToken(token) for token in tokens])\n",
    "\n",
    "        normTweet = (\n",
    "            normTweet.replace(\"cannot \", \"can not \")\n",
    "                .replace(\"n't \", \" n't \")\n",
    "                .replace(\"n 't \", \" n't \")\n",
    "                .replace(\"ca n't\", \"can't\")\n",
    "                .replace(\"ai n't\", \"ain't\")\n",
    "        )\n",
    "        normTweet = (\n",
    "            normTweet.replace(\"'m \", \" 'm \")\n",
    "                .replace(\"'re \", \" 're \")\n",
    "                .replace(\"'s \", \" 's \")\n",
    "                .replace(\"'ll \", \" 'll \")\n",
    "                .replace(\"'d \", \" 'd \")\n",
    "                .replace(\"'ve \", \" 've \")\n",
    "        )\n",
    "        normTweet = (\n",
    "            normTweet.replace(\" p . m .\", \"  p.m.\")\n",
    "                .replace(\" p . m \", \" p.m \")\n",
    "                .replace(\" a . m .\", \" a.m.\")\n",
    "                .replace(\" a . m \", \" a.m \")\n",
    "        )\n",
    "        return \" \".join(normTweet.split())\n",
    "\n",
    "    def preprocess_text(self, X):\n",
    "        X = [self.normalizeTweet(tweet) for tweet in X]\n",
    "        \n",
    "        return self.tokenizer(X, return_attention_mask=True, return_tensors='pt', padding=True, truncation = True, max_length=self.max_length)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        return {'input_ids': self.encoded_tweets['input_ids'][idx],\n",
    "                'attention_mask': self.encoded_tweets['attention_mask'][idx],\n",
    "                'label': torch.tensor(label, dtype=torch.float32)}\n",
    "                #'label_ids': self.labels[idx]}\n",
    "\n",
    "\n",
    "# Load the fine-tuned BERT model and tokenizer\n",
    "filename = \"../data/labeled_data/generic_test_0.json\"\n",
    "with open(filename) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(data[\"train\"])\n",
    "val_df = pd.DataFrame(data[\"valid\"])\n",
    "test_df = pd.DataFrame(data[\"test\"])\n",
    "train_size = 100\n",
    "validation_size = 100\n",
    "test_size = 100\n",
    "# train_size argument is used to control the size of the training set \n",
    "if train_size != \"full\":\n",
    "    train_df = train_df.sample(n=train_size)\n",
    "if validation_size != \"full\":\n",
    "    val_df = val_df.sample(n=validation_size)\n",
    "if test_size != \"full\":\n",
    "    test_df = test_df.sample(n=test_size)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-large\", num_labels=15, problem_type=\"multi_label_classification\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n",
    "\n",
    "train_annotations = train_df[\"annotations\"].tolist()\n",
    "\n",
    "# Get all unique classes\n",
    "classes = set()\n",
    "for annotation in train_annotations:\n",
    "    classes.update(annotation)\n",
    "classes = sorted(list(classes))\n",
    "\n",
    "# Convert the annotations to binary labels\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "train_labels = mlb.fit_transform(train_df[\"annotations\"])\n",
    "val_labels = mlb.transform(val_df[\"annotations\"])\n",
    "test_labels = mlb.transform(test_df[\"annotations\"])\n",
    "\n",
    "# Initialize the datasets and DataLoader\n",
    "train_dataset = TweetDataset(train_df['text'].to_list(), train_labels, mlb, tokenizer)\n",
    "val_dataset = TweetDataset(val_df['text'].to_list(), val_labels, mlb, tokenizer)\n",
    "test_dataset = TweetDataset(test_df['text'].to_list(), test_labels, mlb, tokenizer)\n",
    "data_collator = MultiLabelDataCollator(tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, collate_fn=data_collator)\n",
    "\n",
    "# Function to get BERT embeddings using DataLoader\n",
    "def get_bert_embeddings(dataloader):\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing batches\"):\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            sigmoid = torch.nn.Sigmoid()\n",
    "            probs = sigmoid(torch.Tensor(outputs.logits))\n",
    "            embeddings.extend(probs.numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Get the embeddings for the labeled data\n",
    "train_embeddings = get_bert_embeddings(train_dataloader)\n",
    "val_embeddings = get_bert_embeddings(val_dataloader)\n",
    "\n",
    "# Calculate cosine similarity between embeddings\n",
    "cosine_sim_matrix = cosine_similarity(val_embeddings, train_embeddings)\n",
    "\n",
    "# Find the most similar labeled tweets and assign labels\n",
    "predicted_labels = []\n",
    "for i in range(len(val_df)):\n",
    "    most_similar_index = np.argmax(cosine_sim_matrix[i])\n",
    "    predicted_labels.append(train_labels[most_similar_index])\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "val_accuracy = np.sum(np.array(predicted_labels) == val_labels) / len(val_labels)\n",
    "print(f\"Validation accuracy: {val_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/bruno/.var/app/com.visualstudio.code/cache/torch/sentence_transformers/vinai_bertweet-large. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/bruno/.var/app/com.visualstudio.code/cache/torch/sentence_transformers/vinai_bertweet-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f3e297381e4c02ad9a4e33236700a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a93497d640841d790aad8cd3304b439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a3db481b254961bf2be02056db2bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f07a082ec0428c9bde6dfd9d1ef18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254e69f3a8dc44eaa0556cb118ace98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804e07b958f54b868895281397f731c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e77b3b3e8046009a520c6139e203e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ccf5ff9c874a8b9f806930bea28703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict\n",
    "\n",
    "from tabulate import tabulate\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your provided classes and functions: MultiLabelDataCollator, TweetDataset, etc.\n",
    "class MultiLabelDataCollator(DataCollatorWithPadding):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__(tokenizer)\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, torch.Tensor]]):\n",
    "        batch = super().__call__(features)\n",
    "        batch[\"labels\"] = torch.stack([feature[\"label\"] for feature in features])\n",
    "        return batch\n",
    "        \n",
    "    @staticmethod\n",
    "    def loss(logits, labels):\n",
    "        # Use BCEWithLogitsLoss for multi-label classification\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        return loss_fct(logits, labels.float())\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= 0.5)] = 1\n",
    "\n",
    "    report = classification_report(labels, y_pred, labels=range(len(classes)), output_dict=True)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": np.mean(predictions == labels),\n",
    "        \"micro_precision\": report[\"micro avg\"][\"precision\"],\n",
    "        \"micro_recall\": report[\"micro avg\"][\"recall\"],\n",
    "        \"micro_f1\": report[\"micro avg\"][\"f1-score\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, x, y, mlb, tokenizer):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mlb = mlb\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 128\n",
    "        self.encoded_tweets = self.preprocess_text(self.x)\n",
    "        \n",
    "    @staticmethod\n",
    "    def normalizeToken(token):\n",
    "        lowercased_token = token.lower()\n",
    "        if token.startswith(\"@\"):\n",
    "            return \"@USER\"\n",
    "        elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "            return \"HTTPURL\"\n",
    "        elif len(token) == 1:\n",
    "            return demojize(token)\n",
    "        else:\n",
    "            if token == \"’\":\n",
    "                return \"'\"\n",
    "            elif token == \"…\":\n",
    "                return \"...\"\n",
    "            else:\n",
    "                return token\n",
    "    \n",
    "    def normalizeTweet(self, tweet):\n",
    "        tokens = TweetTokenizer().tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
    "        normTweet = \" \".join([self.normalizeToken(token) for token in tokens])\n",
    "\n",
    "        normTweet = (\n",
    "            normTweet.replace(\"cannot \", \"can not \")\n",
    "                .replace(\"n't \", \" n't \")\n",
    "                .replace(\"n 't \", \" n't \")\n",
    "                .replace(\"ca n't\", \"can't\")\n",
    "                .replace(\"ai n't\", \"ain't\")\n",
    "        )\n",
    "        normTweet = (\n",
    "            normTweet.replace(\"'m \", \" 'm \")\n",
    "                .replace(\"'re \", \" 're \")\n",
    "                .replace(\"'s \", \" 's \")\n",
    "                .replace(\"'ll \", \" 'll \")\n",
    "                .replace(\"'d \", \" 'd \")\n",
    "                .replace(\"'ve \", \" 've \")\n",
    "        )\n",
    "        normTweet = (\n",
    "            normTweet.replace(\" p . m .\", \"  p.m.\")\n",
    "                .replace(\" p . m \", \" p.m \")\n",
    "                .replace(\" a . m .\", \" a.m.\")\n",
    "                .replace(\" a . m \", \" a.m \")\n",
    "        )\n",
    "        return \" \".join(normTweet.split())\n",
    "\n",
    "    def preprocess_text(self, X):\n",
    "        X = [self.normalizeTweet(tweet) for tweet in X]\n",
    "        \n",
    "        return self.tokenizer(X, return_attention_mask=True, return_tensors='pt', padding=True, truncation = True, max_length=self.max_length)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        return {'input_ids': self.encoded_tweets['input_ids'][idx],\n",
    "                'attention_mask': self.encoded_tweets['attention_mask'][idx],\n",
    "                'label': torch.tensor(label, dtype=torch.float32)}\n",
    "                #'label_ids': self.labels[idx]}\n",
    "\n",
    "\n",
    "# Load the fine-tuned BERT model and tokenizer\n",
    "filename = \"../data/labeled_data/generic_test_0.json\"\n",
    "with open(filename) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(data[\"train\"])\n",
    "val_df = pd.DataFrame(data[\"valid\"])\n",
    "test_df = pd.DataFrame(data[\"test\"])\n",
    "train_size = \"full\"\n",
    "validation_size = \"full\"\n",
    "test_size = \"full\"\n",
    "# train_size argument is used to control the size of the training set \n",
    "if train_size != \"full\":\n",
    "    train_df = train_df.sample(n=train_size)\n",
    "if validation_size != \"full\":\n",
    "    val_df = val_df.sample(n=validation_size)\n",
    "if test_size != \"full\":\n",
    "    test_df = test_df.sample(n=test_size)\n",
    "\n",
    "model = SentenceTransformer(\"vinai/bertweet-large\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n",
    "\n",
    "train_annotations = train_df[\"annotations\"].tolist()\n",
    "\n",
    "# Get all unique classes\n",
    "classes = set()\n",
    "for annotation in train_annotations:\n",
    "    classes.update(annotation)\n",
    "classes = sorted(list(classes))\n",
    "\n",
    "# Convert the annotations to binary labels\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "train_labels = mlb.fit_transform(train_df[\"annotations\"])\n",
    "val_labels = mlb.transform(val_df[\"annotations\"])\n",
    "test_labels = mlb.transform(test_df[\"annotations\"])\n",
    "\n",
    "train_examples = []\n",
    "\n",
    "# Iterate through each unique label\n",
    "for label_idx in range(len(classes)):\n",
    "    # Create a list of indices for the tweets containing the current label\n",
    "    label_indices = [idx for idx, labels in enumerate(train_labels) if labels[label_idx] == 1]\n",
    "\n",
    "    # Iterate through the tweet indices with the current label\n",
    "    for i in range(len(label_indices)):\n",
    "        anchor_idx = label_indices[i]\n",
    "        anchor_text = train_df['text'].iloc[anchor_idx]\n",
    "        anchor_label = train_labels[anchor_idx]\n",
    "\n",
    "        # Search for a positive example with the same label\n",
    "        for j in range(len(label_indices)):\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            positive_idx = label_indices[j]\n",
    "            positive_text = train_df['text'].iloc[positive_idx]\n",
    "            positive_label = train_labels[positive_idx]\n",
    "\n",
    "            # Check if the anchor and positive texts share the current label\n",
    "            if anchor_label[label_idx] == positive_label[label_idx]:\n",
    "                train_examples.append(InputExample(texts=[anchor_text, positive_text], label=1.0))\n",
    "                break\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=8)\n",
    "\n",
    "#train_dataloader = DataLoader(train_dataset, batch_size=4, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, collate_fn=data_collator)\n",
    "\n",
    "loss_function = losses.CosineSimilarityLoss(model)\n",
    "# loss_function = losses.TripletLoss(model)\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, loss_function)], epochs=5, warmup_steps=100)\n",
    "\n",
    "val_embeddings = model.encode(val_df['text'].to_list(), convert_to_numpy=True, show_progress_bar=True)\n",
    "train_embeddings = model.encode(train_df['text'].to_list(), convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "cosine_sim_matrix = cosine_similarity(val_embeddings, train_embeddings)\n",
    "\n",
    "threshold = 0.5\n",
    "predicted_labels = []\n",
    "\n",
    "for i in range(len(val_df)):\n",
    "    label_indices = np.where(cosine_sim_matrix[i] >= threshold)[0]\n",
    "    label_set = set()\n",
    "    for idx in label_indices:\n",
    "        label_set.update(train_df['annotations'].iloc[idx])\n",
    "    predicted_labels.append(list(label_set))\n",
    "predicted_bin_labels = mlb.transform(predicted_labels)\n",
    "report = classification_report(val_labels, predicted_bin_labels, target_names=classes, labels=range(len(classes)), output_dict=True, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conspiracy Theory</th>\n",
       "      <td>0.05875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.110980</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.01500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029557</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Election Campaign</th>\n",
       "      <td>0.03250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Environment</th>\n",
       "      <td>0.01750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034398</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Government/Public</th>\n",
       "      <td>0.31500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479087</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>0.05625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106509</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Immigration/Integration</th>\n",
       "      <td>0.05000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Justice/Crime</th>\n",
       "      <td>0.13375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235943</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labor/Employment</th>\n",
       "      <td>0.02375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046398</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macroeconomics/Economic Regulation</th>\n",
       "      <td>0.07250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.135198</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media/Journalism</th>\n",
       "      <td>0.04750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090692</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.25625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religion</th>\n",
       "      <td>0.02750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science/Technology</th>\n",
       "      <td>0.01250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War/Terror</th>\n",
       "      <td>0.23125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375635</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.09000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.09000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152585</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.18959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.304616</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.09000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162757</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    precision  recall  f1-score  support\n",
       "Conspiracy Theory                     0.05875     1.0  0.110980       47\n",
       "Education                             0.01500     1.0  0.029557       12\n",
       "Election Campaign                     0.03250     1.0  0.062954       26\n",
       "Environment                           0.01750     1.0  0.034398       14\n",
       "Government/Public                     0.31500     1.0  0.479087      252\n",
       "Health                                0.05625     1.0  0.106509       45\n",
       "Immigration/Integration               0.05000     1.0  0.095238       40\n",
       "Justice/Crime                         0.13375     1.0  0.235943      107\n",
       "Labor/Employment                      0.02375     1.0  0.046398       19\n",
       "Macroeconomics/Economic Regulation    0.07250     1.0  0.135198       58\n",
       "Media/Journalism                      0.04750     1.0  0.090692       38\n",
       "Others                                0.25625     1.0  0.407960      205\n",
       "Religion                              0.02750     1.0  0.053528       22\n",
       "Science/Technology                    0.01250     1.0  0.024691       10\n",
       "War/Terror                            0.23125     1.0  0.375635      185\n",
       "micro avg                             0.09000     1.0  0.165138     1080\n",
       "macro avg                             0.09000     1.0  0.152585     1080\n",
       "weighted avg                          0.18959     1.0  0.304616     1080\n",
       "samples avg                           0.09000     1.0  0.162757     1080"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_report_to_dataframe(average_report):\n",
    "    data = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1-score\": [],\n",
    "        \"support\": []\n",
    "    }\n",
    "    index = []\n",
    "\n",
    "    for class_name, metrics in average_report.items():\n",
    "        if class_name == 'accuracy':\n",
    "            continue\n",
    "\n",
    "        index.append(class_name)\n",
    "        data[\"precision\"].append(metrics[\"precision\"])\n",
    "        data[\"recall\"].append(metrics[\"recall\"])\n",
    "        data[\"f1-score\"].append(metrics[\"f1-score\"])\n",
    "        data[\"support\"].append(metrics[\"support\"])\n",
    "\n",
    "    return pd.DataFrame(data, index=index)\n",
    "\n",
    "average_report_to_dataframe(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conspiracy Theory</th>\n",
       "      <td>0.05875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.110980</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.01500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029557</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Election Campaign</th>\n",
       "      <td>0.03250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Environment</th>\n",
       "      <td>0.01750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034398</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Government/Public</th>\n",
       "      <td>0.31500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479087</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>0.05625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106509</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Immigration/Integration</th>\n",
       "      <td>0.05000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Justice/Crime</th>\n",
       "      <td>0.13375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235943</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labor/Employment</th>\n",
       "      <td>0.02375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046398</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macroeconomics/Economic Regulation</th>\n",
       "      <td>0.07250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.135198</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media/Journalism</th>\n",
       "      <td>0.04750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090692</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.25625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religion</th>\n",
       "      <td>0.02750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science/Technology</th>\n",
       "      <td>0.01250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War/Terror</th>\n",
       "      <td>0.23125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375635</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.09000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.09000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152585</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.18959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.304616</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.09000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162757</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    precision  recall  f1-score  support\n",
       "Conspiracy Theory                     0.05875     1.0  0.110980       47\n",
       "Education                             0.01500     1.0  0.029557       12\n",
       "Election Campaign                     0.03250     1.0  0.062954       26\n",
       "Environment                           0.01750     1.0  0.034398       14\n",
       "Government/Public                     0.31500     1.0  0.479087      252\n",
       "Health                                0.05625     1.0  0.106509       45\n",
       "Immigration/Integration               0.05000     1.0  0.095238       40\n",
       "Justice/Crime                         0.13375     1.0  0.235943      107\n",
       "Labor/Employment                      0.02375     1.0  0.046398       19\n",
       "Macroeconomics/Economic Regulation    0.07250     1.0  0.135198       58\n",
       "Media/Journalism                      0.04750     1.0  0.090692       38\n",
       "Others                                0.25625     1.0  0.407960      205\n",
       "Religion                              0.02750     1.0  0.053528       22\n",
       "Science/Technology                    0.01250     1.0  0.024691       10\n",
       "War/Terror                            0.23125     1.0  0.375635      185\n",
       "micro avg                             0.09000     1.0  0.165138     1080\n",
       "macro avg                             0.09000     1.0  0.152585     1080\n",
       "weighted avg                          0.18959     1.0  0.304616     1080\n",
       "samples avg                           0.09000     1.0  0.162757     1080"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_report_to_dataframe(average_report):\n",
    "    data = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1-score\": [],\n",
    "        \"support\": []\n",
    "    }\n",
    "    index = []\n",
    "\n",
    "    for class_name, metrics in average_report.items():\n",
    "        if class_name == 'accuracy':\n",
    "            continue\n",
    "\n",
    "        index.append(class_name)\n",
    "        data[\"precision\"].append(metrics[\"precision\"])\n",
    "        data[\"recall\"].append(metrics[\"recall\"])\n",
    "        data[\"f1-score\"].append(metrics[\"f1-score\"])\n",
    "        data[\"support\"].append(metrics[\"support\"])\n",
    "\n",
    "    return pd.DataFrame(data, index=index)\n",
    "\n",
    "average_report_to_dataframe(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mvinai/bertweet-large\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Create the SiameseTextDataset\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m siamese_train_dataset \u001b[39m=\u001b[39m SiameseTextDataset(train_examples, tokenizer)\n\u001b[1;32m     39\u001b[0m \u001b[39m# Create the DataLoader\u001b[39;00m\n\u001b[1;32m     40\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(siamese_train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_examples' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class SiameseTextDataset(Dataset):\n",
    "    def __init__(self, examples, tokenizer, max_length=128):\n",
    "        self.examples = examples\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        text1, text2 = example.texts\n",
    "        label = example.label\n",
    "\n",
    "        encoding1 = self.tokenizer(text1, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        encoding2 = self.tokenizer(text2, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "\n",
    "        return {\n",
    "            'input_ids1': encoding1['input_ids'].squeeze(0),\n",
    "            'attention_mask1': encoding1['attention_mask'].squeeze(0),\n",
    "            'input_ids2': encoding2['input_ids'].squeeze(0),\n",
    "            'attention_mask2': encoding2['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Instantiate the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n",
    "\n",
    "# Create the SiameseTextDataset\n",
    "siamese_train_dataset = SiameseTextDataset(train_examples, tokenizer)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(siamese_train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "class SiameseBERT(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(SiameseBERT, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n",
    "        output1 = self.bert(input_ids=input_ids1, attention_mask=attention_mask1)\n",
    "        output2 = self.bert(input_ids=input_ids2, attention_mask=attention_mask2)\n",
    "        return output1, output2\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, labels):\n",
    "        distances = 1 - torch.nn.functional.cosine_similarity(output1, output2)\n",
    "        loss = (labels * distances.pow(2) + (1 - labels) * torch.clamp(self.margin - distances, min=0).pow(2)).mean()\n",
    "        return loss\n",
    "    \n",
    "\n",
    "train_examples = []\n",
    "\n",
    "# Instantiate the SiameseBERT model and the ContrastiveLoss\n",
    "siamese_model = SiameseBERT(\"vinai/bertweet-large\")\n",
    "contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "# Set up the training loop\n",
    "optimizer = torch.optim.Adam(siamese_model.parameters(), lr=5e-5)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "siamese_model = siamese_model.to(device)\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    siamese_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids1, attention_mask1 = batch['input_ids1'].to(device), batch['attention_mask1'].to(device)\n",
    "        input_ids2, attention_mask2 = batch['input_ids2'].to(device), batch['attention_mask2'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        output1, output2 = siamese_model(input_ids1, attention_mask1, input_ids2, attention_mask2)\n",
    "        loss = contrastive_loss(output1.pooler_output, output2.pooler_output, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {total_loss / len(train_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_df)):\n",
    "    label_indices = np.where(cosine_sim_matrix[i] >= threshold)[0]\n",
    "    label_set = set()\n",
    "    for idx in label_indices:\n",
    "        label_set.update(train_df['annotations'].iloc[idx])\n",
    "    predicted_labels.append(list(label_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
