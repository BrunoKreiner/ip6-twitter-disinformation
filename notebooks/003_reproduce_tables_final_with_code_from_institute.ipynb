{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loss  accuracy  micro_precision  micro_recall  micro_f1  \\\n",
      "0  0.132741       0.0         0.823881      0.787072  0.805056   \n",
      "1  0.184075       0.0         0.779221      0.703934  0.739666   \n",
      "2  0.109380       0.0         0.830753      0.772553  0.800597   \n",
      "3  0.153071       0.0         0.784553      0.665977  0.720418   \n",
      "4  0.113060       0.0         0.816616      0.772031  0.793698   \n",
      "5  0.157828       0.0         0.798791      0.638371  0.709628   \n",
      "6  0.113176       0.0         0.824473      0.772556  0.797671   \n",
      "7  0.152108       0.0         0.803723      0.655625  0.722159   \n",
      "8  0.111680       0.0         0.827362      0.729187  0.775178   \n",
      "9  0.154341       0.0         0.802740      0.606625  0.691038   \n",
      "\n",
      "   macro_precision  macro_recall  macro_f1  runtime  samples_per_second  \\\n",
      "0         0.721881      0.660063  0.683039   3.3753             237.019   \n",
      "1         0.707577      0.623297  0.637038   4.2092             237.577   \n",
      "2         0.810919      0.593703  0.664724   3.3497             238.830   \n",
      "3         0.737310      0.515994  0.568570   4.2346             236.149   \n",
      "4         0.765495      0.627509  0.678246   3.4473             232.064   \n",
      "5         0.687353      0.494920  0.537943   4.2873             233.249   \n",
      "6         0.753957      0.628647  0.674705   3.3684             237.499   \n",
      "7         0.735029      0.539456  0.588076   4.2363             236.053   \n",
      "8         0.703476      0.523191  0.581927   3.3613             238.004   \n",
      "9         0.588048      0.454460  0.480215   4.2586             234.820   \n",
      "\n",
      "   steps_per_second  num_epochs dataset  fold  \n",
      "0            59.255         9.5   valid     1  \n",
      "1            59.394         9.5    test     1  \n",
      "2            59.707         5.0   valid     2  \n",
      "3            59.037         5.0    test     2  \n",
      "4            58.016         5.5   valid     3  \n",
      "5            58.312         5.5    test     3  \n",
      "6            59.375         5.5   valid     4  \n",
      "7            59.013         5.5    test     4  \n",
      "8            59.501         3.5   valid     5  \n",
      "9            58.705         3.5    test     5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from typing import List, Dict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the dataset class\n",
    "\n",
    "# Load data from json file\n",
    "with open('../reports/VENEZUELA_201901_2_epochs_200_train_size_full.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dfs = []\n",
    "for k, v in data.items():\n",
    "    valid_metrics = v['valid']\n",
    "    valid_metrics['dataset'] = 'valid'\n",
    "    valid_metrics['fold'] = int(k) + 1\n",
    "    dfs.append(pd.DataFrame([valid_metrics]))\n",
    "    \n",
    "    test_metrics = v['test']\n",
    "    test_metrics['dataset'] = 'test'\n",
    "    test_metrics['fold'] = int(k) + 1\n",
    "    dfs.append(pd.DataFrame([test_metrics]))\n",
    "\n",
    "# Concatenate all dataframes together\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "df.columns = df.columns.str.replace('eval_', '')\n",
    "df = df.rename(columns={'epoch': 'num_epochs'})\n",
    "\n",
    "# Print the final dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/952663639.py:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df[df.dataset == \"test\"].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loss                    0.160285\n",
       "accuracy                0.000000\n",
       "micro_precision         0.793805\n",
       "micro_recall            0.654106\n",
       "micro_f1                0.716582\n",
       "macro_precision         0.691064\n",
       "macro_recall            0.525625\n",
       "macro_f1                0.562369\n",
       "runtime                 4.245200\n",
       "samples_per_second    235.569600\n",
       "steps_per_second       58.892200\n",
       "num_epochs              5.800000\n",
       "fold                    3.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.dataset == \"test\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/generic_epochs_200_train_size_full_fold_1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/generic_epochs_200_train_size_full_fold_2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/generic_epochs_200_train_size_full_fold_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/generic_epochs_200_train_size_full_fold_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Conspiracy Theory': {'precision': 0.6521739130434783, 'recall': 0.3191489361702128, 'f1-score': 0.4285714285714286, 'support': 47}, 'Education': {'precision': 0.875, 'recall': 0.5833333333333334, 'f1-score': 0.7000000000000001, 'support': 12}, 'Election Campaign': {'precision': 0.8076923076923077, 'recall': 0.8076923076923077, 'f1-score': 0.8076923076923077, 'support': 26}, 'Environment': {'precision': 1.0, 'recall': 0.5714285714285714, 'f1-score': 0.7272727272727273, 'support': 14}, 'Government/Public': {'precision': 0.7686832740213523, 'recall': 0.8571428571428571, 'f1-score': 0.8105065666041276, 'support': 252}, 'Health': {'precision': 0.8571428571428571, 'recall': 0.8, 'f1-score': 0.8275862068965518, 'support': 45}, 'Immigration/Integration': {'precision': 0.8275862068965517, 'recall': 0.6, 'f1-score': 0.6956521739130435, 'support': 40}, 'Justice/Crime': {'precision': 0.7669902912621359, 'recall': 0.7383177570093458, 'f1-score': 0.7523809523809523, 'support': 107}, 'Labor/Employment': {'precision': 0.7058823529411765, 'recall': 0.631578947368421, 'f1-score': 0.6666666666666667, 'support': 19}, 'Macroeconomics/Economic Regulation': {'precision': 0.8780487804878049, 'recall': 0.6206896551724138, 'f1-score': 0.7272727272727273, 'support': 58}, 'Media/Journalism': {'precision': 0.8235294117647058, 'recall': 0.7368421052631579, 'f1-score': 0.7777777777777778, 'support': 38}, 'Others': {'precision': 0.8357487922705314, 'recall': 0.8439024390243902, 'f1-score': 0.8398058252427185, 'support': 205}, 'Religion': {'precision': 0.6666666666666666, 'recall': 0.36363636363636365, 'f1-score': 0.4705882352941177, 'support': 22}, 'Science/Technology': {'precision': 0.6666666666666666, 'recall': 0.4, 'f1-score': 0.5, 'support': 10}, 'War/Terror': {'precision': 0.9710982658959537, 'recall': 0.9081081081081082, 'f1-score': 0.9385474860335196, 'support': 185}, 'micro avg': {'precision': 0.8267326732673267, 'recall': 0.7731481481481481, 'f1-score': 0.7990430622009568, 'support': 1080}, 'macro avg': {'precision': 0.8068606524501458, 'recall': 0.6521214254232989, 'f1-score': 0.7113547387745777, 'support': 1080}, 'weighted avg': {'precision': 0.8255101143884639, 'recall': 0.7731481481481481, 'f1-score': 0.7917527953259383, 'support': 1080}, 'samples avg': {'precision': 0.8335416666666666, 'recall': 0.8048958333333335, 'f1-score': 0.8039999999999999, 'support': 1080}}, {'Conspiracy Theory': {'precision': 0.6944444444444444, 'recall': 0.4166666666666667, 'f1-score': 0.5208333333333334, 'support': 60}, 'Education': {'precision': 0.8333333333333334, 'recall': 0.625, 'f1-score': 0.7142857142857143, 'support': 16}, 'Election Campaign': {'precision': 0.8611111111111112, 'recall': 0.8857142857142857, 'f1-score': 0.8732394366197184, 'support': 35}, 'Environment': {'precision': 0.875, 'recall': 0.5, 'f1-score': 0.6363636363636364, 'support': 14}, 'Government/Public': {'precision': 0.7565543071161048, 'recall': 0.8278688524590164, 'f1-score': 0.7906066536203522, 'support': 244}, 'Health': {'precision': 0.8048780487804879, 'recall': 0.8048780487804879, 'f1-score': 0.8048780487804877, 'support': 41}, 'Immigration/Integration': {'precision': 0.6938775510204082, 'recall': 0.7555555555555555, 'f1-score': 0.723404255319149, 'support': 45}, 'Justice/Crime': {'precision': 0.7563025210084033, 'recall': 0.8181818181818182, 'f1-score': 0.7860262008733625, 'support': 110}, 'Labor/Employment': {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 16}, 'Macroeconomics/Economic Regulation': {'precision': 0.6666666666666666, 'recall': 0.72, 'f1-score': 0.6923076923076923, 'support': 50}, 'Media/Journalism': {'precision': 0.6410256410256411, 'recall': 0.78125, 'f1-score': 0.7042253521126761, 'support': 32}, 'Others': {'precision': 0.8599033816425121, 'recall': 0.7705627705627706, 'f1-score': 0.8127853881278538, 'support': 231}, 'Religion': {'precision': 0.7692307692307693, 'recall': 0.7142857142857143, 'f1-score': 0.7407407407407408, 'support': 14}, 'Science/Technology': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 14}, 'War/Terror': {'precision': 0.9060773480662984, 'recall': 0.9213483146067416, 'f1-score': 0.913649025069638, 'support': 178}, 'micro avg': {'precision': 0.7962962962962963, 'recall': 0.7818181818181819, 'f1-score': 0.7889908256880734, 'support': 1100}, 'macro avg': {'precision': 0.7953936748964121, 'recall': 0.6997779446446799, 'f1-score': 0.7183896985036237, 'support': 1100}, 'weighted avg': {'precision': 0.8008552187842429, 'recall': 0.7818181818181819, 'f1-score': 0.7831627791467639, 'support': 1100}, 'samples avg': {'precision': 0.8075, 'recall': 0.8034375, 'f1-score': 0.7893571428571429, 'support': 1100}}, {'Conspiracy Theory': {'precision': 0.5757575757575758, 'recall': 0.4318181818181818, 'f1-score': 0.49350649350649356, 'support': 44}, 'Education': {'precision': 0.7777777777777778, 'recall': 0.6363636363636364, 'f1-score': 0.7000000000000001, 'support': 11}, 'Election Campaign': {'precision': 0.6666666666666666, 'recall': 0.72, 'f1-score': 0.6923076923076923, 'support': 25}, 'Environment': {'precision': 1.0, 'recall': 0.7272727272727273, 'f1-score': 0.8421052631578948, 'support': 11}, 'Government/Public': {'precision': 0.8617511520737328, 'recall': 0.7540322580645161, 'f1-score': 0.8043010752688172, 'support': 248}, 'Health': {'precision': 0.8125, 'recall': 0.65, 'f1-score': 0.7222222222222223, 'support': 40}, 'Immigration/Integration': {'precision': 0.8, 'recall': 0.8275862068965517, 'f1-score': 0.8135593220338982, 'support': 29}, 'Justice/Crime': {'precision': 0.8303571428571429, 'recall': 0.808695652173913, 'f1-score': 0.8193832599118942, 'support': 115}, 'Labor/Employment': {'precision': 0.7692307692307693, 'recall': 0.5, 'f1-score': 0.6060606060606061, 'support': 20}, 'Macroeconomics/Economic Regulation': {'precision': 0.7073170731707317, 'recall': 0.6041666666666666, 'f1-score': 0.6516853932584269, 'support': 48}, 'Media/Journalism': {'precision': 0.72, 'recall': 0.8, 'f1-score': 0.7578947368421052, 'support': 45}, 'Others': {'precision': 0.8442211055276382, 'recall': 0.7962085308056872, 'f1-score': 0.8195121951219513, 'support': 211}, 'Religion': {'precision': 0.5, 'recall': 0.1, 'f1-score': 0.16666666666666669, 'support': 10}, 'Science/Technology': {'precision': 1.0, 'recall': 0.18181818181818182, 'f1-score': 0.3076923076923077, 'support': 11}, 'War/Terror': {'precision': 0.9004739336492891, 'recall': 0.95, 'f1-score': 0.924574209245742, 'support': 200}, 'micro avg': {'precision': 0.8296146044624746, 'recall': 0.7659176029962547, 'f1-score': 0.7964946445959105, 'support': 1068}, 'macro avg': {'precision': 0.7844035464474215, 'recall': 0.6325308027920041, 'f1-score': 0.674764762886448, 'support': 1068}, 'weighted avg': {'precision': 0.8262380033627459, 'recall': 0.7659176029962547, 'f1-score': 0.7889078257750887, 'support': 1068}, 'samples avg': {'precision': 0.8297916666666667, 'recall': 0.7947916666666666, 'f1-score': 0.7966428571428571, 'support': 1068}}, {'Conspiracy Theory': {'precision': 0.7435897435897436, 'recall': 0.6041666666666666, 'f1-score': 0.6666666666666667, 'support': 48}, 'Education': {'precision': 0.5, 'recall': 0.2, 'f1-score': 0.28571428571428575, 'support': 10}, 'Election Campaign': {'precision': 0.8333333333333334, 'recall': 0.8333333333333334, 'f1-score': 0.8333333333333334, 'support': 24}, 'Environment': {'precision': 1.0, 'recall': 0.375, 'f1-score': 0.5454545454545454, 'support': 8}, 'Government/Public': {'precision': 0.7906976744186046, 'recall': 0.816, 'f1-score': 0.8031496062992125, 'support': 250}, 'Health': {'precision': 0.803921568627451, 'recall': 0.8367346938775511, 'f1-score': 0.8200000000000001, 'support': 49}, 'Immigration/Integration': {'precision': 0.8648648648648649, 'recall': 0.7111111111111111, 'f1-score': 0.7804878048780488, 'support': 45}, 'Justice/Crime': {'precision': 0.7421875, 'recall': 0.8189655172413793, 'f1-score': 0.7786885245901638, 'support': 116}, 'Labor/Employment': {'precision': 0.9166666666666666, 'recall': 0.4583333333333333, 'f1-score': 0.611111111111111, 'support': 24}, 'Macroeconomics/Economic Regulation': {'precision': 0.8979591836734694, 'recall': 0.7857142857142857, 'f1-score': 0.838095238095238, 'support': 56}, 'Media/Journalism': {'precision': 0.875, 'recall': 0.5384615384615384, 'f1-score': 0.6666666666666667, 'support': 39}, 'Others': {'precision': 0.8102564102564103, 'recall': 0.8404255319148937, 'f1-score': 0.825065274151436, 'support': 188}, 'Religion': {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.875, 'support': 16}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, 'War/Terror': {'precision': 0.945054945054945, 'recall': 0.8686868686868687, 'f1-score': 0.9052631578947369, 'support': 198}, 'micro avg': {'precision': 0.8277886497064579, 'recall': 0.7847866419294991, 'f1-score': 0.8057142857142858, 'support': 1078}, 'macro avg': {'precision': 0.7732354593656993, 'recall': 0.6374621920227308, 'f1-score': 0.682313080990363, 'support': 1078}, 'weighted avg': {'precision': 0.8261886369326729, 'recall': 0.7847866419294991, 'f1-score': 0.7992508141662166, 'support': 1078}, 'samples avg': {'precision': 0.844375, 'recall': 0.8184583333333333, 'f1-score': 0.8152053571428571, 'support': 1078}}, {'Conspiracy Theory': {'precision': 0.7272727272727273, 'recall': 0.43636363636363634, 'f1-score': 0.5454545454545455, 'support': 55}, 'Education': {'precision': 0.6666666666666666, 'recall': 0.7142857142857143, 'f1-score': 0.689655172413793, 'support': 14}, 'Election Campaign': {'precision': 0.782608695652174, 'recall': 0.782608695652174, 'f1-score': 0.782608695652174, 'support': 23}, 'Environment': {'precision': 0.8571428571428571, 'recall': 0.5454545454545454, 'f1-score': 0.6666666666666665, 'support': 11}, 'Government/Public': {'precision': 0.7838827838827839, 'recall': 0.84251968503937, 'f1-score': 0.812144212523719, 'support': 254}, 'Health': {'precision': 0.8461538461538461, 'recall': 0.8461538461538461, 'f1-score': 0.8461538461538461, 'support': 39}, 'Immigration/Integration': {'precision': 1.0, 'recall': 0.5714285714285714, 'f1-score': 0.7272727272727273, 'support': 42}, 'Justice/Crime': {'precision': 0.8108108108108109, 'recall': 0.7258064516129032, 'f1-score': 0.7659574468085107, 'support': 124}, 'Labor/Employment': {'precision': 0.9, 'recall': 0.5, 'f1-score': 0.6428571428571429, 'support': 18}, 'Macroeconomics/Economic Regulation': {'precision': 0.6666666666666666, 'recall': 0.7368421052631579, 'f1-score': 0.7, 'support': 38}, 'Media/Journalism': {'precision': 0.7142857142857143, 'recall': 0.5, 'f1-score': 0.588235294117647, 'support': 30}, 'Others': {'precision': 0.8701923076923077, 'recall': 0.8153153153153153, 'f1-score': 0.841860465116279, 'support': 222}, 'Religion': {'precision': 0.35, 'recall': 0.7777777777777778, 'f1-score': 0.48275862068965514, 'support': 9}, 'Science/Technology': {'precision': 0.3333333333333333, 'recall': 0.16666666666666666, 'f1-score': 0.2222222222222222, 'support': 12}, 'War/Terror': {'precision': 0.9021739130434783, 'recall': 0.9325842696629213, 'f1-score': 0.9171270718232043, 'support': 178}, 'micro avg': {'precision': 0.8139763779527559, 'recall': 0.7736202057998129, 'f1-score': 0.7932853717026378, 'support': 1069}, 'macro avg': {'precision': 0.7474126881735578, 'recall': 0.6595871520451067, 'f1-score': 0.6820649419848087, 'support': 1069}, 'weighted avg': {'precision': 0.8187934761459387, 'recall': 0.7736202057998129, 'f1-score': 0.7883713165257594, 'support': 1069}, 'samples avg': {'precision': 0.8177083333333333, 'recall': 0.7994791666666667, 'f1-score': 0.794375, 'support': 1069}}]\n",
      "5\n",
      "[{'Conspiracy Theory': {'precision': 0.7, 'recall': 0.3111111111111111, 'f1-score': 0.43076923076923074, 'support': 45}, 'Education': {'precision': 0.4666666666666667, 'recall': 0.5384615384615384, 'f1-score': 0.5, 'support': 13}, 'Election Campaign': {'precision': 0.8235294117647058, 'recall': 0.8484848484848485, 'f1-score': 0.8358208955223881, 'support': 33}, 'Environment': {'precision': 0.875, 'recall': 0.5, 'f1-score': 0.6363636363636364, 'support': 14}, 'Government/Public': {'precision': 0.7396825396825397, 'recall': 0.8006872852233677, 'f1-score': 0.768976897689769, 'support': 291}, 'Health': {'precision': 0.7352941176470589, 'recall': 0.5434782608695652, 'f1-score': 0.625, 'support': 46}, 'Immigration/Integration': {'precision': 0.7727272727272727, 'recall': 0.4722222222222222, 'f1-score': 0.5862068965517242, 'support': 36}, 'Justice/Crime': {'precision': 0.7947019867549668, 'recall': 0.8759124087591241, 'f1-score': 0.8333333333333334, 'support': 137}, 'Labor/Employment': {'precision': 0.7, 'recall': 0.5, 'f1-score': 0.5833333333333334, 'support': 28}, 'Macroeconomics/Economic Regulation': {'precision': 0.8333333333333334, 'recall': 0.6451612903225806, 'f1-score': 0.7272727272727272, 'support': 62}, 'Media/Journalism': {'precision': 0.8181818181818182, 'recall': 0.5625, 'f1-score': 0.6666666666666666, 'support': 48}, 'Others': {'precision': 0.8284671532846716, 'recall': 0.8376383763837638, 'f1-score': 0.83302752293578, 'support': 271}, 'Religion': {'precision': 0.6666666666666666, 'recall': 0.5454545454545454, 'f1-score': 0.6, 'support': 11}, 'Science/Technology': {'precision': 0.5, 'recall': 0.36363636363636365, 'f1-score': 0.4210526315789474, 'support': 11}, 'War/Terror': {'precision': 0.9517543859649122, 'recall': 0.8509803921568627, 'f1-score': 0.898550724637681, 'support': 255}, 'micro avg': {'precision': 0.8088597210828548, 'recall': 0.7578785549577248, 'f1-score': 0.7825396825396824, 'support': 1301}, 'macro avg': {'precision': 0.7470670235116408, 'recall': 0.6130485762057263, 'f1-score': 0.6630916331103479, 'support': 1301}, 'weighted avg': {'precision': 0.8096397647592806, 'recall': 0.7578785549577248, 'f1-score': 0.7760990798508935, 'support': 1301}, 'samples avg': {'precision': 0.8225, 'recall': 0.7977333333333333, 'f1-score': 0.7935380952380953, 'support': 1301}}, {'Conspiracy Theory': {'precision': 0.5945945945945946, 'recall': 0.4888888888888889, 'f1-score': 0.5365853658536586, 'support': 45}, 'Education': {'precision': 0.4375, 'recall': 0.5384615384615384, 'f1-score': 0.4827586206896552, 'support': 13}, 'Election Campaign': {'precision': 0.875, 'recall': 0.8484848484848485, 'f1-score': 0.8615384615384615, 'support': 33}, 'Environment': {'precision': 0.8181818181818182, 'recall': 0.6428571428571429, 'f1-score': 0.7200000000000001, 'support': 14}, 'Government/Public': {'precision': 0.7583892617449665, 'recall': 0.7766323024054983, 'f1-score': 0.767402376910017, 'support': 291}, 'Health': {'precision': 0.7073170731707317, 'recall': 0.6304347826086957, 'f1-score': 0.6666666666666667, 'support': 46}, 'Immigration/Integration': {'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'f1-score': 0.7000000000000001, 'support': 36}, 'Justice/Crime': {'precision': 0.7793103448275862, 'recall': 0.8248175182481752, 'f1-score': 0.8014184397163121, 'support': 137}, 'Labor/Employment': {'precision': 0.5625, 'recall': 0.6428571428571429, 'f1-score': 0.6000000000000001, 'support': 28}, 'Macroeconomics/Economic Regulation': {'precision': 0.7868852459016393, 'recall': 0.7741935483870968, 'f1-score': 0.7804878048780488, 'support': 62}, 'Media/Journalism': {'precision': 0.6862745098039216, 'recall': 0.7291666666666666, 'f1-score': 0.7070707070707071, 'support': 48}, 'Others': {'precision': 0.81640625, 'recall': 0.7712177121771218, 'f1-score': 0.7931688804554079, 'support': 271}, 'Religion': {'precision': 0.5, 'recall': 0.6363636363636364, 'f1-score': 0.56, 'support': 11}, 'Science/Technology': {'precision': 0.5, 'recall': 0.45454545454545453, 'f1-score': 0.47619047619047616, 'support': 11}, 'War/Terror': {'precision': 0.9473684210526315, 'recall': 0.9176470588235294, 'f1-score': 0.9322709163346613, 'support': 255}, 'micro avg': {'precision': 0.7861003861003861, 'recall': 0.7824750192159877, 'f1-score': 0.7842835130970724, 'support': 1301}, 'macro avg': {'precision': 0.6937394103761018, 'recall': 0.6969564013035476, 'f1-score': 0.6923705810869382, 'support': 1301}, 'weighted avg': {'precision': 0.7893769206228457, 'recall': 0.7824750192159877, 'f1-score': 0.784868286472289, 'support': 1301}, 'samples avg': {'precision': 0.8025833333333332, 'recall': 0.8094333333333332, 'f1-score': 0.7909380952380952, 'support': 1301}}, {'Conspiracy Theory': {'precision': 0.5, 'recall': 0.4444444444444444, 'f1-score': 0.47058823529411764, 'support': 45}, 'Education': {'precision': 0.5, 'recall': 0.38461538461538464, 'f1-score': 0.4347826086956522, 'support': 13}, 'Election Campaign': {'precision': 0.7894736842105263, 'recall': 0.9090909090909091, 'f1-score': 0.8450704225352113, 'support': 33}, 'Environment': {'precision': 0.7, 'recall': 0.5, 'f1-score': 0.5833333333333334, 'support': 14}, 'Government/Public': {'precision': 0.8146551724137931, 'recall': 0.6494845360824743, 'f1-score': 0.722753346080306, 'support': 291}, 'Health': {'precision': 0.8055555555555556, 'recall': 0.6304347826086957, 'f1-score': 0.7073170731707318, 'support': 46}, 'Immigration/Integration': {'precision': 0.8285714285714286, 'recall': 0.8055555555555556, 'f1-score': 0.8169014084507044, 'support': 36}, 'Justice/Crime': {'precision': 0.8409090909090909, 'recall': 0.8102189781021898, 'f1-score': 0.825278810408922, 'support': 137}, 'Labor/Employment': {'precision': 0.6842105263157895, 'recall': 0.4642857142857143, 'f1-score': 0.5531914893617021, 'support': 28}, 'Macroeconomics/Economic Regulation': {'precision': 0.8125, 'recall': 0.6290322580645161, 'f1-score': 0.7090909090909092, 'support': 62}, 'Media/Journalism': {'precision': 0.68, 'recall': 0.7083333333333334, 'f1-score': 0.6938775510204083, 'support': 48}, 'Others': {'precision': 0.8237410071942446, 'recall': 0.8450184501845018, 'f1-score': 0.8342440801457194, 'support': 271}, 'Religion': {'precision': 0.5, 'recall': 0.36363636363636365, 'f1-score': 0.4210526315789474, 'support': 11}, 'Science/Technology': {'precision': 0.6666666666666666, 'recall': 0.18181818181818182, 'f1-score': 0.28571428571428575, 'support': 11}, 'War/Terror': {'precision': 0.9428571428571428, 'recall': 0.9058823529411765, 'f1-score': 0.9239999999999999, 'support': 255}, 'micro avg': {'precision': 0.8209459459459459, 'recall': 0.7471176018447349, 'f1-score': 0.7822937625754527, 'support': 1301}, 'macro avg': {'precision': 0.7259426849796159, 'recall': 0.615456749650896, 'f1-score': 0.6551464123253967, 'support': 1301}, 'weighted avg': {'precision': 0.8168136599834133, 'recall': 0.7471176018447349, 'f1-score': 0.7766685582179377, 'support': 1301}, 'samples avg': {'precision': 0.8228333333333333, 'recall': 0.7862333333333333, 'f1-score': 0.7882714285714286, 'support': 1301}}, {'Conspiracy Theory': {'precision': 0.5365853658536586, 'recall': 0.4888888888888889, 'f1-score': 0.5116279069767442, 'support': 45}, 'Education': {'precision': 0.42857142857142855, 'recall': 0.46153846153846156, 'f1-score': 0.4444444444444445, 'support': 13}, 'Election Campaign': {'precision': 0.8, 'recall': 0.8484848484848485, 'f1-score': 0.823529411764706, 'support': 33}, 'Environment': {'precision': 0.8333333333333334, 'recall': 0.35714285714285715, 'f1-score': 0.5, 'support': 14}, 'Government/Public': {'precision': 0.7793103448275862, 'recall': 0.7766323024054983, 'f1-score': 0.7779690189328744, 'support': 291}, 'Health': {'precision': 0.7297297297297297, 'recall': 0.5869565217391305, 'f1-score': 0.6506024096385542, 'support': 46}, 'Immigration/Integration': {'precision': 0.8, 'recall': 0.6666666666666666, 'f1-score': 0.7272727272727272, 'support': 36}, 'Justice/Crime': {'precision': 0.782312925170068, 'recall': 0.8394160583941606, 'f1-score': 0.8098591549295774, 'support': 137}, 'Labor/Employment': {'precision': 0.5806451612903226, 'recall': 0.6428571428571429, 'f1-score': 0.6101694915254238, 'support': 28}, 'Macroeconomics/Economic Regulation': {'precision': 0.7213114754098361, 'recall': 0.7096774193548387, 'f1-score': 0.7154471544715446, 'support': 62}, 'Media/Journalism': {'precision': 0.84375, 'recall': 0.5625, 'f1-score': 0.675, 'support': 48}, 'Others': {'precision': 0.7881944444444444, 'recall': 0.8376383763837638, 'f1-score': 0.8121645796064401, 'support': 271}, 'Religion': {'precision': 0.6153846153846154, 'recall': 0.7272727272727273, 'f1-score': 0.6666666666666667, 'support': 11}, 'Science/Technology': {'precision': 1.0, 'recall': 0.36363636363636365, 'f1-score': 0.5333333333333333, 'support': 11}, 'War/Terror': {'precision': 0.9563318777292577, 'recall': 0.8588235294117647, 'f1-score': 0.9049586776859504, 'support': 255}, 'micro avg': {'precision': 0.794912559618442, 'recall': 0.7686395080707148, 'f1-score': 0.7815552950371238, 'support': 1301}, 'macro avg': {'precision': 0.746364046782952, 'recall': 0.6485421442784742, 'f1-score': 0.677536331816599, 'support': 1301}, 'weighted avg': {'precision': 0.8000169987612445, 'recall': 0.7686395080707148, 'f1-score': 0.7796543083498748, 'support': 1301}, 'samples avg': {'precision': 0.8118333333333333, 'recall': 0.7970499999999999, 'f1-score': 0.7901960317460317, 'support': 1301}}, {'Conspiracy Theory': {'precision': 0.6, 'recall': 0.3333333333333333, 'f1-score': 0.42857142857142855, 'support': 45}, 'Education': {'precision': 0.5, 'recall': 0.5384615384615384, 'f1-score': 0.5185185185185186, 'support': 13}, 'Election Campaign': {'precision': 0.8387096774193549, 'recall': 0.7878787878787878, 'f1-score': 0.8125, 'support': 33}, 'Environment': {'precision': 0.8888888888888888, 'recall': 0.5714285714285714, 'f1-score': 0.6956521739130435, 'support': 14}, 'Government/Public': {'precision': 0.7652733118971061, 'recall': 0.8178694158075601, 'f1-score': 0.7906976744186045, 'support': 291}, 'Health': {'precision': 0.7297297297297297, 'recall': 0.5869565217391305, 'f1-score': 0.6506024096385542, 'support': 46}, 'Immigration/Integration': {'precision': 0.8846153846153846, 'recall': 0.6388888888888888, 'f1-score': 0.7419354838709676, 'support': 36}, 'Justice/Crime': {'precision': 0.8384615384615385, 'recall': 0.7956204379562044, 'f1-score': 0.8164794007490638, 'support': 137}, 'Labor/Employment': {'precision': 0.64, 'recall': 0.5714285714285714, 'f1-score': 0.6037735849056605, 'support': 28}, 'Macroeconomics/Economic Regulation': {'precision': 0.8269230769230769, 'recall': 0.6935483870967742, 'f1-score': 0.7543859649122807, 'support': 62}, 'Media/Journalism': {'precision': 0.8611111111111112, 'recall': 0.6458333333333334, 'f1-score': 0.738095238095238, 'support': 48}, 'Others': {'precision': 0.8713692946058091, 'recall': 0.7749077490774908, 'f1-score': 0.8203125, 'support': 271}, 'Religion': {'precision': 0.6428571428571429, 'recall': 0.8181818181818182, 'f1-score': 0.7200000000000001, 'support': 11}, 'Science/Technology': {'precision': 0.4444444444444444, 'recall': 0.36363636363636365, 'f1-score': 0.39999999999999997, 'support': 11}, 'War/Terror': {'precision': 0.9105058365758755, 'recall': 0.9176470588235294, 'f1-score': 0.9140624999999999, 'support': 255}, 'micro avg': {'precision': 0.8216926869350862, 'recall': 0.7686395080707148, 'f1-score': 0.7942811755361397, 'support': 1301}, 'macro avg': {'precision': 0.7495259625019642, 'recall': 0.6570413851381264, 'f1-score': 0.6937057918395574, 'support': 1301}, 'weighted avg': {'precision': 0.8204475776112201, 'recall': 0.7686395080707148, 'f1-score': 0.7901483178423465, 'support': 1301}, 'samples avg': {'precision': 0.8249833333333334, 'recall': 0.8010166666666666, 'f1-score': 0.7992119047619047, 'support': 1301}}]\n",
      "5\n",
      "\n",
      "Average Validation Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.678648  0.441633  0.531006     50.8\n",
      "Education                            0.730556  0.551797  0.617931     12.6\n",
      "Election Campaign                    0.790282  0.805870  0.797836     26.6\n",
      "Environment                          0.946429  0.543831  0.683573     11.6\n",
      "Government/Public                    0.792314  0.819513  0.804142    249.6\n",
      "Health                               0.824919  0.787553  0.804168     42.8\n",
      "Immigration/Integration              0.837266  0.693136  0.748075     40.2\n",
      "Justice/Crime                        0.781330  0.781993  0.780487    114.4\n",
      "Labor/Employment                     0.820856  0.580482  0.667839     19.4\n",
      "Macroeconomics/Economic Regulation   0.763332  0.693483  0.721872     50.0\n",
      "Media/Journalism                     0.754768  0.671311  0.698960     36.8\n",
      "Others                               0.844064  0.813283  0.827806    211.4\n",
      "Religion                             0.632179  0.566140  0.547151     14.2\n",
      "Science/Technology                   0.600000  0.178268  0.255983     10.8\n",
      "War/Terror                           0.924976  0.916146  0.919832    187.8\n",
      "micro avg                            0.818882  0.775858  0.796706   1079.0\n",
      "macro avg                            0.781461  0.656296  0.693777   1079.0\n",
      "weighted avg                         0.819517  0.775858  0.790289   1079.0\n",
      "samples avg                          0.826583  0.804212  0.799916   1079.0\n",
      "\n",
      "Average Test Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.586236  0.413333  0.475628     45.0\n",
      "Education                            0.466548  0.492308  0.476101     13.0\n",
      "Election Campaign                    0.825343  0.848485  0.835692     33.0\n",
      "Environment                          0.823081  0.514286  0.627070     14.0\n",
      "Government/Public                    0.771462  0.764261  0.765560    291.0\n",
      "Health                               0.741525  0.595652  0.660038     46.0\n",
      "Immigration/Integration              0.784456  0.672222  0.714463     36.0\n",
      "Justice/Crime                        0.807139  0.829197  0.817274    137.0\n",
      "Labor/Employment                     0.633471  0.564286  0.590094     28.0\n",
      "Macroeconomics/Economic Regulation   0.796191  0.690323  0.737337     62.0\n",
      "Media/Journalism                     0.777863  0.641667  0.696142     48.0\n",
      "Others                               0.825636  0.813284  0.818584    271.0\n",
      "Religion                             0.584982  0.618182  0.593544     11.0\n",
      "Science/Technology                   0.622222  0.345455  0.423258     11.0\n",
      "War/Terror                           0.941764  0.890196  0.914769    255.0\n",
      "micro avg                            0.806502  0.764950  0.784991   1301.0\n",
      "macro avg                            0.732528  0.646209  0.676370   1301.0\n",
      "weighted avg                         0.807259  0.764950  0.781488   1301.0\n",
      "samples avg                          0.816947  0.798293  0.792431   1301.0\n",
      "../models/GRU_202012_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/GRU_202012_epochs_200_train_size_full_fold_1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/GRU_202012_epochs_200_train_size_full_fold_2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/GRU_202012_epochs_200_train_size_full_fold_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/GRU_202012_epochs_200_train_size_full_fold_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Conspiracy Theory': {'precision': 0.6, 'recall': 0.375, 'f1-score': 0.4615384615384615, 'support': 32}, 'Education': {'precision': 0.8333333333333334, 'recall': 0.5, 'f1-score': 0.625, 'support': 10}, 'Election Campaign': {'precision': 0.8148148148148148, 'recall': 0.7857142857142857, 'f1-score': 0.7999999999999999, 'support': 28}, 'Environment': {'precision': 1.0, 'recall': 0.46153846153846156, 'f1-score': 0.631578947368421, 'support': 13}, 'Government/Public': {'precision': 0.8508064516129032, 'recall': 0.7535714285714286, 'f1-score': 0.7992424242424243, 'support': 280}, 'Health': {'precision': 1.0, 'recall': 0.574468085106383, 'f1-score': 0.7297297297297298, 'support': 47}, 'Immigration/Integration': {'precision': 0.6538461538461539, 'recall': 0.7083333333333334, 'f1-score': 0.68, 'support': 24}, 'Justice/Crime': {'precision': 0.7357142857142858, 'recall': 0.8442622950819673, 'f1-score': 0.7862595419847328, 'support': 122}, 'Labor/Employment': {'precision': 0.6111111111111112, 'recall': 0.55, 'f1-score': 0.5789473684210527, 'support': 20}, 'Macroeconomics/Economic Regulation': {'precision': 0.6666666666666666, 'recall': 0.7241379310344828, 'f1-score': 0.6942148760330579, 'support': 58}, 'Media/Journalism': {'precision': 0.7333333333333333, 'recall': 0.55, 'f1-score': 0.6285714285714286, 'support': 40}, 'Others': {'precision': 0.8194945848375451, 'recall': 0.8470149253731343, 'f1-score': 0.8330275229357798, 'support': 268}, 'Religion': {'precision': 0.5555555555555556, 'recall': 0.4166666666666667, 'f1-score': 0.4761904761904762, 'support': 12}, 'Science/Technology': {'precision': 0.8, 'recall': 0.26666666666666666, 'f1-score': 0.4, 'support': 15}, 'War/Terror': {'precision': 0.8695652173913043, 'recall': 0.6451612903225806, 'f1-score': 0.7407407407407407, 'support': 62}, 'micro avg': {'precision': 0.7953586497890295, 'recall': 0.7313288069835111, 'f1-score': 0.7620010106114199, 'support': 1031}, 'macro avg': {'precision': 0.7696161005478005, 'recall': 0.6001690246272927, 'f1-score': 0.657669434517087, 'support': 1031}, 'weighted avg': {'precision': 0.8016002776458035, 'recall': 0.7313288069835111, 'f1-score': 0.7563884116396992, 'support': 1031}, 'samples avg': {'precision': 0.7840625, 'recall': 0.7545000000000001, 'f1-score': 0.7571190476190476, 'support': 1031}}, {'Conspiracy Theory': {'precision': 0.5, 'recall': 0.08, 'f1-score': 0.13793103448275865, 'support': 25}, 'Education': {'precision': 0.75, 'recall': 0.5454545454545454, 'f1-score': 0.631578947368421, 'support': 11}, 'Election Campaign': {'precision': 0.8611111111111112, 'recall': 0.8378378378378378, 'f1-score': 0.8493150684931507, 'support': 37}, 'Environment': {'precision': 0.75, 'recall': 0.5, 'f1-score': 0.6, 'support': 12}, 'Government/Public': {'precision': 0.8503649635036497, 'recall': 0.7871621621621622, 'f1-score': 0.8175438596491228, 'support': 296}, 'Health': {'precision': 0.9310344827586207, 'recall': 0.7105263157894737, 'f1-score': 0.8059701492537312, 'support': 38}, 'Immigration/Integration': {'precision': 0.7931034482758621, 'recall': 0.6052631578947368, 'f1-score': 0.6865671641791046, 'support': 38}, 'Justice/Crime': {'precision': 0.8378378378378378, 'recall': 0.8211920529801324, 'f1-score': 0.8294314381270902, 'support': 151}, 'Labor/Employment': {'precision': 0.5769230769230769, 'recall': 0.75, 'f1-score': 0.6521739130434783, 'support': 20}, 'Macroeconomics/Economic Regulation': {'precision': 0.851063829787234, 'recall': 0.6779661016949152, 'f1-score': 0.7547169811320754, 'support': 59}, 'Media/Journalism': {'precision': 0.7391304347826086, 'recall': 0.8292682926829268, 'f1-score': 0.7816091954022988, 'support': 41}, 'Others': {'precision': 0.8632478632478633, 'recall': 0.8487394957983193, 'f1-score': 0.8559322033898306, 'support': 238}, 'Religion': {'precision': 0.8461538461538461, 'recall': 0.55, 'f1-score': 0.6666666666666667, 'support': 20}, 'Science/Technology': {'precision': 0.625, 'recall': 0.35714285714285715, 'f1-score': 0.45454545454545453, 'support': 14}, 'War/Terror': {'precision': 0.7931034482758621, 'recall': 0.7540983606557377, 'f1-score': 0.7731092436974789, 'support': 61}, 'micro avg': {'precision': 0.8316115702479339, 'recall': 0.7587181903864278, 'f1-score': 0.7934943321833414, 'support': 1061}, 'macro avg': {'precision': 0.7712049561771717, 'recall': 0.643643412006243, 'f1-score': 0.6864727546287109, 'support': 1061}, 'weighted avg': {'precision': 0.8264946741224378, 'recall': 0.7587181903864278, 'f1-score': 0.7852592879072563, 'support': 1061}, 'samples avg': {'precision': 0.831875, 'recall': 0.79375, 'f1-score': 0.7976666666666666, 'support': 1061}}, {'Conspiracy Theory': {'precision': 0.6111111111111112, 'recall': 0.39285714285714285, 'f1-score': 0.4782608695652174, 'support': 28}, 'Education': {'precision': 0.6666666666666666, 'recall': 0.5454545454545454, 'f1-score': 0.6, 'support': 22}, 'Election Campaign': {'precision': 0.8333333333333334, 'recall': 0.7352941176470589, 'f1-score': 0.78125, 'support': 34}, 'Environment': {'precision': 0.7058823529411765, 'recall': 0.8, 'f1-score': 0.7500000000000001, 'support': 15}, 'Government/Public': {'precision': 0.7854671280276817, 'recall': 0.8438661710037175, 'f1-score': 0.8136200716845879, 'support': 269}, 'Health': {'precision': 0.7575757575757576, 'recall': 0.7142857142857143, 'f1-score': 0.7352941176470589, 'support': 35}, 'Immigration/Integration': {'precision': 0.8064516129032258, 'recall': 0.8064516129032258, 'f1-score': 0.8064516129032258, 'support': 31}, 'Justice/Crime': {'precision': 0.8461538461538461, 'recall': 0.8870967741935484, 'f1-score': 0.8661417322834646, 'support': 124}, 'Labor/Employment': {'precision': 0.7142857142857143, 'recall': 0.5357142857142857, 'f1-score': 0.6122448979591837, 'support': 28}, 'Macroeconomics/Economic Regulation': {'precision': 0.75, 'recall': 0.8636363636363636, 'f1-score': 0.8028169014084506, 'support': 66}, 'Media/Journalism': {'precision': 0.8, 'recall': 0.8888888888888888, 'f1-score': 0.8421052631578948, 'support': 45}, 'Others': {'precision': 0.8945147679324894, 'recall': 0.7794117647058824, 'f1-score': 0.8330058939096266, 'support': 272}, 'Religion': {'precision': 0.5833333333333334, 'recall': 0.7, 'f1-score': 0.6363636363636365, 'support': 10}, 'Science/Technology': {'precision': 0.4, 'recall': 0.8, 'f1-score': 0.5333333333333333, 'support': 5}, 'War/Terror': {'precision': 0.7678571428571429, 'recall': 0.9148936170212766, 'f1-score': 0.8349514563106796, 'support': 47}, 'micro avg': {'precision': 0.8025291828793775, 'recall': 0.8001939864209505, 'f1-score': 0.8013598834385623, 'support': 1031}, 'macro avg': {'precision': 0.7281755178080986, 'recall': 0.7471900665541099, 'f1-score': 0.7283893191017575, 'support': 1031}, 'weighted avg': {'precision': 0.8061676704249852, 'recall': 0.8001939864209505, 'f1-score': 0.7994942838506504, 'support': 1031}, 'samples avg': {'precision': 0.8102083333333334, 'recall': 0.8134375, 'f1-score': 0.7992142857142857, 'support': 1031}}, {'Conspiracy Theory': {'precision': 0.5, 'recall': 0.047619047619047616, 'f1-score': 0.08695652173913042, 'support': 21}, 'Education': {'precision': 0.45454545454545453, 'recall': 0.45454545454545453, 'f1-score': 0.45454545454545453, 'support': 11}, 'Election Campaign': {'precision': 0.7692307692307693, 'recall': 0.9090909090909091, 'f1-score': 0.8333333333333333, 'support': 33}, 'Environment': {'precision': 0.875, 'recall': 0.4666666666666667, 'f1-score': 0.608695652173913, 'support': 15}, 'Government/Public': {'precision': 0.8178694158075601, 'recall': 0.8013468013468014, 'f1-score': 0.8095238095238096, 'support': 297}, 'Health': {'precision': 0.8108108108108109, 'recall': 0.6, 'f1-score': 0.6896551724137931, 'support': 50}, 'Immigration/Integration': {'precision': 0.7352941176470589, 'recall': 0.8928571428571429, 'f1-score': 0.806451612903226, 'support': 28}, 'Justice/Crime': {'precision': 0.8715596330275229, 'recall': 0.7089552238805971, 'f1-score': 0.7818930041152263, 'support': 134}, 'Labor/Employment': {'precision': 0.9230769230769231, 'recall': 0.5714285714285714, 'f1-score': 0.7058823529411765, 'support': 21}, 'Macroeconomics/Economic Regulation': {'precision': 0.7213114754098361, 'recall': 0.7719298245614035, 'f1-score': 0.7457627118644067, 'support': 57}, 'Media/Journalism': {'precision': 0.7272727272727273, 'recall': 0.7058823529411765, 'f1-score': 0.7164179104477613, 'support': 34}, 'Others': {'precision': 0.8137651821862348, 'recall': 0.8072289156626506, 'f1-score': 0.810483870967742, 'support': 249}, 'Religion': {'precision': 0.8181818181818182, 'recall': 0.5, 'f1-score': 0.6206896551724137, 'support': 18}, 'Science/Technology': {'precision': 1.0, 'recall': 0.2857142857142857, 'f1-score': 0.4444444444444445, 'support': 14}, 'War/Terror': {'precision': 0.8035714285714286, 'recall': 0.7258064516129032, 'f1-score': 0.7627118644067797, 'support': 62}, 'micro avg': {'precision': 0.805439330543933, 'recall': 0.7375478927203065, 'f1-score': 0.7699999999999999, 'support': 1044}, 'macro avg': {'precision': 0.7760993170512095, 'recall': 0.6166047765285075, 'f1-score': 0.6584964913995075, 'support': 1044}, 'weighted avg': {'precision': 0.805783019552806, 'recall': 0.7375478927203065, 'f1-score': 0.7604460037585207, 'support': 1044}, 'samples avg': {'precision': 0.8072916666666665, 'recall': 0.7717708333333334, 'f1-score': 0.7732380952380953, 'support': 1044}}, {'Conspiracy Theory': {'precision': 0.5217391304347826, 'recall': 0.375, 'f1-score': 0.43636363636363634, 'support': 32}, 'Education': {'precision': 0.7, 'recall': 0.5384615384615384, 'f1-score': 0.608695652173913, 'support': 13}, 'Election Campaign': {'precision': 0.7352941176470589, 'recall': 0.8333333333333334, 'f1-score': 0.78125, 'support': 30}, 'Environment': {'precision': 0.8181818181818182, 'recall': 0.75, 'f1-score': 0.7826086956521738, 'support': 12}, 'Government/Public': {'precision': 0.7461300309597523, 'recall': 0.8515901060070671, 'f1-score': 0.7953795379537952, 'support': 283}, 'Health': {'precision': 0.8235294117647058, 'recall': 0.8, 'f1-score': 0.8115942028985507, 'support': 35}, 'Immigration/Integration': {'precision': 0.8181818181818182, 'recall': 0.5806451612903226, 'f1-score': 0.679245283018868, 'support': 31}, 'Justice/Crime': {'precision': 0.7544910179640718, 'recall': 0.9130434782608695, 'f1-score': 0.8262295081967213, 'support': 138}, 'Labor/Employment': {'precision': 0.7083333333333334, 'recall': 0.8095238095238095, 'f1-score': 0.7555555555555556, 'support': 21}, 'Macroeconomics/Economic Regulation': {'precision': 0.6538461538461539, 'recall': 0.6538461538461539, 'f1-score': 0.6538461538461539, 'support': 52}, 'Media/Journalism': {'precision': 0.75, 'recall': 0.7857142857142857, 'f1-score': 0.7674418604651163, 'support': 42}, 'Others': {'precision': 0.9203539823008849, 'recall': 0.8156862745098039, 'f1-score': 0.8648648648648649, 'support': 255}, 'Religion': {'precision': 0.5384615384615384, 'recall': 0.5, 'f1-score': 0.5185185185185186, 'support': 14}, 'Science/Technology': {'precision': 1.0, 'recall': 0.16666666666666666, 'f1-score': 0.2857142857142857, 'support': 12}, 'War/Terror': {'precision': 0.7714285714285715, 'recall': 0.782608695652174, 'f1-score': 0.7769784172661871, 'support': 69}, 'micro avg': {'precision': 0.7781990521327015, 'recall': 0.7901828681424446, 'f1-score': 0.78414517669532, 'support': 1039}, 'macro avg': {'precision': 0.7506647283002993, 'recall': 0.6770746335510683, 'f1-score': 0.6896190781658895, 'support': 1039}, 'weighted avg': {'precision': 0.7843760163535304, 'recall': 0.7901828681424446, 'f1-score': 0.7798066152673423, 'support': 1039}, 'samples avg': {'precision': 0.8088541666666668, 'recall': 0.8154166666666666, 'f1-score': 0.7950714285714285, 'support': 1039}}]\n",
      "5\n",
      "[{'Conspiracy Theory': {'precision': 1.0, 'recall': 0.024844720496894408, 'f1-score': 0.04848484848484848, 'support': 161}, 'Education': {'precision': 1.0, 'recall': 0.2222222222222222, 'f1-score': 0.3636363636363636, 'support': 9}, 'Election Campaign': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}, 'Environment': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'Government/Public': {'precision': 0.5915492957746479, 'recall': 0.3684210526315789, 'f1-score': 0.4540540540540541, 'support': 114}, 'Health': {'precision': 0.8571428571428571, 'recall': 0.21818181818181817, 'f1-score': 0.34782608695652173, 'support': 55}, 'Immigration/Integration': {'precision': 0.8260869565217391, 'recall': 0.4470588235294118, 'f1-score': 0.5801526717557252, 'support': 85}, 'Justice/Crime': {'precision': 0.4666666666666667, 'recall': 0.35, 'f1-score': 0.4, 'support': 40}, 'Labor/Employment': {'precision': 0.5, 'recall': 0.06666666666666667, 'f1-score': 0.11764705882352941, 'support': 15}, 'Macroeconomics/Economic Regulation': {'precision': 0.631578947368421, 'recall': 0.6, 'f1-score': 0.6153846153846154, 'support': 20}, 'Media/Journalism': {'precision': 0.8666666666666667, 'recall': 0.43333333333333335, 'f1-score': 0.5777777777777778, 'support': 30}, 'Others': {'precision': 0.6842105263157895, 'recall': 0.8478260869565217, 'f1-score': 0.7572815533980581, 'support': 46}, 'Religion': {'precision': 0.36363636363636365, 'recall': 0.5, 'f1-score': 0.4210526315789474, 'support': 8}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'War/Terror': {'precision': 0.9772727272727273, 'recall': 0.9148936170212766, 'f1-score': 0.945054945054945, 'support': 893}, 'micro avg': {'precision': 0.9007220216606499, 'recall': 0.6697986577181209, 'f1-score': 0.7682832948421863, 'support': 1490}, 'macro avg': {'precision': 0.5843207338243919, 'recall': 0.33289655606931495, 'f1-score': 0.3752235071270258, 'support': 1490}, 'weighted avg': {'precision': 0.8903908955394045, 'recall': 0.6697986577181209, 'f1-score': 0.7119647865028068, 'support': 1490}, 'samples avg': {'precision': 0.9175, 'recall': 0.7714833333333333, 'f1-score': 0.8132952380952381, 'support': 1490}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 161}, 'Education': {'precision': 0.8, 'recall': 0.4444444444444444, 'f1-score': 0.5714285714285714, 'support': 9}, 'Election Campaign': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}, 'Environment': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'Government/Public': {'precision': 0.5606060606060606, 'recall': 0.32456140350877194, 'f1-score': 0.4111111111111111, 'support': 114}, 'Health': {'precision': 0.9166666666666666, 'recall': 0.2, 'f1-score': 0.3283582089552239, 'support': 55}, 'Immigration/Integration': {'precision': 0.9302325581395349, 'recall': 0.47058823529411764, 'f1-score': 0.625, 'support': 85}, 'Justice/Crime': {'precision': 0.5454545454545454, 'recall': 0.3, 'f1-score': 0.3870967741935483, 'support': 40}, 'Labor/Employment': {'precision': 0.5714285714285714, 'recall': 0.26666666666666666, 'f1-score': 0.36363636363636365, 'support': 15}, 'Macroeconomics/Economic Regulation': {'precision': 0.8125, 'recall': 0.65, 'f1-score': 0.7222222222222223, 'support': 20}, 'Media/Journalism': {'precision': 0.6666666666666666, 'recall': 0.4666666666666667, 'f1-score': 0.5490196078431373, 'support': 30}, 'Others': {'precision': 0.6862745098039216, 'recall': 0.7608695652173914, 'f1-score': 0.7216494845360826, 'support': 46}, 'Religion': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 8}, 'Science/Technology': {'precision': 0.3333333333333333, 'recall': 0.2, 'f1-score': 0.25, 'support': 5}, 'War/Terror': {'precision': 0.9715302491103203, 'recall': 0.9171332586786114, 'f1-score': 0.9435483870967742, 'support': 893}, 'micro avg': {'precision': 0.9075937785910339, 'recall': 0.6657718120805369, 'f1-score': 0.7680991095625243, 'support': 1490}, 'macro avg': {'precision': 0.5863128774139746, 'recall': 0.35006201603177806, 'f1-score': 0.41820471540153564, 'support': 1490}, 'weighted avg': {'precision': 0.7892932496512695, 'recall': 0.6657718120805369, 'f1-score': 0.7082431277652123, 'support': 1490}, 'samples avg': {'precision': 0.9213333333333332, 'recall': 0.77165, 'f1-score': 0.8148714285714285, 'support': 1490}}, {'Conspiracy Theory': {'precision': 0.75, 'recall': 0.018633540372670808, 'f1-score': 0.03636363636363636, 'support': 161}, 'Education': {'precision': 0.5833333333333334, 'recall': 0.7777777777777778, 'f1-score': 0.6666666666666666, 'support': 9}, 'Election Campaign': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}, 'Environment': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'Government/Public': {'precision': 0.48148148148148145, 'recall': 0.45614035087719296, 'f1-score': 0.46846846846846846, 'support': 114}, 'Health': {'precision': 0.8125, 'recall': 0.4727272727272727, 'f1-score': 0.5977011494252874, 'support': 55}, 'Immigration/Integration': {'precision': 0.926829268292683, 'recall': 0.4470588235294118, 'f1-score': 0.6031746031746031, 'support': 85}, 'Justice/Crime': {'precision': 0.5714285714285714, 'recall': 0.4, 'f1-score': 0.47058823529411764, 'support': 40}, 'Labor/Employment': {'precision': 1.0, 'recall': 0.13333333333333333, 'f1-score': 0.23529411764705882, 'support': 15}, 'Macroeconomics/Economic Regulation': {'precision': 0.6666666666666666, 'recall': 0.7, 'f1-score': 0.6829268292682926, 'support': 20}, 'Media/Journalism': {'precision': 0.7777777777777778, 'recall': 0.4666666666666667, 'f1-score': 0.5833333333333334, 'support': 30}, 'Others': {'precision': 0.76, 'recall': 0.8260869565217391, 'f1-score': 0.7916666666666667, 'support': 46}, 'Religion': {'precision': 0.3076923076923077, 'recall': 0.5, 'f1-score': 0.380952380952381, 'support': 8}, 'Science/Technology': {'precision': 0.3333333333333333, 'recall': 0.2, 'f1-score': 0.25, 'support': 5}, 'War/Terror': {'precision': 0.9737470167064439, 'recall': 0.9137737961926092, 'f1-score': 0.9428076256499133, 'support': 893}, 'micro avg': {'precision': 0.8804440649017934, 'recall': 0.6919463087248322, 'f1-score': 0.7748966553927095, 'support': 1490}, 'macro avg': {'precision': 0.5963193171141732, 'recall': 0.42081323453324504, 'f1-score': 0.4473295808606951, 'support': 1490}, 'weighted avg': {'precision': 0.8641107229964001, 'recall': 0.6919463087248322, 'f1-score': 0.7285612943152199, 'support': 1490}, 'samples avg': {'precision': 0.9049166666666666, 'recall': 0.7859833333333334, 'f1-score': 0.8170238095238094, 'support': 1490}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 161}, 'Education': {'precision': 1.0, 'recall': 0.4444444444444444, 'f1-score': 0.6153846153846153, 'support': 9}, 'Election Campaign': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}, 'Environment': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'Government/Public': {'precision': 0.5714285714285714, 'recall': 0.42105263157894735, 'f1-score': 0.48484848484848486, 'support': 114}, 'Health': {'precision': 0.9090909090909091, 'recall': 0.18181818181818182, 'f1-score': 0.30303030303030304, 'support': 55}, 'Immigration/Integration': {'precision': 0.8723404255319149, 'recall': 0.4823529411764706, 'f1-score': 0.6212121212121212, 'support': 85}, 'Justice/Crime': {'precision': 0.8571428571428571, 'recall': 0.15, 'f1-score': 0.2553191489361702, 'support': 40}, 'Labor/Employment': {'precision': 1.0, 'recall': 0.06666666666666667, 'f1-score': 0.125, 'support': 15}, 'Macroeconomics/Economic Regulation': {'precision': 0.9090909090909091, 'recall': 0.5, 'f1-score': 0.6451612903225806, 'support': 20}, 'Media/Journalism': {'precision': 0.7333333333333333, 'recall': 0.36666666666666664, 'f1-score': 0.4888888888888889, 'support': 30}, 'Others': {'precision': 0.775, 'recall': 0.6739130434782609, 'f1-score': 0.7209302325581396, 'support': 46}, 'Religion': {'precision': 0.6666666666666666, 'recall': 0.25, 'f1-score': 0.36363636363636365, 'support': 8}, 'Science/Technology': {'precision': 1.0, 'recall': 0.2, 'f1-score': 0.33333333333333337, 'support': 5}, 'War/Terror': {'precision': 0.9598623853211009, 'recall': 0.9372900335946248, 'f1-score': 0.948441926345609, 'support': 893}, 'micro avg': {'precision': 0.912568306010929, 'recall': 0.6724832214765101, 'f1-score': 0.7743431221020093, 'support': 1490}, 'macro avg': {'precision': 0.6835970705070841, 'recall': 0.3116136406282842, 'f1-score': 0.39367911389977395, 'support': 1490}, 'weighted avg': {'precision': 0.7992615900709253, 'recall': 0.6724832214765101, 'f1-score': 0.7078092165849073, 'support': 1490}, 'samples avg': {'precision': 0.9265, 'recall': 0.7729833333333332, 'f1-score': 0.8189714285714286, 'support': 1490}}, {'Conspiracy Theory': {'precision': 0.64, 'recall': 0.09937888198757763, 'f1-score': 0.17204301075268819, 'support': 161}, 'Education': {'precision': 0.6, 'recall': 0.6666666666666666, 'f1-score': 0.631578947368421, 'support': 9}, 'Election Campaign': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}, 'Environment': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'Government/Public': {'precision': 0.3574660633484163, 'recall': 0.6929824561403509, 'f1-score': 0.47164179104477616, 'support': 114}, 'Health': {'precision': 0.8571428571428571, 'recall': 0.43636363636363634, 'f1-score': 0.5783132530120482, 'support': 55}, 'Immigration/Integration': {'precision': 0.8780487804878049, 'recall': 0.4235294117647059, 'f1-score': 0.5714285714285715, 'support': 85}, 'Justice/Crime': {'precision': 0.2972972972972973, 'recall': 0.55, 'f1-score': 0.38596491228070173, 'support': 40}, 'Labor/Employment': {'precision': 1.0, 'recall': 0.06666666666666667, 'f1-score': 0.125, 'support': 15}, 'Macroeconomics/Economic Regulation': {'precision': 0.7142857142857143, 'recall': 0.75, 'f1-score': 0.7317073170731706, 'support': 20}, 'Media/Journalism': {'precision': 0.7894736842105263, 'recall': 0.5, 'f1-score': 0.6122448979591837, 'support': 30}, 'Others': {'precision': 0.7391304347826086, 'recall': 0.7391304347826086, 'f1-score': 0.7391304347826085, 'support': 46}, 'Religion': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 8}, 'Science/Technology': {'precision': 0.5, 'recall': 0.2, 'f1-score': 0.28571428571428575, 'support': 5}, 'War/Terror': {'precision': 0.9625850340136054, 'recall': 0.9507278835386338, 'f1-score': 0.9566197183098591, 'support': 893}, 'micro avg': {'precision': 0.8017492711370262, 'recall': 0.738255033557047, 'f1-score': 0.7686932215234101, 'support': 1490}, 'macro avg': {'precision': 0.622361991037922, 'recall': 0.4216964025273898, 'f1-score': 0.44409247598175433, 'support': 1490}, 'weighted avg': {'precision': 0.8321599911302763, 'recall': 0.738255033557047, 'f1-score': 0.7454590782378772, 'support': 1490}, 'samples avg': {'precision': 0.8603500000000001, 'recall': 0.8184833333333333, 'f1-score': 0.8143190476190475, 'support': 1490}}]\n",
      "5\n",
      "\n",
      "Average Validation Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.546570  0.254095  0.320210     27.6\n",
      "Education                            0.680909  0.516783  0.583964     13.4\n",
      "Election Campaign                    0.802757  0.820254  0.809030     32.4\n",
      "Environment                          0.829813  0.595641  0.674577     13.4\n",
      "Government/Public                    0.810128  0.807507  0.807062    285.0\n",
      "Health                               0.864590  0.679856  0.754449     41.0\n",
      "Immigration/Integration              0.761375  0.718710  0.731743     30.4\n",
      "Justice/Crime                        0.809151  0.834910  0.817991    133.8\n",
      "Labor/Employment                     0.706746  0.643333  0.660961     22.0\n",
      "Macroeconomics/Economic Regulation   0.728578  0.738303  0.730272     58.4\n",
      "Media/Journalism                     0.749947  0.751951  0.747229     40.4\n",
      "Others                               0.862275  0.819616  0.839463    256.4\n",
      "Religion                             0.668337  0.533333  0.583686     14.8\n",
      "Science/Technology                   0.765000  0.375238  0.423608     12.0\n",
      "War/Terror                           0.801105  0.764514  0.777698     60.2\n",
      "micro avg                            0.802628  0.763594  0.782200   1041.2\n",
      "macro avg                            0.759152  0.656936  0.684129   1041.2\n",
      "weighted avg                         0.804884  0.763594  0.776279   1041.2\n",
      "samples avg                          0.808458  0.789775  0.784462   1041.2\n",
      "\n",
      "Average Test Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.478000  0.028571  0.051378    161.0\n",
      "Education                            0.796667  0.511111  0.569739      9.0\n",
      "Election Campaign                    0.000000  0.000000  0.000000      4.0\n",
      "Environment                          0.000000  0.000000  0.000000      5.0\n",
      "Government/Public                    0.512506  0.452632  0.458025    114.0\n",
      "Health                               0.870509  0.301818  0.431046     55.0\n",
      "Immigration/Integration              0.886708  0.454118  0.600194     85.0\n",
      "Justice/Crime                        0.547598  0.350000  0.379794     40.0\n",
      "Labor/Employment                     0.814286  0.120000  0.193316     15.0\n",
      "Macroeconomics/Economic Regulation   0.746824  0.640000  0.679480     20.0\n",
      "Media/Journalism                     0.766784  0.446667  0.562253     30.0\n",
      "Others                               0.728923  0.769565  0.746132     46.0\n",
      "Religion                             0.667599  0.350000  0.393128      8.0\n",
      "Science/Technology                   0.433333  0.160000  0.223810      5.0\n",
      "War/Terror                           0.968999  0.926764  0.947295    893.0\n",
      "micro avg                            0.880615  0.687651  0.770863   1490.0\n",
      "macro avg                            0.614582  0.367416  0.415706   1490.0\n",
      "weighted avg                         0.835043  0.687651  0.720408   1490.0\n",
      "samples avg                          0.906120  0.784117  0.815696   1490.0\n",
      "../models/IRA_202012_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/IRA_202012_epochs_200_train_size_full_fold_1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/IRA_202012_epochs_200_train_size_full_fold_2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/IRA_202012_epochs_200_train_size_full_fold_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/IRA_202012_epochs_200_train_size_full_fold_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Conspiracy Theory': {'precision': 0.8, 'recall': 0.4528301886792453, 'f1-score': 0.5783132530120482, 'support': 53}, 'Education': {'precision': 0.7272727272727273, 'recall': 0.4444444444444444, 'f1-score': 0.5517241379310345, 'support': 18}, 'Election Campaign': {'precision': 0.875, 'recall': 0.84, 'f1-score': 0.8571428571428572, 'support': 25}, 'Environment': {'precision': 1.0, 'recall': 0.29411764705882354, 'f1-score': 0.45454545454545453, 'support': 17}, 'Government/Public': {'precision': 0.7777777777777778, 'recall': 0.8064516129032258, 'f1-score': 0.7918552036199094, 'support': 217}, 'Health': {'precision': 0.8235294117647058, 'recall': 0.7368421052631579, 'f1-score': 0.7777777777777778, 'support': 38}, 'Immigration/Integration': {'precision': 0.7419354838709677, 'recall': 0.6388888888888888, 'f1-score': 0.6865671641791045, 'support': 36}, 'Justice/Crime': {'precision': 0.8888888888888888, 'recall': 0.8135593220338984, 'f1-score': 0.8495575221238938, 'support': 118}, 'Labor/Employment': {'precision': 0.3333333333333333, 'recall': 0.2, 'f1-score': 0.25, 'support': 10}, 'Macroeconomics/Economic Regulation': {'precision': 0.6363636363636364, 'recall': 0.6363636363636364, 'f1-score': 0.6363636363636364, 'support': 22}, 'Media/Journalism': {'precision': 0.8333333333333334, 'recall': 0.625, 'f1-score': 0.7142857142857143, 'support': 24}, 'Others': {'precision': 0.8888888888888888, 'recall': 0.7634854771784232, 'f1-score': 0.8214285714285714, 'support': 241}, 'Religion': {'precision': 0.46153846153846156, 'recall': 0.6, 'f1-score': 0.5217391304347826, 'support': 10}, 'Science/Technology': {'precision': 1.0, 'recall': 0.4666666666666667, 'f1-score': 0.6363636363636364, 'support': 15}, 'War/Terror': {'precision': 0.9302325581395349, 'recall': 0.9803921568627451, 'f1-score': 0.9546539379474941, 'support': 204}, 'micro avg': {'precision': 0.8451882845188284, 'recall': 0.7709923664122137, 'f1-score': 0.8063872255489022, 'support': 1048}, 'macro avg': {'precision': 0.7812063000781504, 'recall': 0.6199361430895436, 'f1-score': 0.6721545331437276, 'support': 1048}, 'weighted avg': {'precision': 0.8463499550146896, 'recall': 0.7709923664122137, 'f1-score': 0.7988637532047886, 'support': 1048}, 'samples avg': {'precision': 0.8310416666666666, 'recall': 0.7985416666666667, 'f1-score': 0.8012797619047619, 'support': 1048}}, {'Conspiracy Theory': {'precision': 0.875, 'recall': 0.45652173913043476, 'f1-score': 0.6, 'support': 46}, 'Education': {'precision': 0.6666666666666666, 'recall': 0.3076923076923077, 'f1-score': 0.42105263157894735, 'support': 13}, 'Election Campaign': {'precision': 0.7586206896551724, 'recall': 0.8461538461538461, 'f1-score': 0.8, 'support': 26}, 'Environment': {'precision': 0.7, 'recall': 0.7, 'f1-score': 0.7, 'support': 10}, 'Government/Public': {'precision': 0.7668161434977578, 'recall': 0.7808219178082192, 'f1-score': 0.7737556561085973, 'support': 219}, 'Health': {'precision': 0.7906976744186046, 'recall': 0.8717948717948718, 'f1-score': 0.8292682926829267, 'support': 39}, 'Immigration/Integration': {'precision': 0.7222222222222222, 'recall': 0.8666666666666667, 'f1-score': 0.7878787878787877, 'support': 45}, 'Justice/Crime': {'precision': 0.7588652482269503, 'recall': 0.9067796610169492, 'f1-score': 0.8262548262548263, 'support': 118}, 'Labor/Employment': {'precision': 0.6923076923076923, 'recall': 0.5294117647058824, 'f1-score': 0.5999999999999999, 'support': 17}, 'Macroeconomics/Economic Regulation': {'precision': 0.47368421052631576, 'recall': 0.391304347826087, 'f1-score': 0.42857142857142855, 'support': 23}, 'Media/Journalism': {'precision': 0.7647058823529411, 'recall': 0.7222222222222222, 'f1-score': 0.7428571428571428, 'support': 18}, 'Others': {'precision': 0.8722466960352423, 'recall': 0.8081632653061225, 'f1-score': 0.8389830508474577, 'support': 245}, 'Religion': {'precision': 0.5454545454545454, 'recall': 0.3, 'f1-score': 0.3870967741935483, 'support': 20}, 'Science/Technology': {'precision': 0.6428571428571429, 'recall': 0.6428571428571429, 'f1-score': 0.6428571428571429, 'support': 14}, 'War/Terror': {'precision': 0.9395604395604396, 'recall': 0.9344262295081968, 'f1-score': 0.9369863013698629, 'support': 183}, 'micro avg': {'precision': 0.8094768015794669, 'recall': 0.7915057915057915, 'f1-score': 0.8003904343582235, 'support': 1036}, 'macro avg': {'precision': 0.7313136835854461, 'recall': 0.6709877321792633, 'f1-score': 0.6877041356800446, 'support': 1036}, 'weighted avg': {'precision': 0.8092998204515353, 'recall': 0.7915057915057915, 'f1-score': 0.7942182420717304, 'support': 1036}, 'samples avg': {'precision': 0.8227083333333334, 'recall': 0.815, 'f1-score': 0.804672619047619, 'support': 1036}}, {'Conspiracy Theory': {'precision': 0.6530612244897959, 'recall': 0.6037735849056604, 'f1-score': 0.6274509803921567, 'support': 53}, 'Education': {'precision': 0.6, 'recall': 0.5, 'f1-score': 0.5454545454545454, 'support': 12}, 'Election Campaign': {'precision': 0.7058823529411765, 'recall': 0.75, 'f1-score': 0.7272727272727272, 'support': 16}, 'Environment': {'precision': 0.8, 'recall': 0.6666666666666666, 'f1-score': 0.7272727272727272, 'support': 6}, 'Government/Public': {'precision': 0.7608695652173914, 'recall': 0.8254716981132075, 'f1-score': 0.7918552036199095, 'support': 212}, 'Health': {'precision': 0.9032258064516129, 'recall': 0.717948717948718, 'f1-score': 0.8, 'support': 39}, 'Immigration/Integration': {'precision': 0.8297872340425532, 'recall': 0.8478260869565217, 'f1-score': 0.8387096774193549, 'support': 46}, 'Justice/Crime': {'precision': 0.8157894736842105, 'recall': 0.775, 'f1-score': 0.7948717948717949, 'support': 120}, 'Labor/Employment': {'precision': 0.8888888888888888, 'recall': 0.38095238095238093, 'f1-score': 0.5333333333333333, 'support': 21}, 'Macroeconomics/Economic Regulation': {'precision': 0.7647058823529411, 'recall': 0.4642857142857143, 'f1-score': 0.5777777777777777, 'support': 28}, 'Media/Journalism': {'precision': 0.875, 'recall': 0.4827586206896552, 'f1-score': 0.6222222222222222, 'support': 29}, 'Others': {'precision': 0.9178082191780822, 'recall': 0.8553191489361702, 'f1-score': 0.8854625550660793, 'support': 235}, 'Religion': {'precision': 0.7777777777777778, 'recall': 0.5833333333333334, 'f1-score': 0.6666666666666666, 'support': 12}, 'Science/Technology': {'precision': 0.8, 'recall': 0.4444444444444444, 'f1-score': 0.5714285714285714, 'support': 9}, 'War/Terror': {'precision': 0.9330143540669856, 'recall': 0.9798994974874372, 'f1-score': 0.9558823529411765, 'support': 199}, 'micro avg': {'precision': 0.8419452887537994, 'recall': 0.8013500482160077, 'f1-score': 0.8211462450592886, 'support': 1037}, 'macro avg': {'precision': 0.8017207186060946, 'recall': 0.6585119929813275, 'f1-score': 0.711044075715936, 'support': 1037}, 'weighted avg': {'precision': 0.8426644350075627, 'recall': 0.8013500482160077, 'f1-score': 0.8155335470207016, 'support': 1037}, 'samples avg': {'precision': 0.8485416666666667, 'recall': 0.8325, 'f1-score': 0.8251845238095237, 'support': 1037}}, {'Conspiracy Theory': {'precision': 0.7142857142857143, 'recall': 0.603448275862069, 'f1-score': 0.6542056074766354, 'support': 58}, 'Education': {'precision': 0.7777777777777778, 'recall': 0.5833333333333334, 'f1-score': 0.6666666666666666, 'support': 12}, 'Election Campaign': {'precision': 0.6363636363636364, 'recall': 0.875, 'f1-score': 0.7368421052631579, 'support': 24}, 'Environment': {'precision': 0.75, 'recall': 0.2727272727272727, 'f1-score': 0.39999999999999997, 'support': 11}, 'Government/Public': {'precision': 0.7980295566502463, 'recall': 0.7641509433962265, 'f1-score': 0.7807228915662651, 'support': 212}, 'Health': {'precision': 0.8095238095238095, 'recall': 0.7391304347826086, 'f1-score': 0.7727272727272727, 'support': 46}, 'Immigration/Integration': {'precision': 0.725, 'recall': 0.7073170731707317, 'f1-score': 0.7160493827160495, 'support': 41}, 'Justice/Crime': {'precision': 0.8861788617886179, 'recall': 0.7956204379562044, 'f1-score': 0.8384615384615385, 'support': 137}, 'Labor/Employment': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'Macroeconomics/Economic Regulation': {'precision': 0.8421052631578947, 'recall': 0.7272727272727273, 'f1-score': 0.7804878048780488, 'support': 22}, 'Media/Journalism': {'precision': 0.85, 'recall': 0.68, 'f1-score': 0.7555555555555556, 'support': 25}, 'Others': {'precision': 0.8392857142857143, 'recall': 0.8785046728971962, 'f1-score': 0.8584474885844748, 'support': 214}, 'Religion': {'precision': 0.7, 'recall': 0.5833333333333334, 'f1-score': 0.6363636363636365, 'support': 12}, 'Science/Technology': {'precision': 1.0, 'recall': 0.16666666666666666, 'f1-score': 0.2857142857142857, 'support': 6}, 'War/Terror': {'precision': 0.9392523364485982, 'recall': 0.9348837209302325, 'f1-score': 0.9370629370629371, 'support': 215}, 'micro avg': {'precision': 0.8346613545816733, 'recall': 0.799618320610687, 'f1-score': 0.8167641325536062, 'support': 1048}, 'macro avg': {'precision': 0.7922124857111082, 'recall': 0.6617849005142145, 'f1-score': 0.695646119228076, 'support': 1048}, 'weighted avg': {'precision': 0.8354572598575241, 'recall': 0.799618320610687, 'f1-score': 0.8128823117848439, 'support': 1048}, 'samples avg': {'precision': 0.8490416666666667, 'recall': 0.8286458333333334, 'f1-score': 0.8230714285714285, 'support': 1048}}, {'Conspiracy Theory': {'precision': 0.8461538461538461, 'recall': 0.4, 'f1-score': 0.5432098765432098, 'support': 55}, 'Education': {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 8}, 'Election Campaign': {'precision': 0.896551724137931, 'recall': 0.8125, 'f1-score': 0.8524590163934426, 'support': 32}, 'Environment': {'precision': 0.7142857142857143, 'recall': 0.4166666666666667, 'f1-score': 0.5263157894736842, 'support': 12}, 'Government/Public': {'precision': 0.7886792452830189, 'recall': 0.8744769874476988, 'f1-score': 0.8293650793650794, 'support': 239}, 'Health': {'precision': 0.7346938775510204, 'recall': 0.8181818181818182, 'f1-score': 0.7741935483870968, 'support': 44}, 'Immigration/Integration': {'precision': 0.8484848484848485, 'recall': 0.9032258064516129, 'f1-score': 0.875, 'support': 31}, 'Justice/Crime': {'precision': 0.8666666666666667, 'recall': 0.8297872340425532, 'f1-score': 0.8478260869565217, 'support': 141}, 'Labor/Employment': {'precision': 0.6666666666666666, 'recall': 0.4, 'f1-score': 0.5, 'support': 15}, 'Macroeconomics/Economic Regulation': {'precision': 0.75, 'recall': 0.5, 'f1-score': 0.6, 'support': 30}, 'Media/Journalism': {'precision': 0.9047619047619048, 'recall': 0.5428571428571428, 'f1-score': 0.6785714285714285, 'support': 35}, 'Others': {'precision': 0.815668202764977, 'recall': 0.8309859154929577, 'f1-score': 0.8232558139534883, 'support': 213}, 'Religion': {'precision': 0.8, 'recall': 0.6153846153846154, 'f1-score': 0.6956521739130435, 'support': 13}, 'Science/Technology': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1-score': 0.4, 'support': 12}, 'War/Terror': {'precision': 0.9180327868852459, 'recall': 0.9545454545454546, 'f1-score': 0.935933147632312, 'support': 176}, 'micro avg': {'precision': 0.8294117647058824, 'recall': 0.8011363636363636, 'f1-score': 0.8150289017341041, 'support': 1056}, 'macro avg': {'precision': 0.7867096989094561, 'recall': 0.6654629982935902, 'f1-score': 0.7087854640792871, 'support': 1056}, 'weighted avg': {'precision': 0.8285996308405593, 'recall': 0.8011363636363636, 'f1-score': 0.8064332104001479, 'support': 1056}, 'samples avg': {'precision': 0.8473958333333332, 'recall': 0.8341249999999999, 'f1-score': 0.8263492063492063, 'support': 1056}}]\n",
      "5\n",
      "[{'Conspiracy Theory': {'precision': 0.16393442622950818, 'recall': 0.29411764705882354, 'f1-score': 0.21052631578947367, 'support': 34}, 'Education': {'precision': 0.875, 'recall': 0.5384615384615384, 'f1-score': 0.6666666666666667, 'support': 13}, 'Election Campaign': {'precision': 0.673469387755102, 'recall': 0.7674418604651163, 'f1-score': 0.7173913043478259, 'support': 43}, 'Environment': {'precision': 0.875, 'recall': 0.4375, 'f1-score': 0.5833333333333334, 'support': 16}, 'Government/Public': {'precision': 0.775, 'recall': 0.634090909090909, 'f1-score': 0.6974999999999999, 'support': 440}, 'Health': {'precision': 0.8780487804878049, 'recall': 0.6666666666666666, 'f1-score': 0.7578947368421053, 'support': 54}, 'Immigration/Integration': {'precision': 0.6428571428571429, 'recall': 0.7105263157894737, 'f1-score': 0.6749999999999999, 'support': 38}, 'Justice/Crime': {'precision': 0.6271186440677966, 'recall': 0.49333333333333335, 'f1-score': 0.5522388059701493, 'support': 75}, 'Labor/Employment': {'precision': 0.8333333333333334, 'recall': 0.7142857142857143, 'f1-score': 0.7692307692307692, 'support': 49}, 'Macroeconomics/Economic Regulation': {'precision': 0.7793103448275862, 'recall': 0.6042780748663101, 'f1-score': 0.6807228915662651, 'support': 187}, 'Media/Journalism': {'precision': 0.7931034482758621, 'recall': 0.22772277227722773, 'f1-score': 0.35384615384615387, 'support': 101}, 'Others': {'precision': 0.7213114754098361, 'recall': 0.4888888888888889, 'f1-score': 0.5827814569536424, 'support': 180}, 'Religion': {'precision': 0.7, 'recall': 0.4666666666666667, 'f1-score': 0.56, 'support': 15}, 'Science/Technology': {'precision': 0.2, 'recall': 0.2222222222222222, 'f1-score': 0.2105263157894737, 'support': 9}, 'War/Terror': {'precision': 0.640926640926641, 'recall': 0.7649769585253456, 'f1-score': 0.6974789915966386, 'support': 217}, 'micro avg': {'precision': 0.6987951807228916, 'recall': 0.5914343983684568, 'f1-score': 0.6406480117820325, 'support': 1471}, 'macro avg': {'precision': 0.6785609082780408, 'recall': 0.5354119712398825, 'f1-score': 0.5810091827954997, 'support': 1471}, 'weighted avg': {'precision': 0.725812386670344, 'recall': 0.5914343983684568, 'f1-score': 0.6377799029809149, 'support': 1471}, 'samples avg': {'precision': 0.67375, 'recall': 0.6225333333333333, 'f1-score': 0.6223666666666666, 'support': 1471}}, {'Conspiracy Theory': {'precision': 0.24, 'recall': 0.35294117647058826, 'f1-score': 0.28571428571428564, 'support': 34}, 'Education': {'precision': 0.7142857142857143, 'recall': 0.38461538461538464, 'f1-score': 0.5, 'support': 13}, 'Election Campaign': {'precision': 0.7083333333333334, 'recall': 0.7906976744186046, 'f1-score': 0.7472527472527473, 'support': 43}, 'Environment': {'precision': 0.631578947368421, 'recall': 0.75, 'f1-score': 0.6857142857142857, 'support': 16}, 'Government/Public': {'precision': 0.7307692307692307, 'recall': 0.7340909090909091, 'f1-score': 0.7324263038548753, 'support': 440}, 'Health': {'precision': 0.8478260869565217, 'recall': 0.7222222222222222, 'f1-score': 0.78, 'support': 54}, 'Immigration/Integration': {'precision': 0.5294117647058824, 'recall': 0.7105263157894737, 'f1-score': 0.6067415730337078, 'support': 38}, 'Justice/Crime': {'precision': 0.5051546391752577, 'recall': 0.6533333333333333, 'f1-score': 0.5697674418604651, 'support': 75}, 'Labor/Employment': {'precision': 0.7391304347826086, 'recall': 0.6938775510204082, 'f1-score': 0.7157894736842104, 'support': 49}, 'Macroeconomics/Economic Regulation': {'precision': 0.8785046728971962, 'recall': 0.5026737967914439, 'f1-score': 0.6394557823129251, 'support': 187}, 'Media/Journalism': {'precision': 0.6764705882352942, 'recall': 0.22772277227722773, 'f1-score': 0.34074074074074073, 'support': 101}, 'Others': {'precision': 0.5911602209944752, 'recall': 0.5944444444444444, 'f1-score': 0.5927977839335181, 'support': 180}, 'Religion': {'precision': 0.5555555555555556, 'recall': 0.3333333333333333, 'f1-score': 0.4166666666666667, 'support': 15}, 'Science/Technology': {'precision': 0.14814814814814814, 'recall': 0.4444444444444444, 'f1-score': 0.2222222222222222, 'support': 9}, 'War/Terror': {'precision': 0.6941747572815534, 'recall': 0.6589861751152074, 'f1-score': 0.6761229314420805, 'support': 217}, 'micro avg': {'precision': 0.6649635036496351, 'recall': 0.619306594153637, 'f1-score': 0.6413234776487153, 'support': 1471}, 'macro avg': {'precision': 0.6127002729659462, 'recall': 0.5702606355578017, 'f1-score': 0.5674274825621821, 'support': 1471}, 'weighted avg': {'precision': 0.6926358595048822, 'recall': 0.619306594153637, 'f1-score': 0.6391794028398138, 'support': 1471}, 'samples avg': {'precision': 0.66725, 'recall': 0.6424833333333333, 'f1-score': 0.6303238095238096, 'support': 1471}}, {'Conspiracy Theory': {'precision': 0.1366906474820144, 'recall': 0.5588235294117647, 'f1-score': 0.21965317919075145, 'support': 34}, 'Education': {'precision': 0.6666666666666666, 'recall': 0.46153846153846156, 'f1-score': 0.5454545454545455, 'support': 13}, 'Election Campaign': {'precision': 0.6346153846153846, 'recall': 0.7674418604651163, 'f1-score': 0.6947368421052632, 'support': 43}, 'Environment': {'precision': 0.8888888888888888, 'recall': 0.5, 'f1-score': 0.64, 'support': 16}, 'Government/Public': {'precision': 0.6909448818897638, 'recall': 0.7977272727272727, 'f1-score': 0.740506329113924, 'support': 440}, 'Health': {'precision': 0.9285714285714286, 'recall': 0.7222222222222222, 'f1-score': 0.8125000000000001, 'support': 54}, 'Immigration/Integration': {'precision': 0.7297297297297297, 'recall': 0.7105263157894737, 'f1-score': 0.7200000000000001, 'support': 38}, 'Justice/Crime': {'precision': 0.6, 'recall': 0.36, 'f1-score': 0.45, 'support': 75}, 'Labor/Employment': {'precision': 0.8888888888888888, 'recall': 0.4897959183673469, 'f1-score': 0.631578947368421, 'support': 49}, 'Macroeconomics/Economic Regulation': {'precision': 0.9340659340659341, 'recall': 0.45454545454545453, 'f1-score': 0.6115107913669064, 'support': 187}, 'Media/Journalism': {'precision': 0.7575757575757576, 'recall': 0.24752475247524752, 'f1-score': 0.373134328358209, 'support': 101}, 'Others': {'precision': 0.6602564102564102, 'recall': 0.5722222222222222, 'f1-score': 0.613095238095238, 'support': 180}, 'Religion': {'precision': 0.6666666666666666, 'recall': 0.26666666666666666, 'f1-score': 0.3809523809523809, 'support': 15}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 9}, 'War/Terror': {'precision': 0.679324894514768, 'recall': 0.7419354838709677, 'f1-score': 0.7092511013215859, 'support': 217}, 'micro avg': {'precision': 0.6537634408602151, 'recall': 0.619986403806934, 'f1-score': 0.636427076064201, 'support': 1471}, 'macro avg': {'precision': 0.6575257453208201, 'recall': 0.510064677353481, 'f1-score': 0.5428249122218151, 'support': 1471}, 'weighted avg': {'precision': 0.7156450442166671, 'recall': 0.619986403806934, 'f1-score': 0.6379646208926604, 'support': 1471}, 'samples avg': {'precision': 0.6574166666666668, 'recall': 0.6509833333333334, 'f1-score': 0.6284095238095238, 'support': 1471}}, {'Conspiracy Theory': {'precision': 0.12686567164179105, 'recall': 0.5, 'f1-score': 0.20238095238095238, 'support': 34}, 'Education': {'precision': 0.875, 'recall': 0.5384615384615384, 'f1-score': 0.6666666666666667, 'support': 13}, 'Election Campaign': {'precision': 0.5194805194805194, 'recall': 0.9302325581395349, 'f1-score': 0.6666666666666666, 'support': 43}, 'Environment': {'precision': 0.7777777777777778, 'recall': 0.4375, 'f1-score': 0.56, 'support': 16}, 'Government/Public': {'precision': 0.7994428969359332, 'recall': 0.6522727272727272, 'f1-score': 0.718397997496871, 'support': 440}, 'Health': {'precision': 0.925, 'recall': 0.6851851851851852, 'f1-score': 0.7872340425531915, 'support': 54}, 'Immigration/Integration': {'precision': 0.5789473684210527, 'recall': 0.5789473684210527, 'f1-score': 0.5789473684210527, 'support': 38}, 'Justice/Crime': {'precision': 0.6181818181818182, 'recall': 0.4533333333333333, 'f1-score': 0.5230769230769231, 'support': 75}, 'Labor/Employment': {'precision': 0.627906976744186, 'recall': 0.5510204081632653, 'f1-score': 0.5869565217391305, 'support': 49}, 'Macroeconomics/Economic Regulation': {'precision': 0.9318181818181818, 'recall': 0.4385026737967914, 'f1-score': 0.5963636363636364, 'support': 187}, 'Media/Journalism': {'precision': 0.71875, 'recall': 0.22772277227722773, 'f1-score': 0.3458646616541354, 'support': 101}, 'Others': {'precision': 0.5721649484536082, 'recall': 0.6166666666666667, 'f1-score': 0.5935828877005348, 'support': 180}, 'Religion': {'precision': 0.6363636363636364, 'recall': 0.4666666666666667, 'f1-score': 0.5384615384615385, 'support': 15}, 'Science/Technology': {'precision': 0.125, 'recall': 0.1111111111111111, 'f1-score': 0.11764705882352941, 'support': 9}, 'War/Terror': {'precision': 0.7195767195767195, 'recall': 0.6267281105990783, 'f1-score': 0.6699507389162561, 'support': 217}, 'micro avg': {'precision': 0.6521400778210117, 'recall': 0.5696804894629504, 'f1-score': 0.6081277213352685, 'support': 1471}, 'macro avg': {'precision': 0.6368184343596818, 'recall': 0.5209567413396119, 'f1-score': 0.5434798440614057, 'support': 1471}, 'weighted avg': {'precision': 0.7260085220320136, 'recall': 0.5696804894629504, 'f1-score': 0.6183439763909546, 'support': 1471}, 'samples avg': {'precision': 0.6296666666666666, 'recall': 0.5992000000000001, 'f1-score': 0.5907190476190476, 'support': 1471}}, {'Conspiracy Theory': {'precision': 0.2653061224489796, 'recall': 0.38235294117647056, 'f1-score': 0.3132530120481928, 'support': 34}, 'Education': {'precision': 0.875, 'recall': 0.5384615384615384, 'f1-score': 0.6666666666666667, 'support': 13}, 'Election Campaign': {'precision': 0.7659574468085106, 'recall': 0.8372093023255814, 'f1-score': 0.8, 'support': 43}, 'Environment': {'precision': 0.5625, 'recall': 0.5625, 'f1-score': 0.5625, 'support': 16}, 'Government/Public': {'precision': 0.7195121951219512, 'recall': 0.6704545454545454, 'f1-score': 0.6941176470588235, 'support': 440}, 'Health': {'precision': 0.875, 'recall': 0.6481481481481481, 'f1-score': 0.7446808510638299, 'support': 54}, 'Immigration/Integration': {'precision': 0.8620689655172413, 'recall': 0.6578947368421053, 'f1-score': 0.746268656716418, 'support': 38}, 'Justice/Crime': {'precision': 0.6730769230769231, 'recall': 0.4666666666666667, 'f1-score': 0.5511811023622049, 'support': 75}, 'Labor/Employment': {'precision': 0.7555555555555555, 'recall': 0.6938775510204082, 'f1-score': 0.723404255319149, 'support': 49}, 'Macroeconomics/Economic Regulation': {'precision': 0.8796296296296297, 'recall': 0.5080213903743316, 'f1-score': 0.6440677966101696, 'support': 187}, 'Media/Journalism': {'precision': 0.6764705882352942, 'recall': 0.22772277227722773, 'f1-score': 0.34074074074074073, 'support': 101}, 'Others': {'precision': 0.5462555066079295, 'recall': 0.6888888888888889, 'f1-score': 0.6093366093366094, 'support': 180}, 'Religion': {'precision': 0.7777777777777778, 'recall': 0.4666666666666667, 'f1-score': 0.5833333333333334, 'support': 15}, 'Science/Technology': {'precision': 0.14285714285714285, 'recall': 0.1111111111111111, 'f1-score': 0.125, 'support': 9}, 'War/Terror': {'precision': 0.6912442396313364, 'recall': 0.6912442396313364, 'f1-score': 0.6912442396313364, 'support': 217}, 'micro avg': {'precision': 0.6848998459167951, 'recall': 0.6043507817811012, 'f1-score': 0.6421090646442759, 'support': 1471}, 'macro avg': {'precision': 0.6712141395512181, 'recall': 0.5434146999363352, 'f1-score': 0.5863863273924983, 'support': 1471}, 'weighted avg': {'precision': 0.7073563553138342, 'recall': 0.6043507817811012, 'f1-score': 0.6375910824909369, 'support': 1471}, 'samples avg': {'precision': 0.6766666666666667, 'recall': 0.6432333333333333, 'f1-score': 0.6351904761904762, 'support': 1471}}]\n",
      "5\n",
      "\n",
      "Average Validation Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.777700  0.503315  0.600636     53.0\n",
      "Education                            0.704343  0.517094  0.586980     12.6\n",
      "Election Campaign                    0.774484  0.824731  0.794743     24.6\n",
      "Environment                          0.792857  0.470036  0.561627     11.2\n",
      "Government/Public                    0.778434  0.810275  0.793511    219.8\n",
      "Health                               0.812334  0.776780  0.790793     41.2\n",
      "Immigration/Integration              0.773486  0.792785  0.780841     39.8\n",
      "Justice/Crime                        0.843278  0.824149  0.831394    126.8\n",
      "Labor/Employment                     0.639316  0.425150  0.499744     15.2\n",
      "Macroeconomics/Economic Regulation   0.693372  0.543845  0.604640     25.0\n",
      "Media/Journalism                     0.845560  0.610568  0.702698     26.2\n",
      "Others                               0.866780  0.827292  0.845515    229.6\n",
      "Religion                             0.656954  0.536410  0.581504     13.4\n",
      "Science/Technology                   0.788571  0.410794  0.507273     11.2\n",
      "War/Terror                           0.932018  0.956829  0.944104    195.4\n",
      "micro avg                            0.832137  0.792921  0.811943   1045.0\n",
      "macro avg                            0.778633  0.655337  0.695067   1045.0\n",
      "weighted avg                         0.832474  0.792921  0.805586   1045.0\n",
      "samples avg                          0.839746  0.821762  0.816112   1045.0\n",
      "\n",
      "Average Test Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.186559  0.417647  0.246306     34.0\n",
      "Education                            0.801190  0.492308  0.609091     13.0\n",
      "Election Campaign                    0.660371  0.818605  0.725210     43.0\n",
      "Environment                          0.747149  0.537500  0.606310     16.0\n",
      "Government/Public                    0.743134  0.697727  0.716590    440.0\n",
      "Health                               0.890889  0.688889  0.776462     54.0\n",
      "Immigration/Integration              0.668603  0.673684  0.665392     38.0\n",
      "Justice/Crime                        0.604706  0.485333  0.529253     75.0\n",
      "Labor/Employment                     0.768963  0.628571  0.685392     49.0\n",
      "Macroeconomics/Economic Regulation   0.880666  0.501604  0.634424    187.0\n",
      "Media/Journalism                     0.724474  0.231683  0.350865    101.0\n",
      "Others                               0.618230  0.592222  0.598319    180.0\n",
      "Religion                             0.667273  0.400000  0.495883     15.0\n",
      "Science/Technology                   0.123201  0.177778  0.135079      9.0\n",
      "War/Terror                           0.685049  0.696774  0.688810    217.0\n",
      "micro avg                            0.670912  0.600952  0.633727   1471.0\n",
      "macro avg                            0.651364  0.536022  0.564226   1471.0\n",
      "weighted avg                         0.713492  0.600952  0.634172   1471.0\n",
      "samples avg                          0.660950  0.631687  0.621402   1471.0\n",
      "../models/REA_0621_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/REA_0621_epochs_200_train_size_full_fold_1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/REA_0621_epochs_200_train_size_full_fold_2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/REA_0621_epochs_200_train_size_full_fold_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/REA_0621_epochs_200_train_size_full_fold_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Conspiracy Theory': {'precision': 0.7906976744186046, 'recall': 0.5666666666666667, 'f1-score': 0.6601941747572816, 'support': 60}, 'Education': {'precision': 0.5, 'recall': 0.2, 'f1-score': 0.28571428571428575, 'support': 5}, 'Election Campaign': {'precision': 0.7142857142857143, 'recall': 0.6896551724137931, 'f1-score': 0.7017543859649122, 'support': 29}, 'Environment': {'precision': 0.5, 'recall': 0.2, 'f1-score': 0.28571428571428575, 'support': 10}, 'Government/Public': {'precision': 0.8022388059701493, 'recall': 0.8174904942965779, 'f1-score': 0.8097928436911488, 'support': 263}, 'Health': {'precision': 0.8387096774193549, 'recall': 0.6341463414634146, 'f1-score': 0.7222222222222222, 'support': 41}, 'Immigration/Integration': {'precision': 0.9666666666666667, 'recall': 0.6304347826086957, 'f1-score': 0.763157894736842, 'support': 46}, 'Justice/Crime': {'precision': 0.6818181818181818, 'recall': 0.6428571428571429, 'f1-score': 0.6617647058823529, 'support': 70}, 'Labor/Employment': {'precision': 0.7, 'recall': 0.4117647058823529, 'f1-score': 0.5185185185185185, 'support': 17}, 'Macroeconomics/Economic Regulation': {'precision': 0.8113207547169812, 'recall': 0.7678571428571429, 'f1-score': 0.7889908256880735, 'support': 56}, 'Media/Journalism': {'precision': 0.8333333333333334, 'recall': 0.6976744186046512, 'f1-score': 0.759493670886076, 'support': 43}, 'Others': {'precision': 0.825531914893617, 'recall': 0.8508771929824561, 'f1-score': 0.838012958963283, 'support': 228}, 'Religion': {'precision': 1.0, 'recall': 0.3333333333333333, 'f1-score': 0.5, 'support': 15}, 'Science/Technology': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 12}, 'War/Terror': {'precision': 0.9644670050761421, 'recall': 0.8715596330275229, 'f1-score': 0.9156626506024096, 'support': 218}, 'micro avg': {'precision': 0.8348170128585559, 'recall': 0.7583108715184187, 'f1-score': 0.7947269303201506, 'support': 1113}, 'macro avg': {'precision': 0.7952713152399166, 'recall': 0.57095446846625, 'f1-score': 0.6407328948894462, 'support': 1113}, 'weighted avg': {'precision': 0.8372581919294807, 'recall': 0.7583108715184187, 'f1-score': 0.7878720619156139, 'support': 1113}, 'samples avg': {'precision': 0.8302083333333333, 'recall': 0.7940625, 'f1-score': 0.7959761904761905, 'support': 1113}}, {'Conspiracy Theory': {'precision': 0.75, 'recall': 0.1935483870967742, 'f1-score': 0.30769230769230765, 'support': 62}, 'Education': {'precision': 1.0, 'recall': 0.6923076923076923, 'f1-score': 0.8181818181818181, 'support': 13}, 'Election Campaign': {'precision': 0.8947368421052632, 'recall': 0.7727272727272727, 'f1-score': 0.8292682926829269, 'support': 22}, 'Environment': {'precision': 0.6, 'recall': 0.3, 'f1-score': 0.4, 'support': 10}, 'Government/Public': {'precision': 0.7884615384615384, 'recall': 0.803921568627451, 'f1-score': 0.7961165048543688, 'support': 255}, 'Health': {'precision': 0.7058823529411765, 'recall': 0.8571428571428571, 'f1-score': 0.7741935483870968, 'support': 28}, 'Immigration/Integration': {'precision': 0.75, 'recall': 0.9285714285714286, 'f1-score': 0.8297872340425532, 'support': 42}, 'Justice/Crime': {'precision': 0.7608695652173914, 'recall': 0.6363636363636364, 'f1-score': 0.693069306930693, 'support': 55}, 'Labor/Employment': {'precision': 0.75, 'recall': 0.42857142857142855, 'f1-score': 0.5454545454545454, 'support': 14}, 'Macroeconomics/Economic Regulation': {'precision': 0.6739130434782609, 'recall': 0.7380952380952381, 'f1-score': 0.7045454545454546, 'support': 42}, 'Media/Journalism': {'precision': 0.8076923076923077, 'recall': 0.6176470588235294, 'f1-score': 0.7, 'support': 34}, 'Others': {'precision': 0.9154228855721394, 'recall': 0.8214285714285714, 'f1-score': 0.8658823529411764, 'support': 224}, 'Religion': {'precision': 0.8181818181818182, 'recall': 0.6923076923076923, 'f1-score': 0.7500000000000001, 'support': 13}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 9}, 'War/Terror': {'precision': 0.924, 'recall': 0.9058823529411765, 'f1-score': 0.9148514851485149, 'support': 255}, 'micro avg': {'precision': 0.8402848423194303, 'recall': 0.7662337662337663, 'f1-score': 0.8015526443474043, 'support': 1078}, 'macro avg': {'precision': 0.7426106902433264, 'recall': 0.6259010123336499, 'f1-score': 0.6619361900574304, 'support': 1078}, 'weighted avg': {'precision': 0.8320328488826213, 'recall': 0.7662337662337663, 'f1-score': 0.7863044911456, 'support': 1078}, 'samples avg': {'precision': 0.83625, 'recall': 0.8034375, 'f1-score': 0.8037559523809523, 'support': 1078}}, {'Conspiracy Theory': {'precision': 0.7692307692307693, 'recall': 0.38461538461538464, 'f1-score': 0.5128205128205128, 'support': 52}, 'Education': {'precision': 0.6923076923076923, 'recall': 0.9, 'f1-score': 0.7826086956521738, 'support': 10}, 'Election Campaign': {'precision': 0.92, 'recall': 0.7419354838709677, 'f1-score': 0.8214285714285714, 'support': 31}, 'Environment': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 4}, 'Government/Public': {'precision': 0.7733333333333333, 'recall': 0.8498168498168498, 'f1-score': 0.8097731239092495, 'support': 273}, 'Health': {'precision': 0.7804878048780488, 'recall': 0.8421052631578947, 'f1-score': 0.810126582278481, 'support': 38}, 'Immigration/Integration': {'precision': 0.7391304347826086, 'recall': 0.7555555555555555, 'f1-score': 0.7472527472527473, 'support': 45}, 'Justice/Crime': {'precision': 0.7258064516129032, 'recall': 0.75, 'f1-score': 0.7377049180327869, 'support': 60}, 'Labor/Employment': {'precision': 0.75, 'recall': 0.5454545454545454, 'f1-score': 0.631578947368421, 'support': 22}, 'Macroeconomics/Economic Regulation': {'precision': 0.8928571428571429, 'recall': 0.46296296296296297, 'f1-score': 0.6097560975609756, 'support': 54}, 'Media/Journalism': {'precision': 0.8823529411764706, 'recall': 0.6, 'f1-score': 0.7142857142857143, 'support': 50}, 'Others': {'precision': 0.9418604651162791, 'recall': 0.7641509433962265, 'f1-score': 0.84375, 'support': 212}, 'Religion': {'precision': 0.625, 'recall': 0.6666666666666666, 'f1-score': 0.6451612903225806, 'support': 15}, 'Science/Technology': {'precision': 1.0, 'recall': 0.2222222222222222, 'f1-score': 0.3636363636363636, 'support': 9}, 'War/Terror': {'precision': 0.9319148936170213, 'recall': 0.9279661016949152, 'f1-score': 0.9299363057324841, 'support': 236}, 'micro avg': {'precision': 0.8416912487708947, 'recall': 0.7704770477047704, 'f1-score': 0.8045112781954886, 'support': 1111}, 'macro avg': {'precision': 0.8282854619274846, 'recall': 0.6442301319609459, 'f1-score': 0.6906546580187374, 'support': 1111}, 'weighted avg': {'precision': 0.8495446772653571, 'recall': 0.7704770477047704, 'f1-score': 0.7966917620204665, 'support': 1111}, 'samples avg': {'precision': 0.8309375, 'recall': 0.8020416666666668, 'f1-score': 0.800718253968254, 'support': 1111}}, {'Conspiracy Theory': {'precision': 0.782608695652174, 'recall': 0.3103448275862069, 'f1-score': 0.4444444444444444, 'support': 58}, 'Education': {'precision': 0.5, 'recall': 0.3, 'f1-score': 0.37499999999999994, 'support': 10}, 'Election Campaign': {'precision': 0.7619047619047619, 'recall': 0.8, 'f1-score': 0.7804878048780488, 'support': 20}, 'Environment': {'precision': 1.0, 'recall': 0.2, 'f1-score': 0.33333333333333337, 'support': 5}, 'Government/Public': {'precision': 0.7927272727272727, 'recall': 0.7985347985347986, 'f1-score': 0.7956204379562044, 'support': 273}, 'Health': {'precision': 0.9487179487179487, 'recall': 0.7115384615384616, 'f1-score': 0.8131868131868132, 'support': 52}, 'Immigration/Integration': {'precision': 0.673469387755102, 'recall': 0.7857142857142857, 'f1-score': 0.7252747252747253, 'support': 42}, 'Justice/Crime': {'precision': 0.7209302325581395, 'recall': 0.5535714285714286, 'f1-score': 0.6262626262626263, 'support': 56}, 'Labor/Employment': {'precision': 0.7777777777777778, 'recall': 0.30434782608695654, 'f1-score': 0.43750000000000006, 'support': 23}, 'Macroeconomics/Economic Regulation': {'precision': 0.6451612903225806, 'recall': 0.7547169811320755, 'f1-score': 0.6956521739130435, 'support': 53}, 'Media/Journalism': {'precision': 0.7719298245614035, 'recall': 0.8301886792452831, 'f1-score': 0.8, 'support': 53}, 'Others': {'precision': 0.826530612244898, 'recall': 0.7714285714285715, 'f1-score': 0.7980295566502463, 'support': 210}, 'Religion': {'precision': 0.8888888888888888, 'recall': 0.38095238095238093, 'f1-score': 0.5333333333333333, 'support': 21}, 'Science/Technology': {'precision': 1.0, 'recall': 0.23076923076923078, 'f1-score': 0.375, 'support': 13}, 'War/Terror': {'precision': 0.9308755760368663, 'recall': 0.8859649122807017, 'f1-score': 0.9078651685393259, 'support': 228}, 'micro avg': {'precision': 0.8148514851485148, 'recall': 0.7367949865711728, 'f1-score': 0.773859896567936, 'support': 1117}, 'macro avg': {'precision': 0.8014348179431877, 'recall': 0.5745381589226921, 'f1-score': 0.6293993611848097, 'support': 1117}, 'weighted avg': {'precision': 0.8196128292166615, 'recall': 0.7367949865711728, 'f1-score': 0.762590036224636, 'support': 1117}, 'samples avg': {'precision': 0.8009375, 'recall': 0.7623541666666668, 'f1-score': 0.7641259920634922, 'support': 1117}}, {'Conspiracy Theory': {'precision': 0.7368421052631579, 'recall': 0.4666666666666667, 'f1-score': 0.5714285714285714, 'support': 60}, 'Education': {'precision': 0.7142857142857143, 'recall': 0.35714285714285715, 'f1-score': 0.4761904761904762, 'support': 14}, 'Election Campaign': {'precision': 0.7307692307692307, 'recall': 0.7307692307692307, 'f1-score': 0.7307692307692306, 'support': 26}, 'Environment': {'precision': 1.0, 'recall': 0.1, 'f1-score': 0.18181818181818182, 'support': 10}, 'Government/Public': {'precision': 0.7666666666666667, 'recall': 0.7992277992277992, 'f1-score': 0.782608695652174, 'support': 259}, 'Health': {'precision': 0.8275862068965517, 'recall': 0.7741935483870968, 'f1-score': 0.7999999999999999, 'support': 31}, 'Immigration/Integration': {'precision': 0.8444444444444444, 'recall': 0.76, 'f1-score': 0.8, 'support': 50}, 'Justice/Crime': {'precision': 0.6545454545454545, 'recall': 0.5538461538461539, 'f1-score': 0.6000000000000001, 'support': 65}, 'Labor/Employment': {'precision': 0.8571428571428571, 'recall': 0.3157894736842105, 'f1-score': 0.46153846153846156, 'support': 19}, 'Macroeconomics/Economic Regulation': {'precision': 0.8478260869565217, 'recall': 0.6724137931034483, 'f1-score': 0.75, 'support': 58}, 'Media/Journalism': {'precision': 0.8, 'recall': 0.6666666666666666, 'f1-score': 0.7272727272727272, 'support': 36}, 'Others': {'precision': 0.8840579710144928, 'recall': 0.8061674008810573, 'f1-score': 0.8433179723502304, 'support': 227}, 'Religion': {'precision': 0.6428571428571429, 'recall': 0.8181818181818182, 'f1-score': 0.7200000000000001, 'support': 11}, 'Science/Technology': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1-score': 0.5714285714285715, 'support': 8}, 'War/Terror': {'precision': 0.9, 'recall': 0.9642857142857143, 'f1-score': 0.9310344827586207, 'support': 224}, 'micro avg': {'precision': 0.821743388834476, 'recall': 0.7641165755919854, 'f1-score': 0.7918829636621048, 'support': 1098}, 'macro avg': {'precision': 0.7915793698339267, 'recall': 0.6190234081895146, 'f1-score': 0.6631604914138164, 'support': 1098}, 'weighted avg': {'precision': 0.8207154743334885, 'recall': 0.7641165755919854, 'f1-score': 0.7825078290786763, 'support': 1098}, 'samples avg': {'precision': 0.828125, 'recall': 0.7928125, 'f1-score': 0.7939940476190476, 'support': 1098}}]\n",
      "5\n",
      "[{'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, 'Education': {'precision': 0.5454545454545454, 'recall': 0.5, 'f1-score': 0.5217391304347826, 'support': 24}, 'Election Campaign': {'precision': 0.8333333333333334, 'recall': 0.9210526315789473, 'f1-score': 0.875, 'support': 38}, 'Environment': {'precision': 0.8125, 'recall': 0.3939393939393939, 'f1-score': 0.5306122448979591, 'support': 33}, 'Government/Public': {'precision': 0.663003663003663, 'recall': 0.8379629629629629, 'f1-score': 0.7402862985685071, 'support': 216}, 'Health': {'precision': 0.8260869565217391, 'recall': 0.8142857142857143, 'f1-score': 0.8201438848920863, 'support': 70}, 'Immigration/Integration': {'precision': 1.0, 'recall': 0.4166666666666667, 'f1-score': 0.5882352941176471, 'support': 12}, 'Justice/Crime': {'precision': 0.9143576826196473, 'recall': 0.9007444168734491, 'f1-score': 0.9075, 'support': 403}, 'Labor/Employment': {'precision': 0.5384615384615384, 'recall': 0.23333333333333334, 'f1-score': 0.32558139534883723, 'support': 30}, 'Macroeconomics/Economic Regulation': {'precision': 0.5454545454545454, 'recall': 0.7346938775510204, 'f1-score': 0.6260869565217392, 'support': 49}, 'Media/Journalism': {'precision': 0.42105263157894735, 'recall': 0.5, 'f1-score': 0.45714285714285713, 'support': 16}, 'Others': {'precision': 0.770949720670391, 'recall': 0.6079295154185022, 'f1-score': 0.6798029556650246, 'support': 227}, 'Religion': {'precision': 0.4, 'recall': 0.2857142857142857, 'f1-score': 0.3333333333333333, 'support': 7}, 'Science/Technology': {'precision': 0.36363636363636365, 'recall': 0.2857142857142857, 'f1-score': 0.32, 'support': 14}, 'War/Terror': {'precision': 0.6071428571428571, 'recall': 0.5151515151515151, 'f1-score': 0.5573770491803278, 'support': 33}, 'micro avg': {'precision': 0.7654751525719268, 'recall': 0.7446988973706531, 'f1-score': 0.754944110060189, 'support': 1179}, 'macro avg': {'precision': 0.616095589191838, 'recall': 0.5298125732793384, 'f1-score': 0.5521894266735401, 'support': 1179}, 'weighted avg': {'precision': 0.7681435716486775, 'recall': 0.7446988973706531, 'f1-score': 0.7469526840638538, 'support': 1179}, 'samples avg': {'precision': 0.7583333333333334, 'recall': 0.7671666666666667, 'f1-score': 0.7495666666666667, 'support': 1179}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, 'Education': {'precision': 0.7058823529411765, 'recall': 0.5, 'f1-score': 0.5853658536585366, 'support': 24}, 'Election Campaign': {'precision': 0.8095238095238095, 'recall': 0.8947368421052632, 'f1-score': 0.8500000000000001, 'support': 38}, 'Environment': {'precision': 0.6086956521739131, 'recall': 0.42424242424242425, 'f1-score': 0.5, 'support': 33}, 'Government/Public': {'precision': 0.6762295081967213, 'recall': 0.7638888888888888, 'f1-score': 0.717391304347826, 'support': 216}, 'Health': {'precision': 0.6346153846153846, 'recall': 0.9428571428571428, 'f1-score': 0.7586206896551724, 'support': 70}, 'Immigration/Integration': {'precision': 0.5454545454545454, 'recall': 0.5, 'f1-score': 0.5217391304347826, 'support': 12}, 'Justice/Crime': {'precision': 0.9429429429429429, 'recall': 0.7791563275434243, 'f1-score': 0.8532608695652174, 'support': 403}, 'Labor/Employment': {'precision': 0.6363636363636364, 'recall': 0.23333333333333334, 'f1-score': 0.34146341463414637, 'support': 30}, 'Macroeconomics/Economic Regulation': {'precision': 0.4605263157894737, 'recall': 0.7142857142857143, 'f1-score': 0.56, 'support': 49}, 'Media/Journalism': {'precision': 0.46153846153846156, 'recall': 0.375, 'f1-score': 0.41379310344827586, 'support': 16}, 'Others': {'precision': 0.8558558558558559, 'recall': 0.4185022026431718, 'f1-score': 0.5621301775147929, 'support': 227}, 'Religion': {'precision': 0.5, 'recall': 0.42857142857142855, 'f1-score': 0.4615384615384615, 'support': 7}, 'Science/Technology': {'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1-score': 0.2, 'support': 14}, 'War/Terror': {'precision': 0.68, 'recall': 0.5151515151515151, 'f1-score': 0.5862068965517241, 'support': 33}, 'micro avg': {'precision': 0.7592954990215264, 'recall': 0.6581849024597116, 'f1-score': 0.7051340299863699, 'support': 1179}, 'macro avg': {'precision': 0.5900641199152835, 'recall': 0.5088388641652967, 'f1-score': 0.5274339934232625, 'support': 1179}, 'weighted avg': {'precision': 0.779268370563542, 'recall': 0.6581849024597116, 'f1-score': 0.6940775994146127, 'support': 1179}, 'samples avg': {'precision': 0.6785833333333332, 'recall': 0.6781666666666667, 'f1-score': 0.6649571428571428, 'support': 1179}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, 'Education': {'precision': 0.36363636363636365, 'recall': 0.8333333333333334, 'f1-score': 0.5063291139240507, 'support': 24}, 'Election Campaign': {'precision': 0.8095238095238095, 'recall': 0.8947368421052632, 'f1-score': 0.8500000000000001, 'support': 38}, 'Environment': {'precision': 0.5227272727272727, 'recall': 0.696969696969697, 'f1-score': 0.5974025974025974, 'support': 33}, 'Government/Public': {'precision': 0.6075085324232082, 'recall': 0.8240740740740741, 'f1-score': 0.6994106090373281, 'support': 216}, 'Health': {'precision': 0.6559139784946236, 'recall': 0.8714285714285714, 'f1-score': 0.7484662576687117, 'support': 70}, 'Immigration/Integration': {'precision': 0.7, 'recall': 0.5833333333333334, 'f1-score': 0.6363636363636365, 'support': 12}, 'Justice/Crime': {'precision': 0.8773148148148148, 'recall': 0.9404466501240695, 'f1-score': 0.9077844311377246, 'support': 403}, 'Labor/Employment': {'precision': 0.6363636363636364, 'recall': 0.23333333333333334, 'f1-score': 0.34146341463414637, 'support': 30}, 'Macroeconomics/Economic Regulation': {'precision': 0.6041666666666666, 'recall': 0.5918367346938775, 'f1-score': 0.5979381443298969, 'support': 49}, 'Media/Journalism': {'precision': 0.3684210526315789, 'recall': 0.4375, 'f1-score': 0.39999999999999997, 'support': 16}, 'Others': {'precision': 0.918918918918919, 'recall': 0.29955947136563876, 'f1-score': 0.45182724252491696, 'support': 227}, 'Religion': {'precision': 0.625, 'recall': 0.7142857142857143, 'f1-score': 0.6666666666666666, 'support': 7}, 'Science/Technology': {'precision': 0.23529411764705882, 'recall': 0.2857142857142857, 'f1-score': 0.2580645161290323, 'support': 14}, 'War/Terror': {'precision': 0.6896551724137931, 'recall': 0.6060606060606061, 'f1-score': 0.6451612903225807, 'support': 33}, 'micro avg': {'precision': 0.7165957446808511, 'recall': 0.714164546225615, 'f1-score': 0.7153780798640612, 'support': 1179}, 'macro avg': {'precision': 0.5742962890841165, 'recall': 0.5875075097881197, 'f1-score': 0.5537918613427526, 'support': 1179}, 'weighted avg': {'precision': 0.7544062891336505, 'recall': 0.714164546225615, 'f1-score': 0.6948113243932704, 'support': 1179}, 'samples avg': {'precision': 0.7101666666666666, 'recall': 0.727, 'f1-score': 0.7022333333333334, 'support': 1179}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, 'Education': {'precision': 0.625, 'recall': 0.625, 'f1-score': 0.625, 'support': 24}, 'Election Campaign': {'precision': 0.8048780487804879, 'recall': 0.868421052631579, 'f1-score': 0.8354430379746836, 'support': 38}, 'Environment': {'precision': 0.6086956521739131, 'recall': 0.42424242424242425, 'f1-score': 0.5, 'support': 33}, 'Government/Public': {'precision': 0.6153846153846154, 'recall': 0.8518518518518519, 'f1-score': 0.7145631067961165, 'support': 216}, 'Health': {'precision': 0.6896551724137931, 'recall': 0.8571428571428571, 'f1-score': 0.7643312101910829, 'support': 70}, 'Immigration/Integration': {'precision': 0.5555555555555556, 'recall': 0.4166666666666667, 'f1-score': 0.4761904761904762, 'support': 12}, 'Justice/Crime': {'precision': 0.9397260273972603, 'recall': 0.8511166253101737, 'f1-score': 0.8932291666666667, 'support': 403}, 'Labor/Employment': {'precision': 0.46153846153846156, 'recall': 0.2, 'f1-score': 0.27906976744186046, 'support': 30}, 'Macroeconomics/Economic Regulation': {'precision': 0.45121951219512196, 'recall': 0.7551020408163265, 'f1-score': 0.5648854961832062, 'support': 49}, 'Media/Journalism': {'precision': 0.30434782608695654, 'recall': 0.4375, 'f1-score': 0.358974358974359, 'support': 16}, 'Others': {'precision': 0.8521739130434782, 'recall': 0.43171806167400884, 'f1-score': 0.5730994152046784, 'support': 227}, 'Religion': {'precision': 0.4, 'recall': 0.2857142857142857, 'f1-score': 0.3333333333333333, 'support': 7}, 'Science/Technology': {'precision': 0.375, 'recall': 0.21428571428571427, 'f1-score': 0.2727272727272727, 'support': 14}, 'War/Terror': {'precision': 0.6551724137931034, 'recall': 0.5757575757575758, 'f1-score': 0.6129032258064515, 'support': 33}, 'micro avg': {'precision': 0.7355298308103295, 'recall': 0.7005937234944869, 'f1-score': 0.7176368375325803, 'support': 1179}, 'macro avg': {'precision': 0.5558898132241832, 'recall': 0.5196346104062309, 'f1-score': 0.5202499911660124, 'support': 1179}, 'weighted avg': {'precision': 0.7601248177712899, 'recall': 0.7005937234944869, 'f1-score': 0.7082673893466838, 'support': 1179}, 'samples avg': {'precision': 0.7126666666666667, 'recall': 0.721, 'f1-score': 0.7028333333333334, 'support': 1179}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, 'Education': {'precision': 0.5909090909090909, 'recall': 0.5416666666666666, 'f1-score': 0.5652173913043478, 'support': 24}, 'Election Campaign': {'precision': 0.8974358974358975, 'recall': 0.9210526315789473, 'f1-score': 0.9090909090909091, 'support': 38}, 'Environment': {'precision': 1.0, 'recall': 0.18181818181818182, 'f1-score': 0.3076923076923077, 'support': 33}, 'Government/Public': {'precision': 0.6579925650557621, 'recall': 0.8194444444444444, 'f1-score': 0.7298969072164948, 'support': 216}, 'Health': {'precision': 0.6185567010309279, 'recall': 0.8571428571428571, 'f1-score': 0.718562874251497, 'support': 70}, 'Immigration/Integration': {'precision': 0.625, 'recall': 0.4166666666666667, 'f1-score': 0.5, 'support': 12}, 'Justice/Crime': {'precision': 0.8850855745721271, 'recall': 0.8982630272952854, 'f1-score': 0.8916256157635468, 'support': 403}, 'Labor/Employment': {'precision': 0.6, 'recall': 0.4, 'f1-score': 0.48, 'support': 30}, 'Macroeconomics/Economic Regulation': {'precision': 0.5483870967741935, 'recall': 0.6938775510204082, 'f1-score': 0.6126126126126127, 'support': 49}, 'Media/Journalism': {'precision': 0.3333333333333333, 'recall': 0.375, 'f1-score': 0.35294117647058826, 'support': 16}, 'Others': {'precision': 0.8660714285714286, 'recall': 0.42731277533039647, 'f1-score': 0.5722713864306784, 'support': 227}, 'Religion': {'precision': 0.5714285714285714, 'recall': 0.5714285714285714, 'f1-score': 0.5714285714285714, 'support': 7}, 'Science/Technology': {'precision': 0.45454545454545453, 'recall': 0.7142857142857143, 'f1-score': 0.5555555555555556, 'support': 14}, 'War/Terror': {'precision': 0.5, 'recall': 0.6363636363636364, 'f1-score': 0.56, 'support': 33}, 'micro avg': {'precision': 0.7425044091710759, 'recall': 0.714164546225615, 'f1-score': 0.7280587980977087, 'support': 1179}, 'macro avg': {'precision': 0.6099163809104524, 'recall': 0.5636215149361183, 'f1-score': 0.555126353854474, 'support': 1179}, 'weighted avg': {'precision': 0.7672310294196597, 'recall': 0.714164546225615, 'f1-score': 0.7139739047826729, 'support': 1179}, 'samples avg': {'precision': 0.7193333333333333, 'recall': 0.7298333333333332, 'f1-score': 0.7112666666666666, 'support': 1179}}]\n",
      "5\n",
      "\n",
      "Average Validation Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.765876  0.384368  0.499316     58.4\n",
      "Education                            0.681319  0.489890  0.547539     10.4\n",
      "Election Campaign                    0.804339  0.747017  0.772742     25.6\n",
      "Environment                          0.820000  0.210000  0.320173      7.8\n",
      "Government/Public                    0.784686  0.813798  0.798782    264.6\n",
      "Health                               0.820277  0.763825  0.783946     38.0\n",
      "Immigration/Integration              0.794742  0.772055  0.773095     45.0\n",
      "Justice/Crime                        0.708794  0.627328  0.663760     61.2\n",
      "Labor/Employment                     0.766984  0.401186  0.518918     19.0\n",
      "Macroeconomics/Economic Regulation   0.774216  0.679209  0.709789     52.6\n",
      "Media/Journalism                     0.819062  0.682435  0.740210     43.2\n",
      "Others                               0.878681  0.802811  0.837799    220.2\n",
      "Religion                             0.794986  0.578288  0.629699     15.0\n",
      "Science/Technology                   0.733333  0.240598  0.342013     10.2\n",
      "War/Terror                           0.930251  0.911132  0.919870    232.2\n",
      "micro avg                            0.830678  0.759187  0.793307   1103.4\n",
      "macro avg                            0.791836  0.606929  0.657177   1103.4\n",
      "weighted avg                         0.831833  0.759187  0.783193   1103.4\n",
      "samples avg                          0.825292  0.790942  0.791714   1103.4\n",
      "\n",
      "Average Test Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.000000  0.000000  0.000000      7.0\n",
      "Education                            0.566176  0.600000  0.560730     24.0\n",
      "Election Campaign                    0.830939  0.900000  0.863907     38.0\n",
      "Environment                          0.710524  0.424242  0.487141     33.0\n",
      "Government/Public                    0.644024  0.819444  0.720310    216.0\n",
      "Health                               0.684966  0.868571  0.762025     70.0\n",
      "Immigration/Integration              0.685202  0.466667  0.544506     12.0\n",
      "Justice/Crime                        0.911885  0.873945  0.890680    403.0\n",
      "Labor/Employment                     0.574545  0.260000  0.353516     30.0\n",
      "Macroeconomics/Economic Regulation   0.521951  0.697959  0.592305     49.0\n",
      "Media/Journalism                     0.377739  0.425000  0.396570     16.0\n",
      "Others                               0.852794  0.437004  0.567826    227.0\n",
      "Religion                             0.499286  0.457143  0.473260      7.0\n",
      "Science/Technology                   0.352362  0.328571  0.321269     14.0\n",
      "War/Terror                           0.626394  0.569697  0.592330     33.0\n",
      "micro avg                            0.743880  0.706361  0.724230   1179.0\n",
      "macro avg                            0.589252  0.541883  0.541758   1179.0\n",
      "weighted avg                         0.765835  0.706361  0.711617   1179.0\n",
      "samples avg                          0.715817  0.724633  0.706171   1179.0\n",
      "../models/UGANDA_0621_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/UGANDA_0621_epochs_200_train_size_full_fold_1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/UGANDA_0621_epochs_200_train_size_full_fold_2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/UGANDA_0621_epochs_200_train_size_full_fold_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/UGANDA_0621_epochs_200_train_size_full_fold_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Conspiracy Theory': {'precision': 0.7297297297297297, 'recall': 0.5, 'f1-score': 0.5934065934065933, 'support': 54}, 'Education': {'precision': 0.8181818181818182, 'recall': 0.6923076923076923, 'f1-score': 0.7500000000000001, 'support': 13}, 'Election Campaign': {'precision': 0.7037037037037037, 'recall': 0.8260869565217391, 'f1-score': 0.76, 'support': 23}, 'Environment': {'precision': 0.3333333333333333, 'recall': 0.5, 'f1-score': 0.4, 'support': 8}, 'Government/Public': {'precision': 0.7941176470588235, 'recall': 0.8586572438162544, 'f1-score': 0.8251273344651952, 'support': 283}, 'Health': {'precision': 0.9230769230769231, 'recall': 0.8571428571428571, 'f1-score': 0.888888888888889, 'support': 42}, 'Immigration/Integration': {'precision': 0.94, 'recall': 0.8103448275862069, 'f1-score': 0.8703703703703703, 'support': 58}, 'Justice/Crime': {'precision': 0.7686567164179104, 'recall': 0.8046875, 'f1-score': 0.7862595419847329, 'support': 128}, 'Labor/Employment': {'precision': 0.5217391304347826, 'recall': 0.5714285714285714, 'f1-score': 0.5454545454545454, 'support': 21}, 'Macroeconomics/Economic Regulation': {'precision': 0.6428571428571429, 'recall': 0.8035714285714286, 'f1-score': 0.7142857142857142, 'support': 56}, 'Media/Journalism': {'precision': 0.8297872340425532, 'recall': 0.75, 'f1-score': 0.787878787878788, 'support': 52}, 'Others': {'precision': 0.8620689655172413, 'recall': 0.5952380952380952, 'f1-score': 0.7042253521126761, 'support': 126}, 'Religion': {'precision': 0.7, 'recall': 0.6363636363636364, 'f1-score': 0.6666666666666666, 'support': 11}, 'Science/Technology': {'precision': 0.6, 'recall': 0.375, 'f1-score': 0.4615384615384615, 'support': 8}, 'War/Terror': {'precision': 0.9482071713147411, 'recall': 0.9333333333333333, 'f1-score': 0.9407114624505929, 'support': 255}, 'micro avg': {'precision': 0.8178539224526601, 'recall': 0.79701230228471, 'f1-score': 0.8072986203827325, 'support': 1138}, 'macro avg': {'precision': 0.7410306343779136, 'recall': 0.7009441428206544, 'f1-score': 0.7129875813002151, 'support': 1138}, 'weighted avg': {'precision': 0.8245388240173689, 'recall': 0.79701230228471, 'f1-score': 0.8053644364037337, 'support': 1138}, 'samples avg': {'precision': 0.82625, 'recall': 0.8130208333333333, 'f1-score': 0.8032440476190476, 'support': 1138}}, {'Conspiracy Theory': {'precision': 0.6617647058823529, 'recall': 0.6521739130434783, 'f1-score': 0.656934306569343, 'support': 69}, 'Education': {'precision': 0.6363636363636364, 'recall': 0.3888888888888889, 'f1-score': 0.4827586206896552, 'support': 18}, 'Election Campaign': {'precision': 0.8, 'recall': 0.8333333333333334, 'f1-score': 0.816326530612245, 'support': 24}, 'Environment': {'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'f1-score': 0.5, 'support': 9}, 'Government/Public': {'precision': 0.764525993883792, 'recall': 0.8896797153024911, 'f1-score': 0.8223684210526316, 'support': 281}, 'Health': {'precision': 0.85, 'recall': 0.85, 'f1-score': 0.85, 'support': 40}, 'Immigration/Integration': {'precision': 0.75, 'recall': 0.8461538461538461, 'f1-score': 0.7951807228915662, 'support': 39}, 'Justice/Crime': {'precision': 0.8231292517006803, 'recall': 0.8402777777777778, 'f1-score': 0.831615120274914, 'support': 144}, 'Labor/Employment': {'precision': 0.45454545454545453, 'recall': 0.25, 'f1-score': 0.3225806451612903, 'support': 20}, 'Macroeconomics/Economic Regulation': {'precision': 0.6956521739130435, 'recall': 0.8727272727272727, 'f1-score': 0.7741935483870968, 'support': 55}, 'Media/Journalism': {'precision': 0.813953488372093, 'recall': 0.7777777777777778, 'f1-score': 0.7954545454545455, 'support': 45}, 'Others': {'precision': 0.8369565217391305, 'recall': 0.6754385964912281, 'f1-score': 0.7475728155339806, 'support': 114}, 'Religion': {'precision': 0.8333333333333334, 'recall': 0.7142857142857143, 'f1-score': 0.7692307692307692, 'support': 14}, 'Science/Technology': {'precision': 0.8, 'recall': 0.5714285714285714, 'f1-score': 0.6666666666666666, 'support': 7}, 'War/Terror': {'precision': 0.9399141630901288, 'recall': 0.9125, 'f1-score': 0.9260042283298098, 'support': 240}, 'micro avg': {'precision': 0.8042328042328042, 'recall': 0.8150134048257373, 'f1-score': 0.8095872170439413, 'support': 1119}, 'macro avg': {'precision': 0.7487711529501478, 'recall': 0.7012739901103215, 'f1-score': 0.7171257960569675, 'support': 1119}, 'weighted avg': {'precision': 0.8045669157720801, 'recall': 0.8150134048257373, 'f1-score': 0.805798066759997, 'support': 1119}, 'samples avg': {'precision': 0.8286458333333333, 'recall': 0.835, 'f1-score': 0.8146488095238095, 'support': 1119}}, {'Conspiracy Theory': {'precision': 0.5535714285714286, 'recall': 0.5254237288135594, 'f1-score': 0.5391304347826087, 'support': 59}, 'Education': {'precision': 0.6, 'recall': 0.6, 'f1-score': 0.6, 'support': 10}, 'Election Campaign': {'precision': 0.9655172413793104, 'recall': 0.8484848484848485, 'f1-score': 0.9032258064516129, 'support': 33}, 'Environment': {'precision': 0.6153846153846154, 'recall': 0.8421052631578947, 'f1-score': 0.7111111111111111, 'support': 19}, 'Government/Public': {'precision': 0.7807308970099668, 'recall': 0.8245614035087719, 'f1-score': 0.8020477815699658, 'support': 285}, 'Health': {'precision': 0.7941176470588235, 'recall': 0.7105263157894737, 'f1-score': 0.7499999999999999, 'support': 38}, 'Immigration/Integration': {'precision': 0.8378378378378378, 'recall': 0.6888888888888889, 'f1-score': 0.7560975609756098, 'support': 45}, 'Justice/Crime': {'precision': 0.8608695652173913, 'recall': 0.7557251908396947, 'f1-score': 0.8048780487804879, 'support': 131}, 'Labor/Employment': {'precision': 0.8181818181818182, 'recall': 0.4090909090909091, 'f1-score': 0.5454545454545455, 'support': 22}, 'Macroeconomics/Economic Regulation': {'precision': 0.7090909090909091, 'recall': 0.6724137931034483, 'f1-score': 0.6902654867256638, 'support': 58}, 'Media/Journalism': {'precision': 0.8888888888888888, 'recall': 0.8421052631578947, 'f1-score': 0.8648648648648649, 'support': 38}, 'Others': {'precision': 0.9191919191919192, 'recall': 0.7, 'f1-score': 0.7947598253275109, 'support': 130}, 'Religion': {'precision': 0.47058823529411764, 'recall': 0.7272727272727273, 'f1-score': 0.5714285714285714, 'support': 11}, 'Science/Technology': {'precision': 0.5, 'recall': 0.45454545454545453, 'f1-score': 0.47619047619047616, 'support': 11}, 'War/Terror': {'precision': 0.8740157480314961, 'recall': 0.961038961038961, 'f1-score': 0.9154639175257733, 'support': 231}, 'micro avg': {'precision': 0.8064220183486238, 'recall': 0.784121320249777, 'f1-score': 0.7951153324287652, 'support': 1121}, 'macro avg': {'precision': 0.7458657834092348, 'recall': 0.7041455165128351, 'f1-score': 0.7149945620792535, 'support': 1121}, 'weighted avg': {'precision': 0.812087949428463, 'recall': 0.784121320249777, 'f1-score': 0.7929422886865012, 'support': 1121}, 'samples avg': {'precision': 0.8226041666666666, 'recall': 0.8151041666666665, 'f1-score': 0.8018273809523808, 'support': 1121}}, {'Conspiracy Theory': {'precision': 0.6428571428571429, 'recall': 0.1875, 'f1-score': 0.2903225806451613, 'support': 48}, 'Education': {'precision': 1.0, 'recall': 0.18181818181818182, 'f1-score': 0.3076923076923077, 'support': 11}, 'Election Campaign': {'precision': 0.8947368421052632, 'recall': 0.7727272727272727, 'f1-score': 0.8292682926829269, 'support': 22}, 'Environment': {'precision': 1.0, 'recall': 0.15384615384615385, 'f1-score': 0.2666666666666667, 'support': 13}, 'Government/Public': {'precision': 0.7892857142857143, 'recall': 0.8371212121212122, 'f1-score': 0.8125, 'support': 264}, 'Health': {'precision': 0.9, 'recall': 0.75, 'f1-score': 0.8181818181818182, 'support': 48}, 'Immigration/Integration': {'precision': 0.7551020408163265, 'recall': 0.8043478260869565, 'f1-score': 0.7789473684210526, 'support': 46}, 'Justice/Crime': {'precision': 0.8832116788321168, 'recall': 0.7960526315789473, 'f1-score': 0.8373702422145328, 'support': 152}, 'Labor/Employment': {'precision': 0.6875, 'recall': 0.5238095238095238, 'f1-score': 0.5945945945945946, 'support': 21}, 'Macroeconomics/Economic Regulation': {'precision': 0.8367346938775511, 'recall': 0.6612903225806451, 'f1-score': 0.7387387387387386, 'support': 62}, 'Media/Journalism': {'precision': 0.6842105263157895, 'recall': 0.7027027027027027, 'f1-score': 0.6933333333333334, 'support': 37}, 'Others': {'precision': 0.87, 'recall': 0.6692307692307692, 'f1-score': 0.7565217391304347, 'support': 130}, 'Religion': {'precision': 0.875, 'recall': 0.5, 'f1-score': 0.6363636363636364, 'support': 14}, 'Science/Technology': {'precision': 1.0, 'recall': 0.08333333333333333, 'f1-score': 0.15384615384615385, 'support': 12}, 'War/Terror': {'precision': 0.9134615384615384, 'recall': 0.9090909090909091, 'f1-score': 0.9112709832134293, 'support': 209}, 'micro avg': {'precision': 0.8390446521287642, 'recall': 0.7419651056014692, 'f1-score': 0.7875243664717347, 'support': 1089}, 'macro avg': {'precision': 0.8488066785034294, 'recall': 0.5688580559284405, 'f1-score': 0.6283745637149857, 'support': 1089}, 'weighted avg': {'precision': 0.8402111598232084, 'recall': 0.7419651056014692, 'f1-score': 0.770813204181275, 'support': 1089}, 'samples avg': {'precision': 0.8275, 'recall': 0.7863541666666666, 'f1-score': 0.7893630952380951, 'support': 1089}}, {'Conspiracy Theory': {'precision': 0.6808510638297872, 'recall': 0.5517241379310345, 'f1-score': 0.6095238095238096, 'support': 58}, 'Education': {'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'f1-score': 0.5333333333333333, 'support': 9}, 'Election Campaign': {'precision': 0.875, 'recall': 0.6774193548387096, 'f1-score': 0.7636363636363636, 'support': 31}, 'Environment': {'precision': 1.0, 'recall': 0.4117647058823529, 'f1-score': 0.5833333333333334, 'support': 17}, 'Government/Public': {'precision': 0.7840909090909091, 'recall': 0.7752808988764045, 'f1-score': 0.7796610169491526, 'support': 267}, 'Health': {'precision': 0.782608695652174, 'recall': 0.8181818181818182, 'f1-score': 0.8, 'support': 44}, 'Immigration/Integration': {'precision': 0.72, 'recall': 0.8, 'f1-score': 0.7578947368421052, 'support': 45}, 'Justice/Crime': {'precision': 0.8294573643410853, 'recall': 0.816793893129771, 'f1-score': 0.823076923076923, 'support': 131}, 'Labor/Employment': {'precision': 0.7647058823529411, 'recall': 0.5652173913043478, 'f1-score': 0.65, 'support': 23}, 'Macroeconomics/Economic Regulation': {'precision': 0.803921568627451, 'recall': 0.6612903225806451, 'f1-score': 0.7256637168141592, 'support': 62}, 'Media/Journalism': {'precision': 0.8085106382978723, 'recall': 0.76, 'f1-score': 0.7835051546391754, 'support': 50}, 'Others': {'precision': 0.7, 'recall': 0.6695652173913044, 'f1-score': 0.6844444444444445, 'support': 115}, 'Religion': {'precision': 0.8, 'recall': 0.3076923076923077, 'f1-score': 0.4444444444444444, 'support': 13}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, 'War/Terror': {'precision': 0.932806324110672, 'recall': 0.944, 'f1-score': 0.9383697813121272, 'support': 250}, 'micro avg': {'precision': 0.8126773888363292, 'recall': 0.7655971479500892, 'f1-score': 0.7884350619550253, 'support': 1122}, 'macro avg': {'precision': 0.7432412741979705, 'recall': 0.6135582994835427, 'f1-score': 0.6584591372232914, 'support': 1122}, 'weighted avg': {'precision': 0.8078599084299103, 'recall': 0.7655971479500892, 'f1-score': 0.7818514695985095, 'support': 1122}, 'samples avg': {'precision': 0.806875, 'recall': 0.7816249999999999, 'f1-score': 0.7782212301587301, 'support': 1122}}]\n",
      "5\n",
      "[{'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11}, 'Education': {'precision': 0.47058823529411764, 'recall': 0.5333333333333333, 'f1-score': 0.5, 'support': 15}, 'Election Campaign': {'precision': 0.8, 'recall': 0.48484848484848486, 'f1-score': 0.6037735849056605, 'support': 33}, 'Environment': {'precision': 0.3076923076923077, 'recall': 0.6666666666666666, 'f1-score': 0.42105263157894735, 'support': 6}, 'Government/Public': {'precision': 0.5789473684210527, 'recall': 0.6226415094339622, 'f1-score': 0.6, 'support': 159}, 'Health': {'precision': 0.7727272727272727, 'recall': 0.7083333333333334, 'f1-score': 0.7391304347826088, 'support': 48}, 'Immigration/Integration': {'precision': 0.6, 'recall': 0.75, 'f1-score': 0.6666666666666665, 'support': 4}, 'Justice/Crime': {'precision': 0.34782608695652173, 'recall': 0.6956521739130435, 'f1-score': 0.46376811594202894, 'support': 23}, 'Labor/Employment': {'precision': 0.5625, 'recall': 0.5, 'f1-score': 0.5294117647058824, 'support': 18}, 'Macroeconomics/Economic Regulation': {'precision': 0.48, 'recall': 0.631578947368421, 'f1-score': 0.5454545454545454, 'support': 19}, 'Media/Journalism': {'precision': 0.1111111111111111, 'recall': 0.1, 'f1-score': 0.10526315789473685, 'support': 10}, 'Others': {'precision': 0.9327073552425665, 'recall': 0.8359046283309958, 'f1-score': 0.8816568047337278, 'support': 713}, 'Religion': {'precision': 0.5, 'recall': 0.5263157894736842, 'f1-score': 0.5128205128205129, 'support': 19}, 'Science/Technology': {'precision': 0.7142857142857143, 'recall': 0.25, 'f1-score': 0.37037037037037035, 'support': 20}, 'War/Terror': {'precision': 0.3333333333333333, 'recall': 0.8888888888888888, 'f1-score': 0.48484848484848486, 'support': 9}, 'micro avg': {'precision': 0.7774621212121212, 'recall': 0.7416440831074977, 'f1-score': 0.7591308368007398, 'support': 1107}, 'macro avg': {'precision': 0.5007812523375998, 'recall': 0.5462775837060542, 'f1-score': 0.4949478049802783, 'support': 1107}, 'weighted avg': {'precision': 0.8012743339929517, 'recall': 0.7416440831074977, 'f1-score': 0.7635447635874708, 'support': 1107}, 'samples avg': {'precision': 0.7771666666666668, 'recall': 0.7698333333333333, 'f1-score': 0.7666666666666666, 'support': 1107}}, {'Conspiracy Theory': {'precision': 0.6666666666666666, 'recall': 0.18181818181818182, 'f1-score': 0.28571428571428575, 'support': 11}, 'Education': {'precision': 0.5384615384615384, 'recall': 0.4666666666666667, 'f1-score': 0.5, 'support': 15}, 'Election Campaign': {'precision': 0.8125, 'recall': 0.3939393939393939, 'f1-score': 0.5306122448979591, 'support': 33}, 'Environment': {'precision': 0.4, 'recall': 0.6666666666666666, 'f1-score': 0.5, 'support': 6}, 'Government/Public': {'precision': 0.56353591160221, 'recall': 0.6415094339622641, 'f1-score': 0.6, 'support': 159}, 'Health': {'precision': 0.7555555555555555, 'recall': 0.7083333333333334, 'f1-score': 0.7311827956989247, 'support': 48}, 'Immigration/Integration': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1-score': 0.5714285714285715, 'support': 4}, 'Justice/Crime': {'precision': 0.34615384615384615, 'recall': 0.782608695652174, 'f1-score': 0.48, 'support': 23}, 'Labor/Employment': {'precision': 0.875, 'recall': 0.3888888888888889, 'f1-score': 0.5384615384615385, 'support': 18}, 'Macroeconomics/Economic Regulation': {'precision': 0.4838709677419355, 'recall': 0.7894736842105263, 'f1-score': 0.6, 'support': 19}, 'Media/Journalism': {'precision': 0.1, 'recall': 0.1, 'f1-score': 0.10000000000000002, 'support': 10}, 'Others': {'precision': 0.939297124600639, 'recall': 0.8246844319775596, 'f1-score': 0.878267363704257, 'support': 713}, 'Religion': {'precision': 0.5161290322580645, 'recall': 0.8421052631578947, 'f1-score': 0.6399999999999999, 'support': 19}, 'Science/Technology': {'precision': 0.3333333333333333, 'recall': 0.2, 'f1-score': 0.25, 'support': 20}, 'War/Terror': {'precision': 0.20512820512820512, 'recall': 0.8888888888888888, 'f1-score': 0.3333333333333333, 'support': 9}, 'micro avg': {'precision': 0.7601851851851852, 'recall': 0.7416440831074977, 'f1-score': 0.7508001828989483, 'support': 1107}, 'macro avg': {'precision': 0.546819923211244, 'recall': 0.5583722352774959, 'f1-score': 0.5026000088825913, 'support': 1107}, 'weighted avg': {'precision': 0.8085831151788216, 'recall': 0.7416440831074977, 'f1-score': 0.7619082996541964, 'support': 1107}, 'samples avg': {'precision': 0.7733333333333332, 'recall': 0.7665, 'f1-score': 0.7620666666666666, 'support': 1107}}, {'Conspiracy Theory': {'precision': 1.0, 'recall': 0.18181818181818182, 'f1-score': 0.3076923076923077, 'support': 11}, 'Education': {'precision': 0.5833333333333334, 'recall': 0.4666666666666667, 'f1-score': 0.5185185185185186, 'support': 15}, 'Election Campaign': {'precision': 0.7391304347826086, 'recall': 0.5151515151515151, 'f1-score': 0.6071428571428571, 'support': 33}, 'Environment': {'precision': 0.3125, 'recall': 0.8333333333333334, 'f1-score': 0.45454545454545453, 'support': 6}, 'Government/Public': {'precision': 0.5950920245398773, 'recall': 0.610062893081761, 'f1-score': 0.6024844720496895, 'support': 159}, 'Health': {'precision': 0.7948717948717948, 'recall': 0.6458333333333334, 'f1-score': 0.7126436781609194, 'support': 48}, 'Immigration/Integration': {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 4}, 'Justice/Crime': {'precision': 0.3617021276595745, 'recall': 0.7391304347826086, 'f1-score': 0.4857142857142858, 'support': 23}, 'Labor/Employment': {'precision': 0.8, 'recall': 0.2222222222222222, 'f1-score': 0.3478260869565218, 'support': 18}, 'Macroeconomics/Economic Regulation': {'precision': 0.41379310344827586, 'recall': 0.631578947368421, 'f1-score': 0.5, 'support': 19}, 'Media/Journalism': {'precision': 0.1, 'recall': 0.1, 'f1-score': 0.10000000000000002, 'support': 10}, 'Others': {'precision': 0.943089430894309, 'recall': 0.8134642356241234, 'f1-score': 0.8734939759036146, 'support': 713}, 'Religion': {'precision': 0.4864864864864865, 'recall': 0.9473684210526315, 'f1-score': 0.6428571428571428, 'support': 19}, 'Science/Technology': {'precision': 0.5, 'recall': 0.4, 'f1-score': 0.4444444444444445, 'support': 20}, 'War/Terror': {'precision': 0.22857142857142856, 'recall': 0.8888888888888888, 'f1-score': 0.3636363636363636, 'support': 9}, 'micro avg': {'precision': 0.7692307692307693, 'recall': 0.7317073170731707, 'f1-score': 0.7499999999999999, 'support': 1107}, 'macro avg': {'precision': 0.5739046776391792, 'recall': 0.5830346048882459, 'f1-score': 0.514066639174808, 'support': 1107}, 'weighted avg': {'precision': 0.8194165769044521, 'recall': 0.7317073170731707, 'f1-score': 0.760647436869765, 'support': 1107}, 'samples avg': {'precision': 0.7618333333333333, 'recall': 0.7548333333333332, 'f1-score': 0.7514666666666666, 'support': 1107}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11}, 'Education': {'precision': 1.0, 'recall': 0.2, 'f1-score': 0.33333333333333337, 'support': 15}, 'Election Campaign': {'precision': 0.7647058823529411, 'recall': 0.3939393939393939, 'f1-score': 0.5199999999999999, 'support': 33}, 'Environment': {'precision': 0.8, 'recall': 0.6666666666666666, 'f1-score': 0.7272727272727272, 'support': 6}, 'Government/Public': {'precision': 0.6370370370370371, 'recall': 0.5408805031446541, 'f1-score': 0.5850340136054422, 'support': 159}, 'Health': {'precision': 0.6458333333333334, 'recall': 0.6458333333333334, 'f1-score': 0.6458333333333334, 'support': 48}, 'Immigration/Integration': {'precision': 0.2857142857142857, 'recall': 0.5, 'f1-score': 0.36363636363636365, 'support': 4}, 'Justice/Crime': {'precision': 0.4473684210526316, 'recall': 0.7391304347826086, 'f1-score': 0.5573770491803278, 'support': 23}, 'Labor/Employment': {'precision': 0.7272727272727273, 'recall': 0.4444444444444444, 'f1-score': 0.5517241379310345, 'support': 18}, 'Macroeconomics/Economic Regulation': {'precision': 0.5882352941176471, 'recall': 0.5263157894736842, 'f1-score': 0.5555555555555555, 'support': 19}, 'Media/Journalism': {'precision': 0.2, 'recall': 0.2, 'f1-score': 0.20000000000000004, 'support': 10}, 'Others': {'precision': 0.9138187221396731, 'recall': 0.8625525946704067, 'f1-score': 0.8874458874458874, 'support': 713}, 'Religion': {'precision': 0.25, 'recall': 0.15789473684210525, 'f1-score': 0.1935483870967742, 'support': 19}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}, 'War/Terror': {'precision': 0.4, 'recall': 0.8888888888888888, 'f1-score': 0.5517241379310346, 'support': 9}, 'micro avg': {'precision': 0.8052208835341366, 'recall': 0.7244805781391147, 'f1-score': 0.762719923918212, 'support': 1107}, 'macro avg': {'precision': 0.5106657135346852, 'recall': 0.4511031190790791, 'f1-score': 0.4448323284214542, 'support': 1107}, 'weighted avg': {'precision': 0.7903583038828681, 'recall': 0.7244805781391147, 'f1-score': 0.7485968441698687, 'support': 1107}, 'samples avg': {'precision': 0.777, 'recall': 0.7556666666666667, 'f1-score': 0.7593, 'support': 1107}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11}, 'Education': {'precision': 0.6153846153846154, 'recall': 0.5333333333333333, 'f1-score': 0.5714285714285715, 'support': 15}, 'Election Campaign': {'precision': 0.7058823529411765, 'recall': 0.36363636363636365, 'f1-score': 0.48000000000000004, 'support': 33}, 'Environment': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 6}, 'Government/Public': {'precision': 0.6153846153846154, 'recall': 0.5031446540880503, 'f1-score': 0.5536332179930796, 'support': 159}, 'Health': {'precision': 0.6981132075471698, 'recall': 0.7708333333333334, 'f1-score': 0.7326732673267327, 'support': 48}, 'Immigration/Integration': {'precision': 0.2857142857142857, 'recall': 0.5, 'f1-score': 0.36363636363636365, 'support': 4}, 'Justice/Crime': {'precision': 0.391304347826087, 'recall': 0.782608695652174, 'f1-score': 0.5217391304347826, 'support': 23}, 'Labor/Employment': {'precision': 0.6666666666666666, 'recall': 0.3333333333333333, 'f1-score': 0.4444444444444444, 'support': 18}, 'Macroeconomics/Economic Regulation': {'precision': 0.44, 'recall': 0.5789473684210527, 'f1-score': 0.5, 'support': 19}, 'Media/Journalism': {'precision': 0.1, 'recall': 0.1, 'f1-score': 0.10000000000000002, 'support': 10}, 'Others': {'precision': 0.9049707602339181, 'recall': 0.8681626928471248, 'f1-score': 0.8861846814602719, 'support': 713}, 'Religion': {'precision': 0.42857142857142855, 'recall': 0.15789473684210525, 'f1-score': 0.23076923076923078, 'support': 19}, 'Science/Technology': {'precision': 1.0, 'recall': 0.15, 'f1-score': 0.2608695652173913, 'support': 20}, 'War/Terror': {'precision': 0.3076923076923077, 'recall': 0.8888888888888888, 'f1-score': 0.4571428571428572, 'support': 9}, 'micro avg': {'precision': 0.7828185328185329, 'recall': 0.7326106594399278, 'f1-score': 0.756882874475035, 'support': 1107}, 'macro avg': {'precision': 0.5106456391974847, 'recall': 0.4687188933583839, 'f1-score': 0.4401680886569151, 'support': 1107}, 'weighted avg': {'precision': 0.7900086466016031, 'recall': 0.7326106594399278, 'f1-score': 0.74808305582925, 'support': 1107}, 'samples avg': {'precision': 0.774, 'recall': 0.7611666666666668, 'f1-score': 0.7612000000000001, 'support': 1107}}]\n",
      "5\n",
      "\n",
      "Average Validation Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.653755  0.483364  0.537864     57.6\n",
      "Education                            0.744242  0.461492  0.534757     12.2\n",
      "Election Campaign                    0.847792  0.791610  0.814491     26.6\n",
      "Environment                          0.704029  0.470432  0.492222     13.2\n",
      "Government/Public                    0.782550  0.837060  0.808341    276.0\n",
      "Health                               0.849961  0.797170  0.821414     42.4\n",
      "Immigration/Integration              0.800588  0.789947  0.791698     46.6\n",
      "Justice/Crime                        0.833065  0.802707  0.816640    137.2\n",
      "Labor/Employment                     0.649334  0.463909  0.531617     21.4\n",
      "Macroeconomics/Economic Regulation   0.737651  0.734259  0.728629     58.6\n",
      "Media/Journalism                     0.805070  0.766517  0.785007     44.4\n",
      "Others                               0.837643  0.661895  0.737505    123.0\n",
      "Religion                             0.735784  0.577123  0.617627     12.6\n",
      "Science/Technology                   0.580000  0.296861  0.351648      9.0\n",
      "War/Terror                           0.921681  0.931993  0.926364    237.0\n",
      "micro avg                            0.816046  0.780742  0.797592   1117.8\n",
      "macro avg                            0.765543  0.657756  0.686388   1117.8\n",
      "weighted avg                         0.817853  0.780742  0.791354   1117.8\n",
      "samples avg                          0.822375  0.806221  0.797461   1117.8\n",
      "\n",
      "Average Test Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.333333  0.072727  0.118681     11.0\n",
      "Education                            0.641554  0.440000  0.484656     15.0\n",
      "Election Campaign                    0.764444  0.430303  0.548306     33.0\n",
      "Environment                          0.464038  0.666667  0.520574      6.0\n",
      "Government/Public                    0.597999  0.583648  0.588230    159.0\n",
      "Health                               0.733420  0.695833  0.712293     48.0\n",
      "Immigration/Integration              0.517619  0.600000  0.543074      4.0\n",
      "Justice/Crime                        0.378871  0.747826  0.501720     23.0\n",
      "Labor/Employment                     0.726288  0.377778  0.482374     18.0\n",
      "Macroeconomics/Economic Regulation   0.481180  0.631579  0.540202     19.0\n",
      "Media/Journalism                     0.122222  0.120000  0.121053     10.0\n",
      "Others                               0.926777  0.840954  0.881410    713.0\n",
      "Religion                             0.436237  0.526316  0.443999     19.0\n",
      "Science/Technology                   0.509524  0.200000  0.265137     20.0\n",
      "War/Terror                           0.294945  0.888889  0.438137      9.0\n",
      "micro avg                            0.778983  0.734417  0.755907   1107.0\n",
      "macro avg                            0.528563  0.521501  0.479323   1107.0\n",
      "weighted avg                         0.801928  0.734417  0.756556   1107.0\n",
      "samples avg                          0.772667  0.761600  0.760140   1107.0\n",
      "../models/VENEZUELA_201901_2_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/VENEZUELA_201901_2_epochs_200_train_size_full_fold_1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/VENEZUELA_201901_2_epochs_200_train_size_full_fold_2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/VENEZUELA_201901_2_epochs_200_train_size_full_fold_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/VENEZUELA_201901_2_epochs_200_train_size_full_fold_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_12238/1563409962.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'label': torch.tensor(label, dtype=torch.float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Conspiracy Theory': {'precision': 0.6216216216216216, 'recall': 0.5111111111111111, 'f1-score': 0.5609756097560976, 'support': 45}, 'Education': {'precision': 0.8571428571428571, 'recall': 0.5, 'f1-score': 0.631578947368421, 'support': 12}, 'Election Campaign': {'precision': 0.7241379310344828, 'recall': 0.84, 'f1-score': 0.7777777777777777, 'support': 25}, 'Environment': {'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1-score': 0.6153846153846153, 'support': 14}, 'Government/Public': {'precision': 0.7215909090909091, 'recall': 0.671957671957672, 'f1-score': 0.695890410958904, 'support': 189}, 'Health': {'precision': 0.851063829787234, 'recall': 0.7017543859649122, 'f1-score': 0.7692307692307693, 'support': 57}, 'Immigration/Integration': {'precision': 0.8095238095238095, 'recall': 0.6296296296296297, 'f1-score': 0.7083333333333334, 'support': 27}, 'Justice/Crime': {'precision': 0.803030303030303, 'recall': 0.8983050847457628, 'f1-score': 0.8480000000000001, 'support': 118}, 'Labor/Employment': {'precision': 0.7272727272727273, 'recall': 0.6956521739130435, 'f1-score': 0.711111111111111, 'support': 23}, 'Macroeconomics/Economic Regulation': {'precision': 0.7843137254901961, 'recall': 0.7142857142857143, 'f1-score': 0.7476635514018691, 'support': 56}, 'Media/Journalism': {'precision': 0.7916666666666666, 'recall': 0.6333333333333333, 'f1-score': 0.7037037037037038, 'support': 30}, 'Others': {'precision': 0.8805970149253731, 'recall': 0.8009049773755657, 'f1-score': 0.8388625592417063, 'support': 221}, 'Religion': {'precision': 0.3333333333333333, 'recall': 0.5, 'f1-score': 0.4, 'support': 8}, 'Science/Technology': {'precision': 0.3333333333333333, 'recall': 0.16666666666666666, 'f1-score': 0.2222222222222222, 'support': 6}, 'War/Terror': {'precision': 0.9585253456221198, 'recall': 0.9411764705882353, 'f1-score': 0.9497716894977167, 'support': 221}, 'micro avg': {'precision': 0.8203834510595358, 'recall': 0.7728136882129277, 'f1-score': 0.7958883994126285, 'support': 1052}, 'macro avg': {'precision': 0.7242546716361089, 'recall': 0.651747052733348, 'f1-score': 0.6787004200658832, 'support': 1052}, 'weighted avg': {'precision': 0.8200694461036517, 'recall': 0.7728136882129277, 'f1-score': 0.7933445325423749, 'support': 1052}, 'samples avg': {'precision': 0.8270833333333333, 'recall': 0.8021458333333333, 'f1-score': 0.8006140873015872, 'support': 1052}}, {'Conspiracy Theory': {'precision': 0.8, 'recall': 0.2926829268292683, 'f1-score': 0.4285714285714285, 'support': 41}, 'Education': {'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'f1-score': 0.5, 'support': 9}, 'Election Campaign': {'precision': 0.7083333333333334, 'recall': 0.7727272727272727, 'f1-score': 0.7391304347826088, 'support': 22}, 'Environment': {'precision': 1.0, 'recall': 0.4, 'f1-score': 0.5714285714285715, 'support': 10}, 'Government/Public': {'precision': 0.6564102564102564, 'recall': 0.735632183908046, 'f1-score': 0.6937669376693767, 'support': 174}, 'Health': {'precision': 0.8529411764705882, 'recall': 0.6744186046511628, 'f1-score': 0.7532467532467532, 'support': 43}, 'Immigration/Integration': {'precision': 0.9523809523809523, 'recall': 0.7407407407407407, 'f1-score': 0.8333333333333334, 'support': 27}, 'Justice/Crime': {'precision': 0.8681318681318682, 'recall': 0.7821782178217822, 'f1-score': 0.8229166666666666, 'support': 101}, 'Labor/Employment': {'precision': 0.75, 'recall': 0.4838709677419355, 'f1-score': 0.5882352941176471, 'support': 31}, 'Macroeconomics/Economic Regulation': {'precision': 0.7755102040816326, 'recall': 0.6229508196721312, 'f1-score': 0.6909090909090909, 'support': 61}, 'Media/Journalism': {'precision': 0.7, 'recall': 0.4827586206896552, 'f1-score': 0.5714285714285714, 'support': 29}, 'Others': {'precision': 0.8512396694214877, 'recall': 0.8442622950819673, 'f1-score': 0.8477366255144033, 'support': 244}, 'Religion': {'precision': 0.6666666666666666, 'recall': 0.3333333333333333, 'f1-score': 0.4444444444444444, 'support': 6}, 'Science/Technology': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 8}, 'War/Terror': {'precision': 0.9319148936170213, 'recall': 0.9279661016949152, 'f1-score': 0.9299363057324841, 'support': 236}, 'micro avg': {'precision': 0.8201663201663202, 'recall': 0.7571976967370442, 'f1-score': 0.787425149700599, 'support': 1042}, 'macro avg': {'precision': 0.8056638394628252, 'recall': 0.5858644352891103, 'f1-score': 0.6543389638563588, 'support': 1042}, 'weighted avg': {'precision': 0.823708413394294, 'recall': 0.7571976967370442, 'f1-score': 0.7791725272628834, 'support': 1042}, 'samples avg': {'precision': 0.8220833333333333, 'recall': 0.795625, 'f1-score': 0.7931011904761904, 'support': 1042}}, {'Conspiracy Theory': {'precision': 0.7941176470588235, 'recall': 0.5192307692307693, 'f1-score': 0.627906976744186, 'support': 52}, 'Education': {'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1-score': 0.6666666666666666, 'support': 12}, 'Election Campaign': {'precision': 1.0, 'recall': 0.6842105263157895, 'f1-score': 0.8125000000000001, 'support': 19}, 'Environment': {'precision': 1.0, 'recall': 0.4, 'f1-score': 0.5714285714285715, 'support': 10}, 'Government/Public': {'precision': 0.6771300448430493, 'recall': 0.7947368421052632, 'f1-score': 0.7312348668280871, 'support': 190}, 'Health': {'precision': 0.9032258064516129, 'recall': 0.9032258064516129, 'f1-score': 0.9032258064516129, 'support': 31}, 'Immigration/Integration': {'precision': 0.7368421052631579, 'recall': 0.6363636363636364, 'f1-score': 0.6829268292682926, 'support': 22}, 'Justice/Crime': {'precision': 0.8315789473684211, 'recall': 0.797979797979798, 'f1-score': 0.8144329896907218, 'support': 99}, 'Labor/Employment': {'precision': 0.7647058823529411, 'recall': 0.52, 'f1-score': 0.6190476190476191, 'support': 25}, 'Macroeconomics/Economic Regulation': {'precision': 0.7678571428571429, 'recall': 0.7543859649122807, 'f1-score': 0.7610619469026548, 'support': 57}, 'Media/Journalism': {'precision': 0.9090909090909091, 'recall': 0.5128205128205128, 'f1-score': 0.6557377049180326, 'support': 39}, 'Others': {'precision': 0.8689320388349514, 'recall': 0.8136363636363636, 'f1-score': 0.8403755868544601, 'support': 220}, 'Religion': {'precision': 0.75, 'recall': 0.2727272727272727, 'f1-score': 0.39999999999999997, 'support': 11}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, 'War/Terror': {'precision': 0.9606986899563319, 'recall': 0.9016393442622951, 'f1-score': 0.930232558139535, 'support': 244}, 'micro avg': {'precision': 0.8310880829015544, 'recall': 0.7681992337164751, 'f1-score': 0.798407167745147, 'support': 1044}, 'macro avg': {'precision': 0.7753897253829339, 'recall': 0.6118415668981508, 'f1-score': 0.6677852081960294, 'support': 1044}, 'weighted avg': {'precision': 0.8291678609403849, 'recall': 0.7681992337164751, 'f1-score': 0.7903071787941347, 'support': 1044}, 'samples avg': {'precision': 0.8336458333333334, 'recall': 0.8032291666666665, 'f1-score': 0.8043095238095238, 'support': 1044}}, {'Conspiracy Theory': {'precision': 0.5, 'recall': 0.5588235294117647, 'f1-score': 0.5277777777777778, 'support': 34}, 'Education': {'precision': 0.8, 'recall': 0.5714285714285714, 'f1-score': 0.6666666666666666, 'support': 14}, 'Election Campaign': {'precision': 0.8421052631578947, 'recall': 0.7619047619047619, 'f1-score': 0.8, 'support': 21}, 'Environment': {'precision': 0.75, 'recall': 0.6428571428571429, 'f1-score': 0.6923076923076924, 'support': 14}, 'Government/Public': {'precision': 0.7567567567567568, 'recall': 0.7446808510638298, 'f1-score': 0.7506702412868633, 'support': 188}, 'Health': {'precision': 0.8260869565217391, 'recall': 0.7307692307692307, 'f1-score': 0.7755102040816326, 'support': 52}, 'Immigration/Integration': {'precision': 0.84, 'recall': 0.5675675675675675, 'f1-score': 0.6774193548387097, 'support': 37}, 'Justice/Crime': {'precision': 0.8947368421052632, 'recall': 0.8252427184466019, 'f1-score': 0.8585858585858587, 'support': 103}, 'Labor/Employment': {'precision': 0.6428571428571429, 'recall': 0.5294117647058824, 'f1-score': 0.5806451612903226, 'support': 17}, 'Macroeconomics/Economic Regulation': {'precision': 0.8918918918918919, 'recall': 0.6226415094339622, 'f1-score': 0.7333333333333333, 'support': 53}, 'Media/Journalism': {'precision': 0.875, 'recall': 0.65625, 'f1-score': 0.75, 'support': 32}, 'Others': {'precision': 0.8851674641148325, 'recall': 0.7676348547717843, 'f1-score': 0.8222222222222222, 'support': 241}, 'Religion': {'precision': 0.4, 'recall': 0.2857142857142857, 'f1-score': 0.3333333333333333, 'support': 14}, 'Science/Technology': {'precision': 0.5, 'recall': 0.125, 'f1-score': 0.2, 'support': 8}, 'War/Terror': {'precision': 0.8725868725868726, 'recall': 0.9576271186440678, 'f1-score': 0.9131313131313131, 'support': 236}, 'micro avg': {'precision': 0.8274111675126904, 'recall': 0.7659774436090225, 'f1-score': 0.7955100048804296, 'support': 1064}, 'macro avg': {'precision': 0.7518126126661595, 'recall': 0.6231702604479635, 'f1-score': 0.6721068772570484, 'support': 1064}, 'weighted avg': {'precision': 0.8269770674375722, 'recall': 0.7659774436090225, 'f1-score': 0.790770984527679, 'support': 1064}, 'samples avg': {'precision': 0.826875, 'recall': 0.7987083333333334, 'f1-score': 0.7997063492063492, 'support': 1064}}, {'Conspiracy Theory': {'precision': 0.8260869565217391, 'recall': 0.4634146341463415, 'f1-score': 0.59375, 'support': 41}, 'Education': {'precision': 1.0, 'recall': 0.21428571428571427, 'f1-score': 0.35294117647058826, 'support': 14}, 'Election Campaign': {'precision': 0.8947368421052632, 'recall': 0.5483870967741935, 'f1-score': 0.6799999999999999, 'support': 31}, 'Environment': {'precision': 1.0, 'recall': 0.16666666666666666, 'f1-score': 0.2857142857142857, 'support': 12}, 'Government/Public': {'precision': 0.7333333333333333, 'recall': 0.7021276595744681, 'f1-score': 0.7173913043478262, 'support': 188}, 'Health': {'precision': 0.7954545454545454, 'recall': 0.7954545454545454, 'f1-score': 0.7954545454545455, 'support': 44}, 'Immigration/Integration': {'precision': 0.9333333333333333, 'recall': 0.5384615384615384, 'f1-score': 0.6829268292682926, 'support': 26}, 'Justice/Crime': {'precision': 0.91, 'recall': 0.7583333333333333, 'f1-score': 0.8272727272727273, 'support': 120}, 'Labor/Employment': {'precision': 0.875, 'recall': 0.4375, 'f1-score': 0.5833333333333334, 'support': 16}, 'Macroeconomics/Economic Regulation': {'precision': 0.7021276595744681, 'recall': 0.6875, 'f1-score': 0.6947368421052632, 'support': 48}, 'Media/Journalism': {'precision': 0.7368421052631579, 'recall': 0.5185185185185185, 'f1-score': 0.6086956521739131, 'support': 27}, 'Others': {'precision': 0.8975609756097561, 'recall': 0.7666666666666667, 'f1-score': 0.8269662921348315, 'support': 240}, 'Religion': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, 'War/Terror': {'precision': 0.8826086956521739, 'recall': 0.9441860465116279, 'f1-score': 0.9123595505617977, 'support': 215}, 'micro avg': {'precision': 0.8424581005586592, 'recall': 0.7215311004784689, 'f1-score': 0.777319587628866, 'support': 1045}, 'macro avg': {'precision': 0.7458056297898514, 'recall': 0.502766828026241, 'f1-score': 0.5707695025891603, 'support': 1045}, 'weighted avg': {'precision': 0.8293895778652883, 'recall': 0.7215311004784689, 'f1-score': 0.7602263978913698, 'support': 1045}, 'samples avg': {'precision': 0.8133333333333332, 'recall': 0.7571875, 'f1-score': 0.7708214285714285, 'support': 1045}}]\n",
      "5\n",
      "[{'Conspiracy Theory': {'precision': 0.3888888888888889, 'recall': 0.08139534883720931, 'f1-score': 0.13461538461538464, 'support': 86}, 'Education': {'precision': 0.6, 'recall': 0.2, 'f1-score': 0.3, 'support': 15}, 'Election Campaign': {'precision': 0.6774193548387096, 'recall': 0.875, 'f1-score': 0.7636363636363636, 'support': 48}, 'Environment': {'precision': 1.0, 'recall': 0.4166666666666667, 'f1-score': 0.5882352941176471, 'support': 12}, 'Government/Public': {'precision': 0.9168443496801706, 'recall': 0.7049180327868853, 'f1-score': 0.7970342910101947, 'support': 610}, 'Health': {'precision': 0.8275862068965517, 'recall': 0.7272727272727273, 'f1-score': 0.7741935483870968, 'support': 33}, 'Immigration/Integration': {'precision': 0.8571428571428571, 'recall': 0.6122448979591837, 'f1-score': 0.7142857142857143, 'support': 98}, 'Justice/Crime': {'precision': 0.6464646464646465, 'recall': 0.7619047619047619, 'f1-score': 0.6994535519125683, 'support': 168}, 'Labor/Employment': {'precision': 0.5833333333333334, 'recall': 0.5384615384615384, 'f1-score': 0.5599999999999999, 'support': 13}, 'Macroeconomics/Economic Regulation': {'precision': 0.7297297297297297, 'recall': 0.7297297297297297, 'f1-score': 0.7297297297297297, 'support': 37}, 'Media/Journalism': {'precision': 0.8387096774193549, 'recall': 0.6933333333333334, 'f1-score': 0.7591240875912408, 'support': 75}, 'Others': {'precision': 0.6270270270270271, 'recall': 0.7160493827160493, 'f1-score': 0.6685878962536024, 'support': 162}, 'Religion': {'precision': 0.8181818181818182, 'recall': 0.5454545454545454, 'f1-score': 0.6545454545454545, 'support': 33}, 'Science/Technology': {'precision': 0.875, 'recall': 0.4117647058823529, 'f1-score': 0.56, 'support': 17}, 'War/Terror': {'precision': 0.6140350877192983, 'recall': 0.8333333333333334, 'f1-score': 0.7070707070707071, 'support': 42}, 'micro avg': {'precision': 0.7756255044390638, 'recall': 0.663216011042098, 'f1-score': 0.715029761904762, 'support': 1449}, 'macro avg': {'precision': 0.7333575318214923, 'recall': 0.5898352669558877, 'f1-score': 0.6273674682103804, 'support': 1449}, 'weighted avg': {'precision': 0.7818367449397015, 'recall': 0.663216011042098, 'f1-score': 0.7035060792647213, 'support': 1449}, 'samples avg': {'precision': 0.7578333333333334, 'recall': 0.6936666666666668, 'f1-score': 0.7017333333333333, 'support': 1449}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, 'Education': {'precision': 0.5714285714285714, 'recall': 0.26666666666666666, 'f1-score': 0.36363636363636365, 'support': 15}, 'Election Campaign': {'precision': 0.8297872340425532, 'recall': 0.8125, 'f1-score': 0.8210526315789474, 'support': 48}, 'Environment': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 12}, 'Government/Public': {'precision': 0.8758620689655172, 'recall': 0.8327868852459016, 'f1-score': 0.853781512605042, 'support': 610}, 'Health': {'precision': 0.9, 'recall': 0.2727272727272727, 'f1-score': 0.41860465116279066, 'support': 33}, 'Immigration/Integration': {'precision': 0.8888888888888888, 'recall': 0.4897959183673469, 'f1-score': 0.631578947368421, 'support': 98}, 'Justice/Crime': {'precision': 0.6866666666666666, 'recall': 0.6130952380952381, 'f1-score': 0.6477987421383649, 'support': 168}, 'Labor/Employment': {'precision': 0.6923076923076923, 'recall': 0.6923076923076923, 'f1-score': 0.6923076923076923, 'support': 13}, 'Macroeconomics/Economic Regulation': {'precision': 0.6511627906976745, 'recall': 0.7567567567567568, 'f1-score': 0.7000000000000001, 'support': 37}, 'Media/Journalism': {'precision': 0.8627450980392157, 'recall': 0.5866666666666667, 'f1-score': 0.6984126984126984, 'support': 75}, 'Others': {'precision': 0.6216216216216216, 'recall': 0.7098765432098766, 'f1-score': 0.6628242074927955, 'support': 162}, 'Religion': {'precision': 0.9166666666666666, 'recall': 0.3333333333333333, 'f1-score': 0.4888888888888888, 'support': 33}, 'Science/Technology': {'precision': 1.0, 'recall': 0.11764705882352941, 'f1-score': 0.21052631578947367, 'support': 17}, 'War/Terror': {'precision': 0.6470588235294118, 'recall': 0.7857142857142857, 'f1-score': 0.7096774193548386, 'support': 42}, 'micro avg': {'precision': 0.7907361455748553, 'recall': 0.6597653554175293, 'f1-score': 0.7193378480060196, 'support': 1449}, 'macro avg': {'precision': 0.7429464081902987, 'recall': 0.5013249545276378, 'f1-score': 0.5532726713824212, 'support': 1449}, 'weighted avg': {'precision': 0.758989832909069, 'recall': 0.6597653554175293, 'f1-score': 0.6895706554717571, 'support': 1449}, 'samples avg': {'precision': 0.7734, 'recall': 0.6966666666666667, 'f1-score': 0.7123047619047619, 'support': 1449}}, {'Conspiracy Theory': {'precision': 0.5714285714285714, 'recall': 0.046511627906976744, 'f1-score': 0.08602150537634408, 'support': 86}, 'Education': {'precision': 0.6666666666666666, 'recall': 0.4, 'f1-score': 0.5, 'support': 15}, 'Election Campaign': {'precision': 0.7735849056603774, 'recall': 0.8541666666666666, 'f1-score': 0.811881188118812, 'support': 48}, 'Environment': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 12}, 'Government/Public': {'precision': 0.8981481481481481, 'recall': 0.7950819672131147, 'f1-score': 0.8434782608695651, 'support': 610}, 'Health': {'precision': 0.7142857142857143, 'recall': 0.6060606060606061, 'f1-score': 0.6557377049180327, 'support': 33}, 'Immigration/Integration': {'precision': 0.8888888888888888, 'recall': 0.40816326530612246, 'f1-score': 0.5594405594405595, 'support': 98}, 'Justice/Crime': {'precision': 0.872093023255814, 'recall': 0.44642857142857145, 'f1-score': 0.5905511811023623, 'support': 168}, 'Labor/Employment': {'precision': 0.5625, 'recall': 0.6923076923076923, 'f1-score': 0.6206896551724138, 'support': 13}, 'Macroeconomics/Economic Regulation': {'precision': 0.5777777777777777, 'recall': 0.7027027027027027, 'f1-score': 0.6341463414634145, 'support': 37}, 'Media/Journalism': {'precision': 0.8666666666666667, 'recall': 0.3466666666666667, 'f1-score': 0.49523809523809526, 'support': 75}, 'Others': {'precision': 0.5849056603773585, 'recall': 0.7654320987654321, 'f1-score': 0.6631016042780749, 'support': 162}, 'Religion': {'precision': 1.0, 'recall': 0.18181818181818182, 'f1-score': 0.3076923076923077, 'support': 33}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17}, 'War/Terror': {'precision': 0.7111111111111111, 'recall': 0.7619047619047619, 'f1-score': 0.735632183908046, 'support': 42}, 'micro avg': {'precision': 0.7973333333333333, 'recall': 0.6190476190476191, 'f1-score': 0.696969696969697, 'support': 1449}, 'macro avg': {'precision': 0.712537142284473, 'recall': 0.4838163205831663, 'f1-score': 0.5269073725052018, 'support': 1449}, 'weighted avg': {'precision': 0.8037619958592259, 'recall': 0.6190476190476191, 'f1-score': 0.6666770864047253, 'support': 1449}, 'samples avg': {'precision': 0.758, 'recall': 0.6598333333333334, 'f1-score': 0.6867666666666666, 'support': 1449}}, {'Conspiracy Theory': {'precision': 0.4166666666666667, 'recall': 0.05813953488372093, 'f1-score': 0.10204081632653061, 'support': 86}, 'Education': {'precision': 0.5, 'recall': 0.2, 'f1-score': 0.28571428571428575, 'support': 15}, 'Election Campaign': {'precision': 0.9090909090909091, 'recall': 0.8333333333333334, 'f1-score': 0.8695652173913043, 'support': 48}, 'Environment': {'precision': 0.7142857142857143, 'recall': 0.4166666666666667, 'f1-score': 0.5263157894736842, 'support': 12}, 'Government/Public': {'precision': 0.8913443830570903, 'recall': 0.7934426229508197, 'f1-score': 0.8395490026019081, 'support': 610}, 'Health': {'precision': 0.7777777777777778, 'recall': 0.8484848484848485, 'f1-score': 0.8115942028985507, 'support': 33}, 'Immigration/Integration': {'precision': 0.9117647058823529, 'recall': 0.3163265306122449, 'f1-score': 0.4696969696969697, 'support': 98}, 'Justice/Crime': {'precision': 0.7716535433070866, 'recall': 0.5833333333333334, 'f1-score': 0.6644067796610169, 'support': 168}, 'Labor/Employment': {'precision': 0.5555555555555556, 'recall': 0.38461538461538464, 'f1-score': 0.4545454545454546, 'support': 13}, 'Macroeconomics/Economic Regulation': {'precision': 0.6388888888888888, 'recall': 0.6216216216216216, 'f1-score': 0.6301369863013699, 'support': 37}, 'Media/Journalism': {'precision': 0.6875, 'recall': 0.7333333333333333, 'f1-score': 0.7096774193548386, 'support': 75}, 'Others': {'precision': 0.7404580152671756, 'recall': 0.5987654320987654, 'f1-score': 0.6621160409556314, 'support': 162}, 'Religion': {'precision': 1.0, 'recall': 0.36363636363636365, 'f1-score': 0.5333333333333333, 'support': 33}, 'Science/Technology': {'precision': 0.8571428571428571, 'recall': 0.35294117647058826, 'f1-score': 0.5, 'support': 17}, 'War/Terror': {'precision': 0.5223880597014925, 'recall': 0.8333333333333334, 'f1-score': 0.6422018348623852, 'support': 42}, 'micro avg': {'precision': 0.8053866203301477, 'recall': 0.639751552795031, 'f1-score': 0.7130769230769232, 'support': 1449}, 'macro avg': {'precision': 0.7263011384415712, 'recall': 0.5291982343582905, 'f1-score': 0.5800596088744843, 'support': 1449}, 'weighted avg': {'precision': 0.7976591711442123, 'recall': 0.639751552795031, 'f1-score': 0.6904482596599859, 'support': 1449}, 'samples avg': {'precision': 0.773, 'recall': 0.6833333333333332, 'f1-score': 0.7027666666666667, 'support': 1449}}, {'Conspiracy Theory': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, 'Education': {'precision': 1.0, 'recall': 0.06666666666666667, 'f1-score': 0.125, 'support': 15}, 'Election Campaign': {'precision': 0.8636363636363636, 'recall': 0.7916666666666666, 'f1-score': 0.8260869565217391, 'support': 48}, 'Environment': {'precision': 1.0, 'recall': 0.08333333333333333, 'f1-score': 0.15384615384615385, 'support': 12}, 'Government/Public': {'precision': 0.9224137931034483, 'recall': 0.7016393442622951, 'f1-score': 0.7970204841713222, 'support': 610}, 'Health': {'precision': 0.7666666666666667, 'recall': 0.696969696969697, 'f1-score': 0.7301587301587302, 'support': 33}, 'Immigration/Integration': {'precision': 0.9629629629629629, 'recall': 0.2653061224489796, 'f1-score': 0.41600000000000004, 'support': 98}, 'Justice/Crime': {'precision': 0.8073394495412844, 'recall': 0.5238095238095238, 'f1-score': 0.6353790613718412, 'support': 168}, 'Labor/Employment': {'precision': 0.5555555555555556, 'recall': 0.38461538461538464, 'f1-score': 0.4545454545454546, 'support': 13}, 'Macroeconomics/Economic Regulation': {'precision': 0.6585365853658537, 'recall': 0.7297297297297297, 'f1-score': 0.6923076923076923, 'support': 37}, 'Media/Journalism': {'precision': 0.7647058823529411, 'recall': 0.6933333333333334, 'f1-score': 0.7272727272727272, 'support': 75}, 'Others': {'precision': 0.6392405063291139, 'recall': 0.6234567901234568, 'f1-score': 0.63125, 'support': 162}, 'Religion': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 33}, 'Science/Technology': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17}, 'War/Terror': {'precision': 0.603448275862069, 'recall': 0.8333333333333334, 'f1-score': 0.7, 'support': 42}, 'micro avg': {'precision': 0.8160237388724035, 'recall': 0.5693581780538303, 'f1-score': 0.6707317073170732, 'support': 1449}, 'macro avg': {'precision': 0.6363004027584173, 'recall': 0.4262573283528266, 'f1-score': 0.4592578173463774, 'support': 1449}, 'weighted avg': {'precision': 0.7620932807520412, 'recall': 0.5693581780538303, 'f1-score': 0.6341581598201114, 'support': 1449}, 'samples avg': {'precision': 0.7086666666666667, 'recall': 0.6065, 'f1-score': 0.6351333333333333, 'support': 1449}}]\n",
      "5\n",
      "\n",
      "Average Validation Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.708365  0.469053  0.547796     42.6\n",
      "Education                            0.779048  0.479365  0.563571     12.2\n",
      "Election Campaign                    0.833863  0.721446  0.761882     23.6\n",
      "Environment                          0.883333  0.436190  0.547253     12.0\n",
      "Government/Public                    0.709044  0.729827  0.717791    185.8\n",
      "Health                               0.845754  0.761125  0.799334     45.4\n",
      "Immigration/Integration              0.854416  0.622553  0.716988     27.8\n",
      "Justice/Crime                        0.861496  0.812408  0.834242    108.2\n",
      "Labor/Employment                     0.751967  0.533287  0.616475     22.4\n",
      "Macroeconomics/Economic Regulation   0.784340  0.680353  0.725541     55.0\n",
      "Media/Journalism                     0.802520  0.560736  0.657913     31.4\n",
      "Others                               0.876699  0.798621  0.835233    233.2\n",
      "Religion                             0.430000  0.278355  0.315556      9.8\n",
      "Science/Technology                   0.366667  0.108333  0.164444      9.6\n",
      "War/Terror                           0.921267  0.934519  0.927086    230.4\n",
      "micro avg                            0.828301  0.757144  0.790910   1049.4\n",
      "macro avg                            0.760585  0.595078  0.648740   1049.4\n",
      "weighted avg                         0.825862  0.757144  0.782764   1049.4\n",
      "samples avg                          0.824604  0.791379  0.793711   1049.4\n",
      "\n",
      "Average Test Classification Report In DataFrame Format:\n",
      "                                    precision    recall  f1-score  support\n",
      "Conspiracy Theory                    0.275397  0.037209  0.064536     86.0\n",
      "Education                            0.667619  0.226667  0.314870     15.0\n",
      "Election Campaign                    0.810704  0.833333  0.818444     48.0\n",
      "Environment                          0.942857  0.283333  0.413679     12.0\n",
      "Government/Public                    0.900923  0.765574  0.826173    610.0\n",
      "Health                               0.797263  0.630303  0.678058     33.0\n",
      "Immigration/Integration              0.901930  0.418367  0.558200     98.0\n",
      "Justice/Crime                        0.756843  0.585714  0.647518    168.0\n",
      "Labor/Employment                     0.589850  0.538462  0.556418     13.0\n",
      "Macroeconomics/Economic Regulation   0.651219  0.708108  0.677264     37.0\n",
      "Media/Journalism                     0.804065  0.610667  0.677945     75.0\n",
      "Others                               0.642651  0.682716  0.657576    162.0\n",
      "Religion                             0.746970  0.284848  0.396892     33.0\n",
      "Science/Technology                   0.546429  0.176471  0.254105     17.0\n",
      "War/Terror                           0.619608  0.809524  0.698916     42.0\n",
      "micro avg                            0.797021  0.630228  0.703029   1449.0\n",
      "macro avg                            0.710289  0.506086  0.549373   1449.0\n",
      "weighted avg                         0.780868  0.630228  0.676872   1449.0\n",
      "samples avg                          0.754180  0.668000  0.687741   1449.0\n"
     ]
    }
   ],
   "source": [
    "def model_summary(model):\n",
    "    print(\"Model summary:\")\n",
    "    print(\"---------------------------\")\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        param_count = param.numel()\n",
    "        total_params += param_count\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    \n",
    "\"\"\"def print_report(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=categories)\n",
    "    print(report)\n",
    "    sns.heatmap(cm, annot=True, xticklabels=categories, yticklabels=categories, fmt='g')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, x, y, mlb, tokenizer):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mlb = mlb\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoded_tweets = self.preprocess_text(self.x)\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        return self.tokenizer(text, return_attention_mask=True, return_tensors='pt', padding=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        return {'input_ids': self.encoded_tweets['input_ids'][idx],\n",
    "                'attention_mask': self.encoded_tweets['attention_mask'][idx],\n",
    "                'label': torch.tensor(label, dtype=torch.float32)}\n",
    "        \n",
    "class MultiLabelDataCollator(DataCollatorWithPadding):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__(tokenizer)\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, torch.Tensor]]):\n",
    "        batch = super().__call__(features)\n",
    "        batch[\"labels\"] = torch.stack([feature[\"label\"] for feature in features])\n",
    "        return batch\n",
    "    \n",
    "def get_classification_report(data_loader, model, target_names, label_names):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for batch in data_loader:\n",
    "        batch_inputs = {'input_ids': batch['input_ids'].to(device),\n",
    "                        'attention_mask': batch['attention_mask'].to(device)}\n",
    "        with torch.no_grad():\n",
    "            logits = model(**batch_inputs).logits\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(torch.Tensor(logits))\n",
    "        batch_predictions = (probs >= 0.5).detach().cpu().numpy().astype(int)\n",
    "        predictions.append(batch_predictions)\n",
    "        labels.append(batch['labels'].detach().cpu().numpy().astype(int))\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    labels = np.concatenate(labels, axis = 0)\n",
    "\n",
    "    #cm = multilabel_confusion_matrix(labels, predictions)\n",
    "    dict_report = classification_report(labels, predictions, target_names=target_names, labels=label_names, zero_division=0, output_dict=True)\n",
    "    report = classification_report(labels, predictions, target_names=target_names, labels=label_names, zero_division=0)\n",
    "    return dict_report, report\n",
    "    \n",
    "def calculate_average_report(reports):\n",
    "    print(reports)\n",
    "    print(len(reports))\n",
    "    avg_report = {}\n",
    "    for report in reports:\n",
    "        for key, scores in report.items():\n",
    "            if key not in avg_report:\n",
    "                avg_report[key] = {}\n",
    "                for score_key, score_value in scores.items():\n",
    "                    avg_report[key][score_key] = score_value\n",
    "            else:\n",
    "                for score_key, score_value in scores.items():\n",
    "                    avg_report[key][score_key] += score_value\n",
    "\n",
    "    num_reports = len(reports)\n",
    "    for key, scores in avg_report.items():\n",
    "        for score_key in scores:\n",
    "            avg_report[key][score_key] /= num_reports\n",
    "\n",
    "    return avg_report\n",
    "\n",
    "def average_report_to_dataframe(average_report):\n",
    "    data = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1-score\": [],\n",
    "        \"support\": []\n",
    "    }\n",
    "    index = []\n",
    "\n",
    "    for class_name, metrics in average_report.items():\n",
    "        if class_name == 'accuracy':\n",
    "            continue\n",
    "\n",
    "        index.append(class_name)\n",
    "        data[\"precision\"].append(metrics[\"precision\"])\n",
    "        data[\"recall\"].append(metrics[\"recall\"])\n",
    "        data[\"f1-score\"].append(metrics[\"f1-score\"])\n",
    "        data[\"support\"].append(metrics[\"support\"])\n",
    "\n",
    "    return pd.DataFrame(data, index=index)\n",
    "\n",
    "def calculate_metrics(task):\n",
    "    k = 5\n",
    "    \n",
    "    val_classification_reports = []\n",
    "    test_classification_reports = []\n",
    "\n",
    "    # Loop over each fold and load the corresponding model\n",
    "    for fold in range(k):\n",
    "        model_path = f\"../models/{task}_epochs_200_train_size_full_fold_{fold}\"\n",
    "        # find the latest checkpoint file\n",
    "        #checkpoint_files = [f for f in os.listdir(model_path) if f.startswith(\"checkpoint\")]\n",
    "        latest_checkpoint = os.path.join(model_path, \"\")  # use \"\" for models that were manually saved after training. use sorted(checkpoint_files)[0] for the first automatically saved checkpoint \n",
    "        print(latest_checkpoint)\n",
    "        \n",
    "        # Load the model and tokenizer\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint)\n",
    "        model.to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n",
    "\n",
    "        filename = f\"../data/labeled_data/{task}_test_{fold}.json\"\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "        train_df = pd.DataFrame(data[\"train\"])\n",
    "        val_df = pd.DataFrame(data[\"valid\"])\n",
    "        test_df = pd.DataFrame(data[\"test\"])\n",
    "        \n",
    "        train_annotations = train_df[\"annotations\"].tolist()\n",
    "        classes = set()\n",
    "        for annotation in train_annotations:\n",
    "            classes.update(annotation)\n",
    "        classes = sorted(list(classes))\n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(model_path, \"pytorch_model.bin\"))\n",
    "        model.load_state_dict(checkpoint)\n",
    "        \n",
    "        mlb = MultiLabelBinarizer(classes=classes)\n",
    "        \n",
    "        train_labels = mlb.fit_transform(train_df[\"annotations\"])\n",
    "        val_labels = mlb.transform(val_df[\"annotations\"])\n",
    "        test_labels = mlb.transform(test_df[\"annotations\"])\n",
    "        \n",
    "        train_dataset = TweetDataset(train_df['text'].to_list(), torch.tensor(train_labels), mlb, tokenizer)\n",
    "        val_dataset = TweetDataset(val_df['text'].to_list(), torch.tensor(val_labels), mlb, tokenizer)\n",
    "        test_dataset = TweetDataset(test_df['text'].to_list(), torch.tensor(test_labels), mlb, tokenizer)\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=256, shuffle=False, collate_fn=MultiLabelDataCollator(tokenizer)\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=256, shuffle=False, collate_fn=MultiLabelDataCollator(tokenizer)\n",
    "        )\n",
    "        \n",
    "        model.eval()\n",
    "        val_report_dict, val_report = get_classification_report(val_loader, model, classes, range(len(classes)))\n",
    "        test_report_dict, test_report = get_classification_report(test_loader, model, classes, range(len(classes)))\n",
    "        val_classification_reports.append(val_report_dict)\n",
    "        test_classification_reports.append(test_report_dict)\n",
    "\n",
    "    val_average_report = calculate_average_report(val_classification_reports)\n",
    "    test_average_report = calculate_average_report(test_classification_reports)\n",
    "    val_average_report_df = average_report_to_dataframe(val_average_report)\n",
    "    test_average_report_df = average_report_to_dataframe(test_average_report)\n",
    "    print(\"\\nAverage Validation Classification Report In DataFrame Format:\")\n",
    "    print(val_average_report_df) \n",
    "    print(\"\\nAverage Test Classification Report In DataFrame Format:\")\n",
    "    print(test_average_report_df) \n",
    "    return val_average_report_df, test_average_report_df\n",
    "\n",
    "generic_val_average_report_df, generic_test_average_report_df = calculate_metrics(\"generic\")\n",
    "GRU_202012_val_average_report_df, GRU_202012_test_average_report_df = calculate_metrics(\"GRU_202012\")\n",
    "IRA_202012_val_average_report_df, IRA_202012_test_average_report_df = calculate_metrics(\"IRA_202012\")\n",
    "REA_0621_val_average_report_df, REA_0621_test_average_report_df = calculate_metrics(\"REA_0621\")\n",
    "UGANDA_0621_val_average_report_df, UGANDA_0621_test_average_report_df = calculate_metrics(\"UGANDA_0621\")\n",
    "VENEZUELA_201901_2_val_average_report_df, VENEZUELA_201901_2_test_average_report_df = calculate_metrics(\"VENEZUELA_201901_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframes = {\n",
    "    \"generic_val_average_report\": generic_val_average_report_df,\n",
    "    \"generic_test_average_report\": generic_test_average_report_df,\n",
    "    \"GRU_202012_val_average_report\": GRU_202012_val_average_report_df,\n",
    "    \"GRU_202012_test_average_report\": GRU_202012_test_average_report_df,\n",
    "    \"IRA_202012_val_average_report\": IRA_202012_val_average_report_df,\n",
    "    \"IRA_202012_test_average_report\": IRA_202012_test_average_report_df,\n",
    "    \"REA_0621_val_average_report\": REA_0621_val_average_report_df,\n",
    "    \"REA_0621_test_average_report\": REA_0621_test_average_report_df,\n",
    "    \"UGANDA_0621_val_average_report\": UGANDA_0621_val_average_report_df,\n",
    "    \"UGANDA_0621_test_average_report\": UGANDA_0621_test_average_report_df,\n",
    "    \"VENEZUELA_201901_2_val_average_report\": VENEZUELA_201901_2_val_average_report_df,\n",
    "    \"VENEZUELA_201901_2_test_average_report\": VENEZUELA_201901_2_test_average_report_df,\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    csv_filename = f\"../reports/{name}_weight_decay.csv\"\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Train Data  Test Data  Validation  Test\n",
      "0            generic    generic        0.69  0.68\n",
      "1        All but GRU        GRU        0.68  0.42\n",
      "2        All but IRA        IRA        0.70  0.56\n",
      "3        All but REA        REA        0.66  0.54\n",
      "4     All but UGANDA     UGANDA        0.69  0.48\n",
      "5  All but VENEZUELA  VENEZUELA        0.65  0.55\n"
     ]
    }
   ],
   "source": [
    "def extract_macro_avg_value(df):\n",
    "    return df[df.index == \"macro avg\"][\"f1-score\"].values[0]\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    micro_avg_value = round(extract_macro_avg_value(df), 2)\n",
    "    train_data = name.split(\"_\")[0]\n",
    "\n",
    "    if \"val\" in name:\n",
    "        validation_value = micro_avg_value\n",
    "        test_value = None\n",
    "    elif \"test\" in name:\n",
    "        validation_value = None\n",
    "        test_value = micro_avg_value\n",
    "\n",
    "    test_data = train_data\n",
    "    if train_data != \"generic\":\n",
    "        train_data = \"All but \" + train_data\n",
    "\n",
    "    summary_data.append({\n",
    "        \"Train Data\": train_data,\n",
    "        \"Test Data\": test_data,\n",
    "        \"Validation\": validation_value,\n",
    "        \"Test\": test_value,\n",
    "    })\n",
    "\n",
    "# Combine rows with the same \"Train Data\" and \"Test Data\" into one\n",
    "macro_summary_df = pd.DataFrame(summary_data)\n",
    "macro_summary_df = macro_summary_df.groupby([\"Train Data\", \"Test Data\"], as_index=False).first()\n",
    "\n",
    "# Reorder columns\n",
    "macro_summary_df = macro_summary_df[[\"Train Data\", \"Test Data\", \"Validation\", \"Test\"]]\n",
    "macro_summary_df = macro_summary_df.reindex([macro_summary_df.index[-1]] + list(macro_summary_df.index[:-1]))\n",
    "macro_summary_df = macro_summary_df.reset_index(drop=True)\n",
    "\n",
    "print(macro_summary_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro Averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Train Data  Test Data  Validation  Test\n",
      "0            generic    generic        0.80  0.78\n",
      "1        All but GRU        GRU        0.78  0.77\n",
      "2        All but IRA        IRA        0.81  0.63\n",
      "3        All but REA        REA        0.79  0.72\n",
      "4     All but UGANDA     UGANDA        0.80  0.76\n",
      "5  All but VENEZUELA  VENEZUELA        0.79  0.70\n"
     ]
    }
   ],
   "source": [
    "def extract_micro_avg_value(df):\n",
    "    return df[df.index == \"micro avg\"][\"f1-score\"].values[0]\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    micro_avg_value = round(extract_micro_avg_value(df), 2)\n",
    "    train_data = name.split(\"_\")[0]\n",
    "\n",
    "    if \"val\" in name:\n",
    "        validation_value = micro_avg_value\n",
    "        test_value = None\n",
    "    elif \"test\" in name:\n",
    "        validation_value = None\n",
    "        test_value = micro_avg_value\n",
    "\n",
    "    test_data = train_data\n",
    "    if train_data != \"generic\":\n",
    "        train_data = \"All but \" + train_data\n",
    "\n",
    "    summary_data.append({\n",
    "        \"Train Data\": train_data,\n",
    "        \"Test Data\": test_data,\n",
    "        \"Validation\": validation_value,\n",
    "        \"Test\": test_value,\n",
    "    })\n",
    "\n",
    "# Combine rows with the same \"Train Data\" and \"Test Data\" into one\n",
    "micro_summary_df = pd.DataFrame(summary_data)\n",
    "micro_summary_df = micro_summary_df.groupby([\"Train Data\", \"Test Data\"], as_index=False).first()\n",
    "\n",
    "# Reorder columns\n",
    "micro_summary_df = micro_summary_df[[\"Train Data\", \"Test Data\", \"Validation\", \"Test\"]]\n",
    "micro_summary_df = micro_summary_df.reindex([micro_summary_df.index[-1]] + list(micro_summary_df.index[:-1]))\n",
    "micro_summary_df = micro_summary_df.reset_index(drop=True)\n",
    "\n",
    "print(micro_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human-readable table:\n",
      "   Dataset           BERTweet Large     \n",
      "Train Data Test Data     Validation Test\n",
      "   Generic   Generic            0.8 0.79\n",
      "\n",
      "\n",
      "LaTeX table:\n",
      "\\begin{tabular}{|l|l|l|l|}\n",
      "\\hline \\hline{@{}c@{}}{|l|l|l|l|}\n",
      "\n",
      "   Dataset & \\multicolumn{2}{c}{BERTweet Large} \\\\ \\hline\n",
      "Train Data & Test Data &     Validation & Test \\\\ \\hline\n",
      "\n",
      "   Generic &   Generic &            0,8 & 0,79 \\\\ \\hline\n",
      "\n",
      "\\\\ \\hline \\hline\n",
      "\\end{tabular}{@{}c@{}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_16532\\3602932945.py:23: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = f1_scores_df.to_latex(index=False, bold_rows=True, multicolumn=True, multicolumn_format='c', decimal=',', column_format='|l|l|l|l|', header=True, escape=False)\n"
     ]
    }
   ],
   "source": [
    "def create_latex_table(val_average_report_df, test_average_report_df):\n",
    "    train_data = \"Generic\"\n",
    "    test_data = \"Generic\"\n",
    "    \n",
    "    val_micro_avg = round(val_average_report_df.loc[\"micro avg\", \"f1-score\"], 2)\n",
    "    test_micro_avg = round(test_average_report_df.loc[\"micro avg\", \"f1-score\"], 2)\n",
    "    \n",
    "    data = [[train_data, test_data, val_micro_avg, test_micro_avg]]\n",
    "    \n",
    "    columns = pd.MultiIndex.from_tuples([\n",
    "        (\"Dataset\", \"Train Data\"),\n",
    "        (\"Dataset\", \"Test Data\"),\n",
    "        (\"BERTweet Large\", \"Validation\"),\n",
    "        (\"BERTweet Large\", \"Test\")\n",
    "    ])\n",
    "    \n",
    "    f1_scores_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    print(\"Human-readable table:\")\n",
    "    print(f1_scores_df.to_string(index=False))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    latex_table = f1_scores_df.to_latex(index=False, bold_rows=True, multicolumn=True, multicolumn_format='c', decimal=',', column_format='|l|l|l|l|', header=True, escape=False)\n",
    "\n",
    "    latex_table = latex_table.replace('\\\\toprule', '')\n",
    "    latex_table = latex_table.replace('\\\\midrule', '')\n",
    "    latex_table = latex_table.replace('\\\\bottomrule', '')\n",
    "\n",
    "    # Resize the header and center it\n",
    "    latex_table = latex_table.replace('{tabular}', '{tabular}{@{}c@{}}')\n",
    "    latex_table = latex_table.replace('Dataset & BERTweet Large', '\\\\large{Dataset} & \\\\large{BERTweet Large}')\n",
    "    \n",
    "    latex_table = latex_table.replace(\"\\\\begin{tabular}\", \"\\\\begin{tabular}{|l|l|l|l|}\\n\\\\hline \\\\hline\")\n",
    "    latex_table = latex_table.replace(\"\\\\end{tabular}\", \"\\\\\\\\ \\\\hline \\\\hline\\n\\\\end{tabular}\")\n",
    "\n",
    "    # Add borders between the rows\n",
    "    latex_table = latex_table.replace('\\\\\\\\\\n', '\\\\\\\\ \\\\hline\\n')\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "latex_table = create_latex_table(val_average_report_df, test_average_report_df)\n",
    "print(\"LaTeX table:\")\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
