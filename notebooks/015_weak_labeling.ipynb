{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import prompt_utils\n",
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "# vicuna \n",
    "# with rules classification only (beta 0.5: 0.76, beta 0.25: 0.86) (0.7-0.8s per prompt)\n",
    "vicuna_base_path = \"../data/vicuna_4bit/\"\n",
    "vicuna_with_rules_classification_only_name = \"generic_prompt_with_rules_only_classification\"\n",
    "vicuna_with_rules_classification_only_func = prompt_utils.get_vicuna_prompt_with_rules_only_classification\n",
    "\n",
    "# OA LLAMA\n",
    "# Classification Only V03 (bta 0.5: 0.81, beta 0.25: 0.83)\n",
    "# With Rules Classification only (beta 0.5: 0.8, beta 0.25: 0.89)\n",
    "# With 3 Random Examples Classification only (beta 0.5: 0.78, beta 0.25: 0.88)\n",
    "oa_base_path = \"../data/openassistant_llama_30b_4bit/\"\n",
    "oa_classification_only_v03_name = \"generic_prompt_without_context_only_classification_v03\"\n",
    "oa_classification_only_v03_func = prompt_utils.get_openassistant_llama_30b_4bit_without_context_only_classification_v03 #\n",
    "oa_with_rules_classification_only_name = \"generic_prompt_with_rules_only_classification\"\n",
    "oa_with_rules_classification_only_func = prompt_utils.get_openassistant_llama_30b_4bit_with_rules_only_classification\n",
    "oa_with_3_random_examples_classification_only_name = \"generic_prompt_few_shot_prompt_only_classification_3_random_example\"\n",
    "oa_with_rules_classification_only_func = prompt_utils.get_openassistant_llama_30b_4bit_few_shot_prompt_only_classification_n_random_example\n",
    "\n",
    "# Text Davinci\n",
    "# Elaboration First V04 (beta 0.5: 0.87, beta 0.25: 0.93)\n",
    "davinci_base_path = \"../data/openai_text_davinci_003/\"\n",
    "davinci_elaboration_first_v04_name = \"generic_prompt_without_context_elaboration_first_v04\"\n",
    "davinci_elaboration_first_v04_func = prompt_utils.get_openai_prompt_without_context_elaboration_first_v04\n",
    "\n",
    "# Define a list of filenames to load\n",
    "labeled_data_filename = \"../data/labeled_data/generic_test_0.json\"\n",
    "\n",
    "dfs = []\n",
    "with open(labeled_data_filename) as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data[\"train\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"test\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"valid\"])\n",
    "dfs.append(df)\n",
    "df_all = pd.concat(dfs)\n",
    "ALL_LABELS = prompt_utils.ALL_LABELS[:-1]\n",
    "LOW_F1_LABELS = prompt_utils.LOW_F1_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_eng_dataframe():\n",
    "    unlabeled_dataset = prompt_utils.generate_unlabeled_dataset()\n",
    "    return unlabeled_dataset.loc[unlabeled_dataset.tweet_language == \"en\"].sample(frac=1, random_state = 42).reset_index()\n",
    "\n",
    "def find_start_index(df: pd.DataFrame, new_column_names: List[str]) -> int:\n",
    "    # Find first row where all weak labels are NaN\n",
    "    try:\n",
    "        start_index = df[new_column_names].isna().all(axis=1).idxmax()\n",
    "        # If no NaN found in any of new_column_names, start from beginning\n",
    "        if pd.isna(start_index):\n",
    "            start_index = 0\n",
    "        return start_index\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8042/3980851207.py:7: DtypeWarning: Columns (0,1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,22,23,28,29,30,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eng_tweets = pd.read_csv(f\"{output_folder}/{model_name}.csv\")\n"
     ]
    }
   ],
   "source": [
    "output_folder = f\"{vicuna_base_path}/{vicuna_with_rules_classification_only_name}\"\n",
    "model_name = \"low_f1_labels_weak_labeling\"\n",
    "prompt_func = vicuna_with_rules_classification_only_func\n",
    "idx_of_rules_of_low_f1_labels = [1, 2, 4, 9, 12, 13]\n",
    "\n",
    "if os.path.isfile(f\"{output_folder}/{model_name}.csv\"):\n",
    "    eng_tweets = pd.read_csv(f\"{output_folder}/{model_name}.csv\")\n",
    "else:\n",
    "    eng_tweets = initialize_eng_dataframe()\n",
    "    eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW_F1_LABELS_COLUMNS = [i + \"_pred\" for i in LOW_F1_LABELS]\n",
    "start_index = find_start_index(eng_tweets, LOW_F1_LABELS_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18106"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llm_utils\n",
    "eng_tweets = eng_tweets.iloc[0:18105]\n",
    "for label in LOW_F1_LABELS:\n",
    "    eng_tweets[f'{label}_pred'] = eng_tweets[f'{label}_pred'].apply(llm_utils.get_extraction_function(\"extract_using_class_token\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Conspiracy Theory predictions:  962\n",
      "Length Conspiracy Theory predictions with all other predictions being 0:  879\n",
      "Length Education predictions:  778\n",
      "Length Education predictions with all other predictions being 0:  2557\n",
      "Length Environment predictions:  933\n",
      "Length Environment predictions with all other predictions being 0:  2579\n",
      "Length Labor/Employment predictions:  699\n",
      "Length Labor/Employment predictions with all other predictions being 0:  2627\n",
      "Length Religion predictions:  348\n",
      "Length Religion predictions with all other predictions being 0:  2914\n",
      "Length Science/Technology predictions:  290\n",
      "Length Science/Technology predictions:  2842\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>Conspiracy Theory_pred</th>\n",
       "      <th>Education_pred</th>\n",
       "      <th>Environment_pred</th>\n",
       "      <th>Labor/Employment_pred</th>\n",
       "      <th>Religion_pred</th>\n",
       "      <th>Science/Technology_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>The #Angara #rocket is built on a modular desi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>RT @djnicknicholas: On #TheHitLab tomorrow @Ka...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>VIDEO : OneWeb Founder on Bringing 3,000 Jobs ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>RT @NRMOnline: President @KagutaMuseveni comme...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>RT @CQvMyyB0YfvwrUrsaZ6KI7yqaJfSUDTrAI0joQhgMA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17764</th>\n",
       "      <td>Giuliani: Trump to fight hacking with cybersec...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17815</th>\n",
       "      <td>RT @TButaka: Which Definition can you never fo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867</th>\n",
       "      <td>This could prevent distracted driving https://...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17893</th>\n",
       "      <td>Wireless headphones for the holidays https://t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18033</th>\n",
       "      <td>Yes, we knew it, we said it and from popular f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text  Conspiracy Theory_pred  Education_pred  Environment_pred  Labor/Employment_pred  Religion_pred  Science/Technology_pred\n",
       "106    The #Angara #rocket is built on a modular desi...                     0.0             0.0               0.0                    0.0            0.0                      1.0\n",
       "154    RT @djnicknicholas: On #TheHitLab tomorrow @Ka...                     0.0             0.0               0.0                    0.0            0.0                      1.0\n",
       "246    VIDEO : OneWeb Founder on Bringing 3,000 Jobs ...                     0.0             1.0               0.0                    1.0            0.0                      1.0\n",
       "345    RT @NRMOnline: President @KagutaMuseveni comme...                     0.0             1.0               0.0                    0.0            0.0                      1.0\n",
       "373    RT @CQvMyyB0YfvwrUrsaZ6KI7yqaJfSUDTrAI0joQhgMA...                     0.0             1.0               1.0                    1.0            0.0                      1.0\n",
       "...                                                  ...                     ...             ...               ...                    ...            ...                      ...\n",
       "17764  Giuliani: Trump to fight hacking with cybersec...                     0.0             0.0               0.0                    0.0            0.0                      1.0\n",
       "17815  RT @TButaka: Which Definition can you never fo...                     0.0             0.0               0.0                    0.0            0.0                      1.0\n",
       "17867  This could prevent distracted driving https://...                     0.0             1.0               1.0                    0.0            0.0                      1.0\n",
       "17893  Wireless headphones for the holidays https://t...                     0.0             0.0               0.0                    0.0            0.0                      1.0\n",
       "18033  Yes, we knew it, we said it and from popular f...                     0.0             1.0               1.0                    1.0            1.0                      1.0\n",
       "\n",
       "[290 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mask_conspiracy = eng_tweets['Conspiracy Theory_pred'] == 0\n",
    "mask_education = eng_tweets['Education_pred'] == 0\n",
    "mask_environment = eng_tweets['Environment_pred'] == 0\n",
    "mask_labor = eng_tweets['Labor/Employment_pred'] == 0\n",
    "mask_religion = eng_tweets['Religion_pred'] == 0\n",
    "mask_science = eng_tweets['Science/Technology_pred'] == 0\n",
    "\n",
    "conspiracy_preds = eng_tweets[eng_tweets['Conspiracy Theory_pred'] == 1]\n",
    "print(\"Length Conspiracy Theory predictions: \", len(conspiracy_preds))\n",
    "\n",
    "only_conspiracy_predicted = eng_tweets[(eng_tweets['Conspiracy Theory_pred'] == 1) & (mask_education & mask_environment & mask_labor & mask_religion & mask_science)]\n",
    "print(\"Length Conspiracy Theory predictions with all other predictions being 0: \", len(only_conspiracy_predicted))\n",
    "\n",
    "education_preds = eng_tweets[eng_tweets['Education_pred'] == 1]\n",
    "print(\"Length Education predictions: \", len(education_preds))\n",
    "\n",
    "only_education_predicted = eng_tweets[eng_tweets['Education_pred'] == 1 & mask_conspiracy & mask_environment & mask_labor & mask_religion & mask_science]\n",
    "print(\"Length Education predictions with all other predictions being 0: \", len(only_education_predicted))\n",
    "\n",
    "environment_preds = eng_tweets[eng_tweets['Environment_pred'] == 1]\n",
    "print(\"Length Environment predictions: \", len(environment_preds))\n",
    "\n",
    "only_environment_predicted = eng_tweets[eng_tweets['Environment_pred'] == 1 & mask_conspiracy & mask_education & mask_labor & mask_religion & mask_science]\n",
    "print(\"Length Environment predictions with all other predictions being 0: \", len(only_environment_predicted))\n",
    "\n",
    "labor_preds = eng_tweets[eng_tweets['Labor/Employment_pred'] == 1]\n",
    "print(\"Length Labor/Employment predictions: \", len(labor_preds))\n",
    "\n",
    "only_labor_predicted = eng_tweets[eng_tweets['Labor/Employment_pred'] == 1 & mask_conspiracy & mask_education & mask_environment & mask_religion & mask_science]\n",
    "print(\"Length Labor/Employment predictions with all other predictions being 0: \", len(only_labor_predicted))\n",
    "\n",
    "religion_pred = eng_tweets[eng_tweets['Religion_pred'] == 1]\n",
    "print(\"Length Religion predictions: \", len(religion_pred))\n",
    "\n",
    "only_religion_predicted = eng_tweets[eng_tweets['Religion_pred'] == 1 & mask_conspiracy & mask_education & mask_environment & mask_labor & mask_science]\n",
    "print(\"Length Religion predictions with all other predictions being 0: \", len(only_religion_predicted))\n",
    "\n",
    "science_pred = eng_tweets[eng_tweets['Science/Technology_pred'] == 1]\n",
    "print(\"Length Science/Technology predictions: \", len(science_pred))\n",
    "\n",
    "only_science_predicted = eng_tweets[eng_tweets['Science/Technology_pred'] == 1 & mask_conspiracy & mask_education & mask_environment & mask_labor & mask_religion]\n",
    "print(\"Length Science/Technology predictions: \", len(only_science_predicted))\n",
    "\n",
    "science_pred[[\"tweet_text\", \"Conspiracy Theory_pred\", \"Education_pred\", \"Environment_pred\", \"Labor/Employment_pred\", \"Religion_pred\", \"Science/Technology_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index: 4143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1565961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4143\n",
      "Label: Conspiracy Theory\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4143\n",
      "Label: Education\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4143\n",
      "Label: Environment\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4143\n",
      "Label: Labor/Employment\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4143\n",
      "Label: Religion\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4143\n",
      "Label: Science/Technology\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4144\n",
      "Label: Conspiracy Theory\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4144\n",
      "Label: Education\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4144\n",
      "Label: Environment\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4144\n",
      "Label: Labor/Employment\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4144\n",
      "Label: Religion\n",
      "'float' object has no attribute 'replace'\n",
      "Error at index: 4144\n",
      "Label: Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 58/1565961 [04:42<4454:00:35, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 4200\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 358/1565961 [29:29<4407:59:52, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 4500\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 658/1565961 [54:15<4407:01:37, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 4800\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 958/1565961 [1:19:03<4415:10:28, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 5100\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1258/1565961 [1:43:53<4413:08:09, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 5400\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1558/1565961 [2:08:42<4437:50:05, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 5700\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1858/1565961 [2:33:28<4409:13:11, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 6000\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2158/1565961 [2:58:19<4434:52:46, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 6300\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2458/1565961 [3:23:07<4421:15:28, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 6600\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2758/1565961 [3:47:55<4416:44:29, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 6900\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3058/1565961 [4:12:47<4466:19:13, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 7200\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3358/1565961 [4:37:37<4444:47:30, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 7500\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3658/1565961 [5:02:26<4505:46:00, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 7800\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3958/1565961 [5:27:21<4464:00:52, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 8100\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not related to Science/Techn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4258/1565961 [5:52:14<4484:07:29, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 8400\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4558/1565961 [6:17:04<4403:01:54, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 8700\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4858/1565961 [6:41:58<4410:36:34, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 9000\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5158/1565961 [7:06:49<4397:13:51, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 9300\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5458/1565961 [7:32:24<4637:06:47, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 9600\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5758/1565961 [7:58:39<4606:54:36, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 9900\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6058/1565961 [8:24:58<4594:05:58, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 10200\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6358/1565961 [8:51:14<4743:41:19, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 10500\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6658/1565961 [9:16:58<4442:23:23, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 10800\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6958/1565961 [9:41:44<4461:21:41, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 11100\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7258/1565961 [10:06:43<4586:20:27, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 11400\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7558/1565961 [10:32:18<4614:25:29, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 11700\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7858/1565961 [10:58:20<4590:22:44, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 12000\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8158/1565961 [11:24:29<4559:48:49, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 12300\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8458/1565961 [11:50:12<4566:10:23, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 12600\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8758/1565961 [12:15:53<4605:23:41, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 12900\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9058/1565961 [12:41:32<4576:47:27, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 13200\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9358/1565961 [13:07:11<4575:15:20, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 13500\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9658/1565961 [13:32:51<4575:10:22, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 13800\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9958/1565961 [13:58:31<4550:51:54, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 14100\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10258/1565961 [14:24:11<4570:01:43, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 14400\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10558/1565961 [14:49:52<4603:59:27, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 14700\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10858/1565961 [15:15:33<4579:09:44, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 15000\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11158/1565961 [15:41:16<4543:04:24, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 15300\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11458/1565961 [16:06:56<4609:52:21, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 15600\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11758/1565961 [16:32:37<4591:41:39, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 15900\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12058/1565961 [16:58:26<4704:03:30, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 16200\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12358/1565961 [17:25:07<4744:59:53, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 16500\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12658/1565961 [17:51:59<4853:56:39, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 16800\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12958/1565961 [18:18:54<4827:59:59, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 17100\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13258/1565961 [18:45:34<4699:41:04, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 17400\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13558/1565961 [19:12:26<4771:35:21, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 17700\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13858/1565961 [19:39:07<4776:43:20, 11.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at index: 18000\n",
      "Last label: Science/Technology\n",
      "Last response:  0 (Not about Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13962/1565961 [19:48:24<2201:42:19,  5.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m#print(tweet_text)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m prompt, followup, request_params \u001b[39m=\u001b[39m prompt_func(tweet_text, label, prompt_utils\u001b[39m.\u001b[39mRULES[rule_idx], prompt_utils\u001b[39m.\u001b[39mget_base_request_params())\n\u001b[0;32m---> 12\u001b[0m response \u001b[39m=\u001b[39m prompt_utils\u001b[39m.\u001b[39mget_response(request_params, prompt, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# for openai\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#response = prompt_utils.get_response_wip(prompt, \"openai-davinci\", max_tokens = 400, openai_model = \"davinci\")\u001b[39;00m\n\u001b[1;32m     15\u001b[0m eng_tweets\u001b[39m.\u001b[39mloc[i, new_column_name] \u001b[39m=\u001b[39m response\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/Documents/ip6-twitter-disinformation/notebooks/../src/prompt_utils.py:132\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(request_params, prompt, context)\u001b[0m\n\u001b[1;32m    129\u001b[0m request_params[\u001b[39m'\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m prompt\n\u001b[1;32m    130\u001b[0m request_params[\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m context\n\u001b[0;32m--> 132\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(URI, json\u001b[39m=\u001b[39mrequest_params)\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    135\u001b[0m     result \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url, data\u001b[39m=\u001b[39mdata, json\u001b[39m=\u001b[39mjson, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     r\u001b[39m.\u001b[39mcontent\n\u001b[1;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread(amt\u001b[39m=\u001b[39mamt, decode_content\u001b[39m=\u001b[39mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LOW_F1_LABELS_COLUMNS = [i + \"_pred\" for i in LOW_F1_LABELS]\n",
    "start_index = find_start_index(eng_tweets, LOW_F1_LABELS_COLUMNS)\n",
    "start_index = 4143\n",
    "print(\"Starting at index:\", start_index)\n",
    "for i in tqdm(range(start_index, len(eng_tweets)), total = len(eng_tweets)-start_index):\n",
    "    for label, rule_idx in zip(LOW_F1_LABELS, idx_of_rules_of_low_f1_labels):\n",
    "        try:\n",
    "            new_column_name = f'{label}_pred'\n",
    "            tweet_text = prompt_utils.normalize_tweet_simplified(eng_tweets.iloc[i]['tweet_text'])\n",
    "            #print(tweet_text)\n",
    "            prompt, followup, request_params = prompt_func(tweet_text, label, prompt_utils.RULES[rule_idx], prompt_utils.get_base_request_params())\n",
    "            response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "            # for openai\n",
    "            #response = prompt_utils.get_response_wip(prompt, \"openai-davinci\", max_tokens = 400, openai_model = \"davinci\")\n",
    "            eng_tweets.loc[i, new_column_name] = response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error at index:\", i)\n",
    "            print(\"Label:\", label)\n",
    "            eng_tweets.loc[i, new_column_name] = \"ERROR\"\n",
    "    \n",
    "    if i % 300 == 0:\n",
    "        eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)\n",
    "        print(\"Saved at index:\", i)\n",
    "        print(\"Last label:\", label)\n",
    "        print(\"Last response:\", response)\n",
    "\n",
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                  424685\n",
       "tweetid                                                   1289113606794223616\n",
       "userid                                                    1108056700450414592\n",
       "user_display_name                                                Hustle Queen\n",
       "user_screen_name                                                HustleQueenUg\n",
       "user_reported_location                                                 Uganda\n",
       "user_profile_description                      patriot of the great Sevolution\n",
       "user_profile_url                                                          NaN\n",
       "follower_count                                                        13491.0\n",
       "following_count                                                          5975\n",
       "account_creation_date                                              2019-03-19\n",
       "account_language                                                           en\n",
       "tweet_language                                                             en\n",
       "tweet_text                  RT @kamukamafredie1: To all Moslem brothers an...\n",
       "tweet_time                                                   2020-07-31 08:20\n",
       "tweet_client_name                                          Twitter for iPhone\n",
       "in_reply_to_userid                                                        NaN\n",
       "in_reply_to_tweetid                                                       NaN\n",
       "quoted_tweet_tweetid                                                      NaN\n",
       "is_retweet                                                               True\n",
       "retweet_userid                                                            NaN\n",
       "retweet_tweetid                                         1289053297761029888.0\n",
       "latitude                                                               absent\n",
       "longitude                                                              absent\n",
       "quote_count                                                               0.0\n",
       "reply_count                                                               0.0\n",
       "like_count                                                                0.0\n",
       "retweet_count                                                             0.0\n",
       "hashtags                                                                   []\n",
       "urls                                                                       []\n",
       "user_mentions                                          ['991655831648325632']\n",
       "poll_choices                                                              NaN\n",
       "Conspiracy Theory_pred                                                    NaN\n",
       "Education_pred                                                            NaN\n",
       "Environment_pred                                                          NaN\n",
       "Labor/Employment_pred                                                     NaN\n",
       "Religion_pred                                                             NaN\n",
       "Science/Technology_pred                                                   NaN\n",
       "Name: 4280, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tweets.iloc[4280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
