{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import prompt_utils\n",
    "import os\n",
    "import random\n",
    "\n",
    "# vicuna \n",
    "# with rules classification only (0.76)\n",
    "vicuna_base_path = \"../data/vicuna_4bit/\"\n",
    "vicuna_with_rules_classification_only_name = \"generic_prompt_with_rules_only_classification\"\n",
    "vicuna_with_rules_classification_only_func = prompt_utils.get_vicuna_prompt_with_rules_only_classification\n",
    "\n",
    "# OA LLAMA\n",
    "# Classification Only V03 (0.81)\n",
    "# 1 pos 1 neg (0.79)\n",
    "oa_base_path = \"../data/openassistant_llama_30b_4bit/\"\n",
    "oa_classification_only_v03_name = \"generic_prompt_without_context_only_classification_v03\"\n",
    "oa_classification_only_v03_func = prompt_utils.get_openassistant_llama_30b_4bit_without_context_only_classification_v03\n",
    "oa_1pos_1neg_path_name = \"generic_prompt_few_shot_prompt_only_classification_1_pos_1_neg_example\"\n",
    "oa_1pos_1neg_path_func = prompt_utils.get_openassistant_llama_30b_4bit_few_shot_prompt_only_classification_1_pos_1_neg_example\n",
    "\n",
    "# Text Davinci\n",
    "# Elaboration First V02 (0.94)\n",
    "davinci_base_path = \"../data/openai_text_davinci_003/\"\n",
    "davinci_elaboration_first_v02_name = \"generic_prompt_without_context_elaboration_first_v02\"\n",
    "davinci_elaboration_first_v02_func = prompt_utils.get_openai_prompt_without_context_elaboration_first_v02\n",
    "\n",
    "# Define a list of filenames to load\n",
    "labeled_data_filename = \"../data/labeled_data/generic_test_0.json\"\n",
    "\n",
    "dfs = []\n",
    "with open(labeled_data_filename) as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data[\"train\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"test\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"valid\"])\n",
    "dfs.append(df)\n",
    "df_all = pd.concat(dfs)\n",
    "all_labels = [\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \n",
    "              \"Government/Public\", \"Health\", \"Immigration/Integration\", \n",
    "              \"Justice/Crime\", \"Labor/Employment\", \n",
    "              \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
    "\n",
    "unlabeled_dataset = prompt_utils.generate_unlabeled_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in all_labels:\n",
    "    prompt, followup, request_params = prompt_utils.get_openassistant_llama_30b_4bit_without_context_only_classification_v03(\"Hey how are you?\", \"War/Terror\", prompt_utils.get_base_request_params())\n",
    "#print(prompt)\n",
    "        \n",
    "#request_params['regenerate'] = False\n",
    "#request_params['do_sample'] = False\n",
    "request_params['max_new_tokens'] = 200\n",
    "response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
