{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import prompt_utils\n",
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "# vicuna \n",
    "# with rules classification only (beta 0.5: 0.76, beta 0.25: 0.86) (0.7-0.8s per prompt)\n",
    "vicuna_base_path = \"../data/vicuna_4bit/\"\n",
    "vicuna_with_rules_classification_only_name = \"generic_prompt_with_rules_only_classification\"\n",
    "vicuna_with_rules_classification_only_func = prompt_utils.get_vicuna_prompt_with_rules_only_classification\n",
    "\n",
    "# OA LLAMA\n",
    "# Classification Only V03 (bta 0.5: 0.81, beta 0.25: 0.83)\n",
    "# With Rules Classification only (beta 0.5: 0.8, beta 0.25: 0.89)\n",
    "# With 3 Random Examples Classification only (beta 0.5: 0.78, beta 0.25: 0.88)\n",
    "oa_base_path = \"../data/openassistant_llama_30b_4bit/\"\n",
    "oa_classification_only_v03_name = \"generic_prompt_without_context_only_classification_v03\"\n",
    "oa_classification_only_v03_func = prompt_utils.get_openassistant_llama_30b_4bit_without_context_only_classification_v03 #\n",
    "oa_with_rules_classification_only_name = \"generic_prompt_with_rules_only_classification\"\n",
    "oa_with_rules_classification_only_func = prompt_utils.get_openassistant_llama_30b_4bit_with_rules_only_classification\n",
    "oa_with_3_random_examples_classification_only_name = \"generic_prompt_few_shot_prompt_only_classification_3_random_example\"\n",
    "oa_with_rules_classification_only_func = prompt_utils.get_openassistant_llama_30b_4bit_few_shot_prompt_only_classification_n_random_example\n",
    "\n",
    "# Text Davinci\n",
    "# Elaboration First V04 (beta 0.5: 0.87, beta 0.25: 0.93)\n",
    "davinci_base_path = \"../data/openai_text_davinci_003/\"\n",
    "davinci_elaboration_first_v04_name = \"generic_prompt_without_context_elaboration_first_v04\"\n",
    "davinci_elaboration_first_v04_func = prompt_utils.get_openai_prompt_without_context_elaboration_first_v04\n",
    "\n",
    "# Define a list of filenames to load\n",
    "labeled_data_filename = \"../data/labeled_data/generic_test_0.json\"\n",
    "\n",
    "dfs = []\n",
    "with open(labeled_data_filename) as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data[\"train\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"test\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"valid\"])\n",
    "dfs.append(df)\n",
    "df_all = pd.concat(dfs)\n",
    "ALL_LABELS = prompt_utils.ALL_LABELS[:-1]\n",
    "LOW_F1_LABELS = prompt_utils.LOW_F1_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_eng_dataframe():\n",
    "    unlabeled_dataset = prompt_utils.generate_unlabeled_dataset()\n",
    "    return unlabeled_dataset.loc[unlabeled_dataset.tweet_language == \"en\"].sample(frac=1, random_state = 42).reset_index()\n",
    "\n",
    "def find_start_index(df: pd.DataFrame, new_column_names: List[str]) -> int:\n",
    "    # Find first row where all weak labels are NaN\n",
    "    try:\n",
    "        start_index = df[new_column_names].isna().all(axis=1).idxmax()\n",
    "        # If no NaN found in any of new_column_names, start from beginning\n",
    "        if pd.isna(start_index):\n",
    "            start_index = 0\n",
    "        return start_index\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39389/1872421907.py:7: DtypeWarning: Columns (0,1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,22,23,28,29,30,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eng_tweets = pd.read_csv(f\"{output_folder}/{model_name}.csv\")\n"
     ]
    }
   ],
   "source": [
    "output_folder = f\"{davinci_base_path}/{davinci_elaboration_first_v04_name}\"\n",
    "model_name = \"low_f1_labels_weak_labeling\"\n",
    "prompt_func = davinci_elaboration_first_v04_func\n",
    "idx_of_rules_of_low_f1_labels = [1, 2, 4, 9, 12, 13]\n",
    "\n",
    "if os.path.isfile(f\"{output_folder}/{model_name}.csv\"):\n",
    "    eng_tweets = pd.read_csv(f\"{output_folder}/{model_name}.csv\")\n",
    "else:\n",
    "    eng_tweets = initialize_eng_dataframe()\n",
    "    eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llm_utils\n",
    "eng_tweets = eng_tweets.iloc[0:1999]\n",
    "for label in LOW_F1_LABELS:\n",
    "    eng_tweets[f'{label}_pred'] = eng_tweets[f'{label}_pred'].apply(llm_utils.get_extraction_function(\"extract_using_class_token\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Conspiracy Theory predictions:  229\n",
      "Length Conspiracy Theory predictions with all other predictions being 0:  217\n",
      "Length Education predictions:  32\n",
      "Length Education predictions with all other predictions being 0:  453\n",
      "Length Environment predictions:  25\n",
      "Length Environment predictions with all other predictions being 0:  452\n",
      "Length Labor/Employment predictions:  59\n",
      "Length Labor/Employment predictions with all other predictions being 0:  453\n",
      "Length Religion predictions:  71\n",
      "Length Religion predictions with all other predictions being 0:  454\n",
      "Length Science/Technology predictions:  74\n",
      "Length Science/Technology predictions:  445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>Conspiracy Theory_pred</th>\n",
       "      <th>Education_pred</th>\n",
       "      <th>Environment_pred</th>\n",
       "      <th>Labor/Employment_pred</th>\n",
       "      <th>Religion_pred</th>\n",
       "      <th>Science/Technology_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@DjShiru smashing it up with  Shekini @PeterPs...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Twitter accidentally suspends its own CEO's ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>The #Angara #rocket is built on a modular desi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Hours Before IBM Meets With Trump, They Announ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>RT @CQvMyyB0YfvwrUrsaZ6KI7yqaJfSUDTrAI0joQhgMA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>RT @MinofHealthUG: Results of COVID-19 tests d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>Silicon Valley wants more water startups https...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>#aur Trump TRIGGERS Climate Change Freaks With...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>Oh the humanity! Poker computer trounces human...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>Tesla falls short of car delivery goal for 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  Conspiracy Theory_pred  Education_pred  Environment_pred  Labor/Employment_pred  Religion_pred  Science/Technology_pred\n",
       "29    @DjShiru smashing it up with  Shekini @PeterPs...                       0               0                 0                      0              0                      1.0\n",
       "85    Twitter accidentally suspends its own CEO's ac...                       0               0                 0                      0              0                      1.0\n",
       "106   The #Angara #rocket is built on a modular desi...                       0               0                 0                      0              0                      1.0\n",
       "121   Hours Before IBM Meets With Trump, They Announ...                       0               0                 0                      1              0                      1.0\n",
       "129   RT @CQvMyyB0YfvwrUrsaZ6KI7yqaJfSUDTrAI0joQhgMA...                       0               0                 1                      0              0                      1.0\n",
       "...                                                 ...                     ...             ...               ...                    ...            ...                      ...\n",
       "1872  RT @MinofHealthUG: Results of COVID-19 tests d...                       0               0                 0                      0              0                      1.0\n",
       "1910  Silicon Valley wants more water startups https...                       0               0                 0                      0              0                      1.0\n",
       "1925  #aur Trump TRIGGERS Climate Change Freaks With...                       0               0                 1                      0              0                      1.0\n",
       "1941  Oh the humanity! Poker computer trounces human...                       0               0                 0                      0              0                      1.0\n",
       "1970  Tesla falls short of car delivery goal for 201...                       0               0                 0                      0              0                      1.0\n",
       "\n",
       "[74 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mask_conspiracy = eng_tweets['Conspiracy Theory_pred'] == 0\n",
    "mask_education = eng_tweets['Education_pred'] == 0\n",
    "mask_environment = eng_tweets['Environment_pred'] == 0\n",
    "mask_labor = eng_tweets['Labor/Employment_pred'] == 0\n",
    "mask_religion = eng_tweets['Religion_pred'] == 0\n",
    "mask_science = eng_tweets['Science/Technology_pred'] == 0\n",
    "\n",
    "conspiracy_preds = eng_tweets[eng_tweets['Conspiracy Theory_pred'] == 1]\n",
    "print(\"Length Conspiracy Theory predictions: \", len(conspiracy_preds))\n",
    "\n",
    "only_conspiracy_predicted = eng_tweets[(eng_tweets['Conspiracy Theory_pred'] == 1) & (mask_education & mask_environment & mask_labor & mask_religion & mask_science)]\n",
    "print(\"Length Conspiracy Theory predictions with all other predictions being 0: \", len(only_conspiracy_predicted))\n",
    "\n",
    "education_preds = eng_tweets[eng_tweets['Education_pred'] == 1]\n",
    "print(\"Length Education predictions: \", len(education_preds))\n",
    "\n",
    "only_education_predicted = eng_tweets[eng_tweets['Education_pred'] == 1 & mask_conspiracy & mask_environment & mask_labor & mask_religion & mask_science]\n",
    "print(\"Length Education predictions with all other predictions being 0: \", len(only_education_predicted))\n",
    "\n",
    "environment_preds = eng_tweets[eng_tweets['Environment_pred'] == 1]\n",
    "print(\"Length Environment predictions: \", len(environment_preds))\n",
    "\n",
    "only_environment_predicted = eng_tweets[eng_tweets['Environment_pred'] == 1 & mask_conspiracy & mask_education & mask_labor & mask_religion & mask_science]\n",
    "print(\"Length Environment predictions with all other predictions being 0: \", len(only_environment_predicted))\n",
    "\n",
    "labor_preds = eng_tweets[eng_tweets['Labor/Employment_pred'] == 1]\n",
    "print(\"Length Labor/Employment predictions: \", len(labor_preds))\n",
    "\n",
    "only_labor_predicted = eng_tweets[eng_tweets['Labor/Employment_pred'] == 1 & mask_conspiracy & mask_education & mask_environment & mask_religion & mask_science]\n",
    "print(\"Length Labor/Employment predictions with all other predictions being 0: \", len(only_labor_predicted))\n",
    "\n",
    "religion_pred = eng_tweets[eng_tweets['Religion_pred'] == 1]\n",
    "print(\"Length Religion predictions: \", len(religion_pred))\n",
    "\n",
    "only_religion_predicted = eng_tweets[eng_tweets['Religion_pred'] == 1 & mask_conspiracy & mask_education & mask_environment & mask_labor & mask_science]\n",
    "print(\"Length Religion predictions with all other predictions being 0: \", len(only_religion_predicted))\n",
    "\n",
    "science_pred = eng_tweets[eng_tweets['Science/Technology_pred'] == 1]\n",
    "print(\"Length Science/Technology predictions: \", len(science_pred))\n",
    "\n",
    "only_science_predicted = eng_tweets[eng_tweets['Science/Technology_pred'] == 1 & mask_conspiracy & mask_education & mask_environment & mask_labor & mask_religion]\n",
    "print(\"Length Science/Technology predictions: \", len(only_science_predicted))\n",
    "\n",
    "science_pred[[\"tweet_text\", \"Conspiracy Theory_pred\", \"Education_pred\", \"Environment_pred\", \"Labor/Employment_pred\", \"Religion_pred\", \"Science/Technology_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The #Angara #rocket is built on a modular design that can be configured to suit its payload. http://t.co/qnnxJIA6nS #Russia'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_science_predicted.iloc[5].tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index: 801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 214/1199 [27:40<27:02:47, 98.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 31 Jul 2023 18:05:37 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7ef7bda54cd001f8-ZRH', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "Error at index: 1014\n",
      "Label: Science/Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [2:06:15<00:00,  6.32s/it] \n"
     ]
    }
   ],
   "source": [
    "LOW_F1_LABELS_COLUMNS = [i + \"_pred\" for i in LOW_F1_LABELS]\n",
    "start_index = find_start_index(eng_tweets, LOW_F1_LABELS_COLUMNS)\n",
    "print(\"Starting at index:\", start_index)\n",
    "for i in tqdm(range(start_index, 2000), total = 2000-start_index):\n",
    "    for label, rule_idx in zip(LOW_F1_LABELS, idx_of_rules_of_low_f1_labels):\n",
    "        try:\n",
    "            new_column_name = f'{label}_pred'\n",
    "            tweet_text = prompt_utils.normalize_tweet_simplified(eng_tweets.iloc[i]['tweet_text'])\n",
    "            #print(tweet_text)\n",
    "            prompt, followup, request_params = prompt_func(tweet_text, label, prompt_utils.get_base_request_params())\n",
    "            #response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "            response = prompt_utils.get_response_wip(prompt, \"openai-davinci\", max_tokens = 400, openai_model = \"davinci\")\n",
    "            eng_tweets.loc[i, new_column_name] = response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error at index:\", i)\n",
    "            print(\"Label:\", label)\n",
    "            eng_tweets.loc[i, new_column_name] = \"ERROR\"\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)\n",
    "\n",
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "Tweet: I'm doing well thank you! How bout yourself?\n",
      "Class: 0\n",
      "\n",
      "Tweet: Not much just working and trying to keep my head above water lol\n",
      "Class: 0\n",
      "\n",
      "Tweet: Same here haha\n",
      "Class: 0\n",
      "\n",
      "Tweet: Anything new with you?\n",
      "Class: 0\n",
      "\n",
      "Tweet: No not really just work and sleep lol\n",
      "Class: 0\n",
      "\n",
      "Tweet: Yeah that's what I do lol\n",
      "Class: 0\n",
      "\n",
      "Tweet: Haha yeah it can be quite boring at times but it pays the bills\n",
      "Class: 0\n",
      "\n",
      "Tweet: Very true, very true\n",
      "Class: 0\n",
      "\n",
      "Tweet: What about you? Any exciting plans this weekend?\n",
      "Class: 0\n",
      "\n",
      "Tweet: Not really just going to try and enjoy some relaxation time\n",
      "Class:\n"
     ]
    }
   ],
   "source": [
    "for label in LOW_F1_LABELS:\n",
    "    prompt, followup, request_params = prompt_utils.get_openassistant_llama_30b_4bit_without_context_only_classification_v03(\"Hey how are you?\", \"War/Terror\", prompt_utils.get_base_request_params())\n",
    "#print(prompt)\n",
    "        \n",
    "#request_params['regenerate'] = False\n",
    "#request_params['do_sample'] = False\n",
    "request_params['max_new_tokens'] = 200\n",
    "response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
