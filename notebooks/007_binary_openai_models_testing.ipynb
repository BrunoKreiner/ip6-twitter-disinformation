{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import prompt_utils\n",
    "\n",
    "# Define a list of filenames to load\n",
    "filenames = [\"../data/labeled_data/generic_test_0.json\"]\n",
    "\n",
    "# Load all JSON data and concatenate into one DataFrame\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data[\"train\"])\n",
    "    dfs.append(df)\n",
    "    df = pd.DataFrame(data[\"test\"])\n",
    "    dfs.append(df)\n",
    "    df = pd.DataFrame(data[\"valid\"])\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs)\n",
    "\n",
    "# For local streaming, the websockets are hosted without ssl - http://\n",
    "HOST = 'http://127.0.0.1:5000'\n",
    "URI = f'{HOST}/api/v1/generate'\n",
    "\n",
    "# For reverse-proxied streaming, the remote will likely host with ssl - https://\n",
    "# URI = 'https://your-uri-here.trycloudflare.com/api/v1/generate'\n",
    "\n",
    "\n",
    "# TODO: maybe use the same \"Class: \" token for output as in vicuna\n",
    "def get_openai_prompt_with_rules_elaboration_first(tweet_text, label, rules):\n",
    "    prompt = f\"Based on rules, elaborate whether you think the Tweet is about {label}.\\nRules: {rules}\\nTweet: {tweet_text}\\nElaborations: \"\n",
    "    followup = f\"\\nAssign the label 1 if it's about {label} or 0 for not based on the elaboration. Only output the number.\"\n",
    "    return prompt, followup\n",
    "\n",
    "def get_openai_prompt_without_context_elaboration_first(tweet_text, label):\n",
    "    prompt = f\"Elaborate on whether you think the Tweet is about {label} or something else.\\n\\nTweet: {tweet_text}\\n\\n\"\n",
    "    followup = f\"\\nAssign the label 1 if it's about {label} or 0 for not based on the elaboration. Only output the number.\"\n",
    "    return prompt, followup\n",
    "\n",
    "# last TODO: Here it's correct check if its correct \n",
    "def get_openai_prompt_without_context_elaboration_first_v02(tweet_text, label):\n",
    "    prompt = f\"Elaborate on whether you think the Tweet is about {label} or something else.\\nTweet: {tweet_text}\\nElaboration: \"\n",
    "    followup = f\"Based on the elaboration, classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\nTweet: {tweet_text}\\nElaboration: [ELABORATION]\\nClass: \"\n",
    "    return prompt, followup\n",
    "\n",
    "def get_openai_prompt_without_context_elaboration_first_v03(tweet_text, label):\n",
    "    prompt = f\"Elaborate on whether you think the Tweet is about {label} or something else.\\nTweet: {tweet_text}\\nElaboration: \"\n",
    "    followup = f\"Based on the elaboration, assign 1 if it's about {label} or 0 if not.\\nElaboration: [ELABORATION]\\nClass: \"\n",
    "    return prompt, followup\n",
    "\n",
    "def get_openai_prompt_without_context_only_classification(tweet_text, label):\n",
    "    prompt = f\"Classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\n\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_openai_prompt_without_context_only_classification_v02(tweet_text, label):\n",
    "    prompt = f\"Give the tweet a binary class based on if it's about {label} or not.\\n\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_openai_prompt_without_context_only_classification_v03(tweet_text, label):\n",
    "    prompt = f\"Assign 1 if the tweet is about {label}. Assign 0 if it is not about {label}.\\n\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_openai_prompt_with_rules_only_classification(tweet_text, label, rules):\n",
    "    prompt = f\"Based on rules, classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\nRules: {rules}\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_openai_few_shot_prompt_only_classification_1_pos_example(tweet_text, label, example_tweet):\n",
    "    prompt = f\"Classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\nExample Tweet: {example_tweet}\\nClass: 1\\n\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_openai_few_shot_prompt_only_classification_1_neg_example(tweet_text, label, example_tweet):\n",
    "    prompt = f\"Classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\nExample Tweet: {example_tweet}\\nClass: 0\\n\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_openai_few_shot_prompt_only_classification_1_random_example(tweet_text, label, example_tweet, example_tweet_label):\n",
    "    prompt = f\"Classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\nExample Tweet: {example_tweet}\\nClass: {example_tweet_label}\\n\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_openai_few_shot_prompt_only_classification_3_random_example(tweet_text, label, example_tweet, example_tweet_label1, example_tweet2, example_tweet_label2, example_tweet3, example_tweet_label3):\n",
    "    prompt = f\"Classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\nExample Tweet: {example_tweet}\\nClass: {example_tweet_label1}\\nExample Tweet: {example_tweet2}\\nClass: {example_tweet_label2}\\nExample Tweet: {example_tweet3}\\nClass: {example_tweet_label3}\\n\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_openai_few_shot_prompt_only_classification_1_pos_1_neg_example(tweet_text, label, pos_example_tweet, neg_example_tweet):\n",
    "    prompt = f\"Classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\nExample Tweet: {pos_example_tweet}\\nClass: 1\\nExample Tweet: {neg_example_tweet}\\nClass: 0\\n\\nTweet: {tweet_text}\\nClass: \"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_positive_example(df, label, exclude_tweet):\n",
    "    pos_example_df = df[(df['annotations'].apply(lambda x: label in x)) & (df['text'] != exclude_tweet)]\n",
    "    pos_example_tweet = pos_example_df.sample(n=1, random_state=42)['text'].values[0]\n",
    "    return pos_example_tweet\n",
    "\n",
    "def get_negative_example(df, label, exclude_tweet):\n",
    "    neg_example_df = df[(df['annotations'].apply(lambda x: label not in x)) & (df['text'] != exclude_tweet)]\n",
    "    neg_example_tweet = neg_example_df.sample(n=1, random_state=42)['text'].values[0]\n",
    "    return neg_example_tweet\n",
    "\n",
    "def get_random_examples(df, label, exclude_tweet, n):\n",
    "    # Exclude the specific tweet\n",
    "    df = df[df['text'] != exclude_tweet]\n",
    "    \n",
    "    # Sample n random examples\n",
    "    sampled_df = df.sample(n=n, random_state=42)\n",
    "    \n",
    "    # Return a list of tuples, each containing the tweet text and its annotations\n",
    "    return list(zip(sampled_df['text'].values, sampled_df['annotations'].apply(lambda x: int(label in x)).values))\n",
    "\n",
    "def get_model_by_type(model_type):\n",
    "    if model_type == \"llama\":\n",
    "        return #get_llama_response\n",
    "    elif model_type == \"vicuna\":\n",
    "        return #get_vicuna_response\n",
    "    elif model_type == \"openassistant\":\n",
    "        return #get_openassistant_response\n",
    "    elif \"openai\" in model_type:\n",
    "        return get_openai_response\n",
    "    elif \"gpt-3.5\" in model_type:\n",
    "        return get_openai_response\n",
    "\n",
    "def get_response(prompt, first_model_type, second_model_type = \"\", follow_up = \"\", prompting_type = \"simple\", context = \"\", openai_model = \"\", max_tokens = 200, temperature = 0.7, stop = None):\n",
    "    \n",
    "    valid_models = [\"llama\", \"vicuna\", \"openassistant\", \"openai-davinci\", \"openai-gpt-3.5-turbo\"]\n",
    "    assert first_model_type in valid_models, \"First model type needs to be one of the following: \" + \", \".join(valid_models)\n",
    "    first_model = get_model_by_type(first_model_type)\n",
    "\n",
    "    if prompting_type == \"two-way\":\n",
    "        if second_model_type == \"\":\n",
    "            second_model = get_model_by_type(first_model_type)\n",
    "        else:\n",
    "            assert second_model_type in valid_models, \"Second model type needs to be one of the following: \" + \", \".join(valid_models)\n",
    "            assert follow_up != \"\", \"Follow up needs to be specified for two_way prompting type\"\n",
    "            second_model = get_model_by_type(second_model_type)\n",
    "\n",
    "        if openai_model != \"\":\n",
    "            #print(\"first prompt: \", prompt)\n",
    "            first_response = first_model(prompt, context = context, model = openai_model)\n",
    "            if \"gpt\" in second_model_type:\n",
    "                first_response = [prompt, {\"role\": \"assistant\", \"content\": first_response}]\n",
    "            #time.sleep(2)\n",
    "            #print(\"First response: \", first_response)\n",
    "            second_response = second_model(follow_up, context = prompt + first_response, model = openai_model)\n",
    "            return second_response\n",
    "        \n",
    "    if prompting_type == \"simple\":\n",
    "        return first_model(prompt, model = openai_model, max_tokens = max_tokens, temperature = temperature, stop = stop)\n",
    "\n",
    "\n",
    "def get_openai_response(prompt, context = [], model = \"gpt-3.5-turbo\", max_tokens = 200, temperature = 0.7, stop = None):\n",
    "    # Use OpenAI's ChatCompletion API to get the chatbot's response\n",
    "\n",
    "    if \"gpt\" in model:\n",
    "        messages = []\n",
    "        if context != [] and context != \"\":\n",
    "            for c in context:\n",
    "                messages.append(c)\n",
    "        messages.append(prompt)\n",
    "    else:\n",
    "        if context != \"\" and context != []:\n",
    "            prompt = context + prompt\n",
    "        #print(\"Context: \", context)\n",
    "        #print(\"Full prompt: \", prompt)\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # The name of the OpenAI chatbot model to use\n",
    "            messages=messages,   # The conversation history up to this point, as a list of dictionaries\n",
    "            max_tokens=200,        # The maximum number of tokens (words or subwords) in the generated response\n",
    "            stop=None,              # The stopping sequence for the generated response, if any (not used here)\n",
    "            temperature=0.7,        # The \"creativity\" of the generated response (higher temperature = more creative)\n",
    "        )\n",
    "\n",
    "    elif model == \"davinci\":\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",  # The name of the OpenAI chatbot model to use\n",
    "            prompt=prompt,   # The conversation history up to this point, as a list of dictionaries\n",
    "            max_tokens=200,        # The maximum number of tokens (words or subwords) in the generated response\n",
    "            stop=None,              # The stopping sequence for the generated response, if any (not used here)\n",
    "            temperature=0.7,        # The \"creativity\" of the generated response (higher temperature = more creative)\n",
    "        )\n",
    "\n",
    "    # Find the first response from the chatbot that has text in it (some responses may not have text)\n",
    "    for choice in response.choices:\n",
    "        if \"text\" in choice:\n",
    "            return choice.text\n",
    "\n",
    "    # If no response with text is found, return the first response's content (which may be empty)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your original DataFrame: df_all\n",
    "# all_labels: list of labels\n",
    "balanced_dfs = []\n",
    "\n",
    "rules = [\"Oxford dictionary's definition of war: ‚Äúsituation in which two or more countries or groups of people fight against each other over a period of time‚Äù. Oxford dictionary's definition of terror (terrorism): ‚Äúviolent action or the threat of violent action that is intended to cause fear, usually for political purposes‚Äù. Remark: This category includes also causes and consequences of war/terror (e.g. ‚Äúthe current situation in Ukraine may cause a supply crisis for wheat products‚Äù).\",\n",
    "\"Oxford dictionary's definition of conspiracy: ‚Äúa secret plan by a group of people to do something harmful or illegal‚Äù. Remark: Assignment of this category may depend on viewpoint and political stance of rater, which can be mitigated by focusing on the definition above. If the content of a tweet describes a conspiratorial activity/process, it will be labeled ‚Äúconspiracy theory‚Äù.\",\n",
    "\"Oxford dictionary's definition of education: ‚Äúa process of teaching, training and learning, especially in schools, colleges or universities, to improve knowledge and develop skills‚Äù. Remark: Does not include education/training of soldiers (ü°™war/terror).\",\n",
    "\"Oxford dictionary's definition of election: ‚Äúthe process of choosing a person or a group of people for a position, especially a political position, by voting‚Äù. Remark: This category includes all activities aimed at rallying the population for participation in a public election, description of election outcomes, and conduct of the election itself.\",\n",
    "\"Oxford dictionary's definition of environment: ‚Äúthe natural world in which people, animals and plants live‚Äù. Remark: This category is typically used for tweet content revolving around activities and processes affecting the environment in some way.\",\n",
    "\"Oxford dictionary's definition of government: ‚Äúthe group of people who are responsible for controlling a country or a state‚Äù. Oxford dictionary's definition of public: ‚Äúordinary people who are not members of a particular group or organization‚Äù Remark: This category includes also statements/content about the public perception of activities/processes of government (i.e. voiced criticism or praise for a government).\",\n",
    "\"Oxford dictionary's definition of health: ‚Äúthe condition of a person's body or mind‚Äù. Remark: This category includes also statements related to public health. In such a case both Health and Government/Public must be selected.\",\n",
    "\"Oxford dictionary's definition of immigration: ‚Äúthe process of coming to live permanently in a different country from the one you were born in‚Äù. Oxford dictionary's definition of integration: ‚Äúthe act or process of mixing people who have previously been separated, usually because of colour, race, religion, etc.‚Äù\",\n",
    "\"Oxford dictionary's definition of justice: ‚Äúthe legal system used to punish people who have committed crimes‚Äù. Oxford dictionary's definition of crime: ‚Äúactivities that involve breaking the law‚Äù. Remark: This category does not include statements/content on war crimes (ü°™ war/terror).\",\n",
    "\"Oxford dictionary's definition of labor: ‚Äúwork, especially physical work‚Äù. Oxford dictionary's definition of employment: ‚Äúwork, especially when it is done to earn money; the state of being employed‚Äù.\",\n",
    "\"Oxford dictionary's definition of macroeconomics: ‚Äúthe study of large economic systems, such as those of whole countries or areas of the world‚Äù. Oxford dictionary's definition of regulation: ‚Äùan official rule made by a government or some other authority‚Äù. Remark: In case of statements/content on economic regulations, this category may likely co-occur with Government/Public category.\", \n",
    "\"Oxford dictionary's definition of media: ‚Äúthe main ways that large numbers of people receive information and entertainment, that is television, radio, newspapers and the internet‚Äù. Oxford dictionary's definition of journalism: ‚Äúthe work of collecting and writing news stories for newspapers, magazines, radio, television or online news sites; the news stories that are written‚Äù. Remark: This category will be used for statements/content which explicitly references other media outlets or journalists (e.g. ‚ÄúBBC has reported that ‚Ä¶‚Äù, ‚ÄúBellingcat has discovered a secret operation of X‚Äù). Content which appears ‚Äúnews-worthy‚Äù does not generally fall into this category (ü°™ newsworthiness is very subjective and context-dependent).\",\n",
    "\"Oxford dictionary's definition of religion: ‚Äúthe belief in the existence of a god or gods, and the activities that are connected with the worship of them, or in the teachings of a spiritual leader‚Äù.\",\n",
    "\"Oxford dictionary's definition of science: ‚Äúknowledge about the structure and behavior of the natural and physical world, based on facts that you can prove, for example by experiments‚Äù. Oxford dictionary's definition of technology: ‚Äúscientific knowledge used in practical ways in industry, for example in designing new machines‚Äù.\"]\n",
    "\n",
    "all_labels = [\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \n",
    "              \"Government/Public\", \"Health\", \"Immigration/Integration\", \n",
    "              \"Justice/Crime\", \"Labor/Employment\", \n",
    "              \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
    "\n",
    "for label in all_labels:\n",
    "    # Initialize an empty DataFrame for the balanced dataset\n",
    "    balanced_df = pd.DataFrame()\n",
    "    # Get the rows with the current label\n",
    "    label_rows = df_all[df_all['annotations'].apply(lambda x: label in x)]\n",
    "    \n",
    "    # Get the rows without the current label\n",
    "    non_label_rows = df_all[df_all['annotations'].apply(lambda x: label not in x)]\n",
    "    \n",
    "    # Sample 65 rows with the current label\n",
    "    sample_label_rows = label_rows.sample(n=65, random_state=42)\n",
    "    \n",
    "    # Sample 65 rows without the current label\n",
    "    sample_non_label_rows = non_label_rows.sample(n=65, random_state=42)\n",
    "    \n",
    "    # Combine the samples\n",
    "    combined_sample = pd.concat([sample_label_rows, sample_non_label_rows], ignore_index=True)\n",
    "    \n",
    "    # Add the samples to the balanced DataFrame\n",
    "    balanced_df = pd.concat([balanced_df, combined_sample], ignore_index=True)\n",
    "\n",
    "    balanced_dfs.append(balanced_df)\n",
    "df_all['normalized_tweet'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model: generic_prompt_few_shot_prompt_only_classification_3_random_example\n",
      "----------------------------------\n",
      "Starting requesting for label: War/Terror\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 99/130 [01:01<00:22,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 98\n",
      "Sample Tweet:  Cleric accused of masterminding 2008 Mumbai attacks under house arrest [url] [url]\n",
      "Sample Annotation:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [01:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting requesting for label: Conspiracy Theory\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 99/130 [00:55<00:14,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 98\n",
      "Sample Tweet:  #Almost all militants of illegal #armed #groups refuse to move to the #front line . #Syria #Idlib\n",
      "Sample Annotation:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [01:13<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting requesting for label: Education\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 99/130 [00:59<00:16,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 98\n",
      "Sample Tweet:  Desperate Clinton Campaign Doubts ‚Äú Legitimacy ‚Äù of Trump's Win One Week from Inauguration [url] [url]\n",
      "Sample Annotation:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [01:16<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting requesting for label: Election Campaign\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 99/130 [00:58<00:17,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 98\n",
      "Sample Tweet:  He's At It Again ! This Guy's Hilarious Photoshop ' Fixes ' Will Make Your Day [url]\n",
      "Sample Annotation:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [01:14<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting requesting for label: Environment\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 99/130 [00:58<00:19,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 98\n",
      "Sample Tweet:  PA Sec of State Releases 20 Electors Names , Addresses and Phone Numbers ! [url] [url]\n",
      "Sample Annotation:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [01:19<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting requesting for label: Government/Public\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 99/130 [00:57<00:17,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 98\n",
      "Sample Tweet:  #CrazySocks4Docs : raising awareness about depression amongst doctors - [url] Thanduxolo Buti The #CrazySocks4Docs campaign hopes to end the stigma and help curb the high number of depression and suicide case amongst doctors and medicine students . The campaig ... [url]\n",
      "Sample Annotation:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [01:16<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting requesting for label: Health\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 99/130 [01:45<00:16,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 98\n",
      "Sample Tweet:  One suspect was arrested in Soweto . During the search , a plastic bag containing 3500 mandrax tablets , 7 plastic bags containing dagga , a box with 25 9mm live rounds and 1 black 9mm Z88 were discovered . [url]\n",
      "Sample Annotation:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting requesting for label: Immigration/Integration\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 99/130 [00:57<00:20,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 98\n",
      "Sample Tweet:  Susan Rice and the Russians . Will Obama's new national security advisor play nice and get along with Moscow ? [url]\n",
      "Sample Annotation:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [01:19<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting requesting for label: Justice/Crime\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 79/130 [00:47<00:29,  1.71it/s]"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "\n",
    "import random\n",
    "models_to_test_names = [\"generic_prompt_few_shot_prompt_only_classification_3_random_example\"]\n",
    "model_funcs = [get_openai_few_shot_prompt_only_classification_3_random_example]\n",
    "\n",
    "for model_name, model_func in zip(models_to_test_names, model_funcs):\n",
    "\n",
    "    print(\"Starting with model: \" + model_name)\n",
    "    print(\"----------------------------------\")\n",
    "    df_all_tmp = df_all.copy()\n",
    "\n",
    "    df_all_tmp['normalized_tweet'] = None\n",
    "    normalized_tweets_db = {}\n",
    "\n",
    "    for idx, label in enumerate(all_labels):\n",
    "\n",
    "        sample_df = balanced_dfs[idx]\n",
    "\n",
    "        print(\"Starting requesting for label: \" + label + \"\\n\")\n",
    "\n",
    "        new_column_name = f'{label}_pred'\n",
    "        df_all[new_column_name] = None\n",
    "        output_folder = f\"../data/openai_text_davinci_003/{model_name}/\"\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        i = 0\n",
    "        # Iterate over the rows of the sample_df\n",
    "        for index, row in tqdm(sample_df.iterrows(), total=sample_df.shape[0]):\n",
    "\n",
    "            tweet_text = normalizeTweet(row['text'])\n",
    "            df_all.loc[lambda df: df['id'] == row[\"id\"], 'normalized_tweet'] = tweet_text\n",
    "\n",
    "            pos_example_tweet = get_positive_example(sample_df, label, row[\"text\"])\n",
    "            neg_example_tweet = get_negative_example(sample_df, label, row[\"text\"])\n",
    "\n",
    "            pos_example_tweet = normalizeTweet(pos_example_tweet)\n",
    "            neg_example_tweet = normalizeTweet(neg_example_tweet)\n",
    "\n",
    "            # select the function based on model_func and generate the prompt\n",
    "            if model_func.__name__ == 'get_openai_few_shot_prompt_only_classification_1_pos_example':\n",
    "                prompt, followup = model_func(tweet_text, label, pos_example_tweet)\n",
    "            elif model_func.__name__ == 'get_openai_few_shot_prompt_only_classification_1_neg_example':\n",
    "                prompt, followup = model_func(tweet_text, label, neg_example_tweet)\n",
    "            elif model_func.__name__ == 'get_openai_few_shot_prompt_only_classification_1_random_example':\n",
    "                example_tweet = random.choice([pos_example_tweet, neg_example_tweet])\n",
    "                example_tweet_label = 1 if example_tweet == pos_example_tweet else 0\n",
    "                prompt, followup = model_func(tweet_text, label, example_tweet, example_tweet_label)\n",
    "            elif model_func.__name__ == 'get_openai_few_shot_prompt_only_classification_3_random_example':\n",
    "                examples = get_random_examples(sample_df, label, row[\"text\"], 3)\n",
    "                prompt, followup = model_func(tweet_text, label, normalizeTweet(examples[0][0]), examples[0][1], normalizeTweet(examples[1][0]), examples[1][1], normalizeTweet(examples[2][0]), examples[2][1])\n",
    "            elif model_func.__name__ == 'get_openai_few_shot_prompt_only_classification_1_pos_1_neg_example':\n",
    "                prompt, followup = model_func(tweet_text, label, pos_example_tweet, neg_example_tweet)\n",
    "\n",
    "            \"\"\"prompt, followup = get_openai_prompt_without_context_elaboration_first(tweet_text, label)\n",
    "            prompt = {\"role\": \"user\", \"content\": prompt}\n",
    "            followup = {\"role\": \"system\", \"content\": followup}\n",
    "            response = get_response(prompt, \"openai-gpt-3.5-turbo\", prompting_type = \"two-way\", follow_up=followup)\"\"\"\n",
    "\n",
    "            \"\"\"prompt, followup = get_openai_prompt_without_context_only_classification(tweet_text, label)\n",
    "            response = get_response(prompt, \"openai-davinci\", prompting_type = \"simple\")\"\"\"\n",
    "            response = get_response(prompt, \"openai-davinci\", prompting_type = \"simple\", follow_up=\"\", openai_model=\"davinci\", max_tokens=5)\n",
    "\n",
    "            # Save the response in the 'api_results' column\n",
    "            df_all.loc[lambda df: df['id'] == row[\"id\"], new_column_name] = response\n",
    "            \n",
    "            i+=1\n",
    "            # Save the DataFrame to a CSV file every 100 steps\n",
    "            if (i + 1) % 100 == 0:\n",
    "                output_path = os.path.join(output_folder, 'generic_test_0.csv')\n",
    "                df_all.to_csv(output_path, index=False)\n",
    "                print(f\"Saved progress at index {index}\")\n",
    "                print(\"Sample Tweet: \", tweet_text)\n",
    "                print(\"Sample Annotation: \", response)\n",
    "\n",
    "        # Save the final DataFrame to a CSV file\n",
    "        output_path = os.path.join(output_folder, 'generic_test_0.csv')\n",
    "        df_all.to_csv(output_path, index=False)\n",
    "\n",
    "        # Save the final DataFrame to a CSV file\n",
    "    output_path = os.path.join(output_folder, 'generic_test_0.csv')\n",
    "    df_all.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>normalized_tweet</th>\n",
       "      <th>War/Terror_pred</th>\n",
       "      <th>Conspiracy Theory_pred</th>\n",
       "      <th>Education_pred</th>\n",
       "      <th>Election Campaign_pred</th>\n",
       "      <th>Environment_pred</th>\n",
       "      <th>Government/Public_pred</th>\n",
       "      <th>Health_pred</th>\n",
       "      <th>Immigration/Integration_pred</th>\n",
       "      <th>Justice/Crime_pred</th>\n",
       "      <th>Labor/Employment_pred</th>\n",
       "      <th>Macroeconomics/Economic Regulation_pred</th>\n",
       "      <th>Media/Journalism_pred</th>\n",
       "      <th>Religion_pred</th>\n",
       "      <th>Science/Technology_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>891103871484870657</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>How life may find a way on Saturn's moon https...</td>\n",
       "      <td>[Science/Technology]</td>\n",
       "      <td>How life may find a way on Saturn's moon [url]...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>898650367067664384</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>RightWing Millennial Retweet RT RT_America to ...</td>\n",
       "      <td>[Others]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012051694136512512</td>\n",
       "      <td>IRA_202012</td>\n",
       "      <td>The tobacco industry then peddles their produc...</td>\n",
       "      <td>[Health, Justice/Crime, Macroeconomics/Economi...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1296389394883063810</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @brianmixologist: Today, i want to salute a...</td>\n",
       "      <td>[Others]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1286189347973279746</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @ArthurMirama: You can only under estimate ...</td>\n",
       "      <td>[Government/Public]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>847754640972070912</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>Stocks: 5 things to know before the bell https...</td>\n",
       "      <td>[Others]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1038043813267296256</td>\n",
       "      <td>GRU_202012</td>\n",
       "      <td>September 4, 2018 #Syrian air defense units re...</td>\n",
       "      <td>[War/Terror]</td>\n",
       "      <td>September 4 , 2018 #Syrian air defense units r...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1030464264748728320</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @xJ57jjSHWvX9mAMmhv7fVaVzxe13bBfCZuGZaBNucL...</td>\n",
       "      <td>[Others]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1020843977669586945</td>\n",
       "      <td>UGANDA_0621</td>\n",
       "      <td>RT @HowweEnt: Dj Shiru To Thrill His Fans http...</td>\n",
       "      <td>[Others]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>883376409502199808</td>\n",
       "      <td>VENEZUELA_201901_2</td>\n",
       "      <td>BREAKING VIDEO : 70 Injured in Chaotic G20 Rio...</td>\n",
       "      <td>[Government/Public, Justice/Crime]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id       campaign_name  \\\n",
       "0     891103871484870657  VENEZUELA_201901_2   \n",
       "1     898650367067664384  VENEZUELA_201901_2   \n",
       "2    1012051694136512512          IRA_202012   \n",
       "3    1296389394883063810         UGANDA_0621   \n",
       "4    1286189347973279746         UGANDA_0621   \n",
       "..                   ...                 ...   \n",
       "795   847754640972070912  VENEZUELA_201901_2   \n",
       "796  1038043813267296256          GRU_202012   \n",
       "797  1030464264748728320         UGANDA_0621   \n",
       "798  1020843977669586945         UGANDA_0621   \n",
       "799   883376409502199808  VENEZUELA_201901_2   \n",
       "\n",
       "                                                  text  \\\n",
       "0    How life may find a way on Saturn's moon https...   \n",
       "1    RightWing Millennial Retweet RT RT_America to ...   \n",
       "2    The tobacco industry then peddles their produc...   \n",
       "3    RT @brianmixologist: Today, i want to salute a...   \n",
       "4    RT @ArthurMirama: You can only under estimate ...   \n",
       "..                                                 ...   \n",
       "795  Stocks: 5 things to know before the bell https...   \n",
       "796  September 4, 2018 #Syrian air defense units re...   \n",
       "797  RT @xJ57jjSHWvX9mAMmhv7fVaVzxe13bBfCZuGZaBNucL...   \n",
       "798  RT @HowweEnt: Dj Shiru To Thrill His Fans http...   \n",
       "799  BREAKING VIDEO : 70 Injured in Chaotic G20 Rio...   \n",
       "\n",
       "                                           annotations  \\\n",
       "0                                 [Science/Technology]   \n",
       "1                                             [Others]   \n",
       "2    [Health, Justice/Crime, Macroeconomics/Economi...   \n",
       "3                                             [Others]   \n",
       "4                                  [Government/Public]   \n",
       "..                                                 ...   \n",
       "795                                           [Others]   \n",
       "796                                       [War/Terror]   \n",
       "797                                           [Others]   \n",
       "798                                           [Others]   \n",
       "799                 [Government/Public, Justice/Crime]   \n",
       "\n",
       "                                      normalized_tweet War/Terror_pred  \\\n",
       "0    How life may find a way on Saturn's moon [url]...            None   \n",
       "1                                                 None            None   \n",
       "2                                                 None            None   \n",
       "3                                                 None            None   \n",
       "4                                                 None            None   \n",
       "..                                                 ...             ...   \n",
       "795                                               None            None   \n",
       "796  September 4 , 2018 #Syrian air defense units r...            None   \n",
       "797                                               None            None   \n",
       "798                                               None            None   \n",
       "799                                               None            None   \n",
       "\n",
       "    Conspiracy Theory_pred Education_pred Election Campaign_pred  \\\n",
       "0                     None           None                   None   \n",
       "1                     None           None                   None   \n",
       "2                     None           None                   None   \n",
       "3                     None           None                   None   \n",
       "4                     None           None                   None   \n",
       "..                     ...            ...                    ...   \n",
       "795                   None           None                   None   \n",
       "796                   None            \\n0                   None   \n",
       "797                   None           None                   None   \n",
       "798                   None           None                   None   \n",
       "799                   None           None                   None   \n",
       "\n",
       "    Environment_pred Government/Public_pred Health_pred  \\\n",
       "0               None                   None        None   \n",
       "1               None                   None        None   \n",
       "2               None                   None        None   \n",
       "3               None                   None        None   \n",
       "4               None                   None        None   \n",
       "..               ...                    ...         ...   \n",
       "795             None                   None        None   \n",
       "796             None                   None        None   \n",
       "797             None                   None        None   \n",
       "798             None                   None        None   \n",
       "799             None                   None        None   \n",
       "\n",
       "    Immigration/Integration_pred Justice/Crime_pred Labor/Employment_pred  \\\n",
       "0                           None               None                  None   \n",
       "1                           None               None                  None   \n",
       "2                           None               None                  None   \n",
       "3                           None               None                  None   \n",
       "4                           None               None                  None   \n",
       "..                           ...                ...                   ...   \n",
       "795                         None               None                  None   \n",
       "796                         None               None                  None   \n",
       "797                         None               None                  None   \n",
       "798                         None               None                  None   \n",
       "799                         None               None                  None   \n",
       "\n",
       "    Macroeconomics/Economic Regulation_pred Media/Journalism_pred  \\\n",
       "0                                      None                  None   \n",
       "1                                      None                  None   \n",
       "2                                      None                  None   \n",
       "3                                      None                  None   \n",
       "4                                      None                  None   \n",
       "..                                      ...                   ...   \n",
       "795                                    None                  None   \n",
       "796                                    None                  None   \n",
       "797                                    None                  None   \n",
       "798                                    None                  None   \n",
       "799                                    None                  None   \n",
       "\n",
       "    Religion_pred Science/Technology_pred  \n",
       "0            None                     \\n0  \n",
       "1            None                    None  \n",
       "2            None                    None  \n",
       "3            None                    None  \n",
       "4            None                    None  \n",
       "..            ...                     ...  \n",
       "795          None                    None  \n",
       "796           \\n0                    None  \n",
       "797          None                    None  \n",
       "798          None                    None  \n",
       "799          None                    None  \n",
       "\n",
       "[5000 rows x 19 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
