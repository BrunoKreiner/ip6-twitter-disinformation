{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Define a list of filenames to load\n",
    "filenames = [\"../data/labeled_data/generic_test_0.json\"]\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_valid = pd.DataFrame()\n",
    "\n",
    "# Load all JSON data and concatenate into one DataFrame\n",
    "for filename in filenames:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    df_train = pd.DataFrame(data[\"train\"])\n",
    "    df_test = pd.DataFrame(data[\"test\"])\n",
    "    df_valid = pd.DataFrame(data[\"valid\"])\n",
    "\n",
    "def normalizeToken(token):\n",
    "    lowercased_token = token.lower()\n",
    "    if token.startswith(\"@\"):\n",
    "        return \"@USER\"\n",
    "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "        return \"[url]\"\n",
    "    elif len(token) == 1:\n",
    "        return demojize(token)\n",
    "    else:\n",
    "        if token == \"’\":\n",
    "            return \"'\"\n",
    "        elif token == \"…\":\n",
    "            return \"...\"\n",
    "        else:\n",
    "            return token\n",
    "    \n",
    "def normalizeTweet(tweet):\n",
    "    tokens = TweetTokenizer().tokenize(tweet.replace(\"’\", \"'\"))\n",
    "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
    "\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"n 't\", \"n't\")\n",
    "            .replace(\"ca n't\", \"can't\")\n",
    "            .replace(\"ai n't\", \"ain't\")\n",
    "    )\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"p . m .\", \"pm\")\n",
    "            .replace(\"p . m\", \"pm\")\n",
    "            .replace(\"a . m .\", \"am\")\n",
    "            .replace(\"a . m\", \"am\")\n",
    "    )\n",
    "    return \" \".join(normTweet.split())\n",
    "\n",
    "def api(prompt):\n",
    "    import requests\n",
    "\n",
    "# For local streaming, the websockets are hosted without ssl - http://\n",
    "HOST = 'http://127.0.0.1:5000'\n",
    "URI = f'{HOST}/api/v1/generate'\n",
    "\n",
    "# For reverse-proxied streaming, the remote will likely host with ssl - https://\n",
    "# URI = 'https://your-uri-here.trycloudflare.com/api/v1/generate'\n",
    "\n",
    "def get_response(request_params, prompt, context):\n",
    "    request_params['prompt'] = prompt\n",
    "    request_params['context'] = context\n",
    "\n",
    "    response = requests.post(URI, json=request_params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()['results'][0]['text']\n",
    "        #print(prompt + result)\n",
    "        return result\n",
    "    else:\n",
    "    \tprint(response)\n",
    "\n",
    "def get_base_request_params(max_new_tokens = 200, stopping_strings = []):\n",
    "    return {\n",
    "        'prompt': None,\n",
    "        'context': None,\n",
    "        'max_new_tokens': 200,\n",
    "        'do_sample': True,\n",
    "        'temperature': 0.7,\n",
    "        'top_p': 0.1,\n",
    "        'typical_p': 1,\n",
    "        'repetition_penalty': 1.2,\n",
    "        'encoder_repetition_penalty': 1.0,\n",
    "        'top_k': 40,\n",
    "        'min_length': 0,\n",
    "        'no_repeat_ngram_size': 0,\n",
    "        'num_beams': 1,\n",
    "        'penalty_alpha': 0,\n",
    "        'length_penalty': 1,\n",
    "        'early_stopping': False,\n",
    "        'seed': -1,\n",
    "        #'add_bos_token': True,\n",
    "        #'truncation_length': 2048,\n",
    "        #'ban_eos_token': False,\n",
    "        #'skip_special_tokens': True,\n",
    "        'stopping_strings': stopping_strings\n",
    "    }\n",
    "\n",
    "def get_vicuna_prompt_without_context_only_classification(tweet_text, label):\n",
    "    prompt = f\"### Human: Classify the Tweet based on if it's about {label}. Use 1 or 0 as class.\\n\\nTweet: {tweet_text}\\n### Assistant:\\nClass: \"\n",
    "    context = ''\n",
    "    return prompt, context\n",
    "\n",
    "all_labels = [\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \n",
    "              \"Government/Public\", \"Health\", \"Immigration/Integration\", \n",
    "              \"Justice/Crime\", \"Labor/Employment\", \n",
    "              \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test_names = [\"get_vicuna_prompt_without_context_only_classification_full_classification\"]\n",
    "model_funcs = [get_vicuna_prompt_without_context_only_classification]\n",
    "dataframes = [df_test]\n",
    "dataframes_names = [\"test\"]\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "\n",
    "    for model_name, model_func in zip(models_to_test_names, model_funcs):\n",
    "        print(\"Starting with model: \" + model_name)\n",
    "        print(\"----------------------------------\")\n",
    "        df_tmp = df.copy()\n",
    "        df_tmp[\"prompt\"] = \"\"\n",
    "        df_tmp[\"context\"] = \"\"\n",
    "\n",
    "        for idx, label in enumerate(all_labels):\n",
    "            new_column_name = f'{label}_pred'\n",
    "            df_tmp[new_column_name] = None\n",
    "\n",
    "        new_column_name = dataframes_names[i] + model_name\n",
    "        output_folder = f\"../data/vicuna_4bit/{model_name}/\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for idx, row in tqdm(df_tmp.iterrows(), total=df_tmp.shape[0]):\n",
    "\n",
    "            tweet_text = normalizeTweet(row[\"text\"])\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], 'normalized_tweet'] = tweet_text\n",
    "            prompt, context = model_func(tweet_text, \"label\")\n",
    "            df_tmp.at[idx, \"prompt\"] = prompt\n",
    "            df_tmp.at[idx, \"context\"] = context\n",
    "\n",
    "            request_params = get_base_request_params()\n",
    "            request_params[\"stopping_strings\"] = [\"\\n\", \"### Human:\", \"Human:\", \"###\"]\n",
    "            \n",
    "            for label in all_labels:        \n",
    "                new_column_name = f'{label}_pred'\n",
    "                prompt, context = model_func(tweet_text, label)\n",
    "                response = get_response(request_params, prompt, \"\")\n",
    "                df_tmp.at[idx, new_column_name] = response\n",
    "\n",
    "            # Save the response in the 'api_results' column\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], new_column_name] = response\n",
    "            if (i + 1) % 100 == 0:\n",
    "                output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "                df_tmp.to_csv(output_path, index=False)\n",
    "                print(f\"Saved progress at index {idx}\")\n",
    "                print(\"Sample Tweet: \", tweet_text)\n",
    "                print(\"Sample Annotation: \", response)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "        df_tmp.to_csv(output_path, index=False)        \n",
    "            # Save the request_params as a JSON file in the output folder\n",
    "        with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "            json.dump(request_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id       campaign_name                                               text                                        annotations                                             prompt  context  War/Terror_pred  ...  Justice/Crime_pred  Labor/Employment_pred  Macroeconomics/Economic Regulation_pred  Media/Journalism_pred  Religion_pred  Science/Technology_pred                                   normalized_tweet\n",
      "0    1144169368227635200            REA_0621  The Automobile Association said it is expectin...             ['Macroeconomics/Economic Regulation']  ### Human: Classify the Tweet based on if it's...      NaN                0  ...                 0.0                    0.0                                        0                      0              0                        0  The Automobile Association said it is expectin...\n",
      "1    1187637103850610688            REA_0621  A severe flooding, triggered by heavy rains an...                                    ['Environment']  ### Human: Classify the Tweet based on if it's...      NaN                0  ...                 0.0                    0.0                                        0                      1              0                        0  A severe flooding , triggered by heavy rains a...\n",
      "2    1062269743749566464          GRU_202012  Militants of the Hayat Tahrir ash-Sham group p...                                     ['War/Terror']  ### Human: Classify the Tweet based on if it's...      NaN                1  ...                 0.0                    0.0                                        0                      0              0                        0  Militants of the Hayat Tahrir ash-Sham group p...\n",
      "3    1100425181946880000            REA_0621  PIC Amendment Bill for transparency adopted by...                              ['Government/Public']  ### Human: Classify the Tweet based on if it's...      NaN                0  ...                 1.0                    1.0                                        1                      1              0                        0  PIC Amendment Bill for transparency adopted by...\n",
      "4    1129575563029561344         UGANDA_0621  RT @CQvMyyB0YfvwrUrsaZ6KI7yqaJfSUDTrAI0joQhgMA...                              ['Government/Public']  ### Human: Classify the Tweet based on if it's...      NaN                1  ...                 1.0                    1.0                                        0                      1              1                        1  RT @USER =: ARMY CHARITY WORK :round_pushpin: ...\n",
      "..                   ...                 ...                                                ...                                                ...                                                ...      ...              ...  ...                 ...                    ...                                      ...                    ...            ...                      ...                                                ...\n",
      "995  1166999406190780417            REA_0621  Rwanda and Zimbabwe entering deal: A Memorandu...             ['Macroeconomics/Economic Regulation']  ### Human: Classify the Tweet based on if it's...      NaN                0  ...                 0.0                    0.0                                        0                      0              0                        0  Rwanda and Zimbabwe entering deal : A Memorand...\n",
      "996   887818127295361024  VENEZUELA_201901_2  Trump Supporters React to Unhinged Rosie THREA...                              ['Government/Public']  ### Human: Classify the Tweet based on if it's...      NaN                0  ...                 1.0                    0.0                                        0                      1              0                        0  Trump Supporters React to Unhinged Rosie THREA...\n",
      "997   495089817923756032          IRA_202012  The American Aggression Enablement Act and the...                                         ['Others']  ### Human: Classify the Tweet based on if it's...      NaN                0  ...                 0.0                    0.0                                        0                      0              0                        0  The American Aggression Enablement Act and the...\n",
      "998  1154775632871477248            REA_0621  Body of a missing 4-year-old girl has been fou...                                  ['Justice/Crime']  ### Human: Classify the Tweet based on if it's...      NaN                1  ...                 1.0                    1.0                                        0                      1              1                        1  Body of a missing 4 - year-old girl has been f...\n",
      "999   823680762167771136  VENEZUELA_201901_2  VIDEO : #Women’sMarch Linda Sarsour Told Maddo...  ['Conspiracy Theory', 'Immigration/Integration...  ### Human: Classify the Tweet based on if it's...      NaN                1  ...                 1.0                    1.0                                        0                      1              1                        0  VIDEO : #Women'sMarch Linda Sarsour Told Maddo...\n",
      "\n",
      "[1000 rows x 21 columns]\n",
      "                                    precision    recall  f1-score  support\n",
      "War/Terror                           0.609907  0.772549  0.681661    255.0\n",
      "Conspiracy Theory                    0.129707  0.688889  0.218310     45.0\n",
      "Education                            0.027586  0.923077  0.053571     13.0\n",
      "Election Campaign                    0.061611  0.787879  0.114286     33.0\n",
      "Environment                          0.021956  0.785714  0.042718     14.0\n",
      "Government/Public                    0.369159  0.814433  0.508039    291.0\n",
      "Health                               0.091185  0.652174  0.160000     46.0\n",
      "Immigration/Integration              0.083832  0.777778  0.151351     36.0\n",
      "Justice/Crime                        0.201377  0.854015  0.325905    137.0\n",
      "Labor/Employment                     0.066066  0.785714  0.121884     28.0\n",
      "Macroeconomics/Economic Regulation   0.303030  0.322581  0.312500     62.0\n",
      "Media/Journalism                     0.061224  0.937500  0.114943     48.0\n",
      "Religion                             0.032573  0.909091  0.062893     11.0\n",
      "Science/Technology                   0.030702  0.636364  0.058577     11.0\n",
      "Others                               0.740000  0.546125  0.628450    271.0\n",
      "micro avg                            0.165815  0.723290  0.269782   1301.0\n",
      "macro avg                            0.188661  0.746259  0.237006   1301.0\n",
      "weighted avg                         0.408225  0.723290  0.456542   1301.0\n",
      "samples avg                          0.295838  0.714383  0.355592   1301.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../src\")\n",
    "import llm_utils\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def classification_reports_to_df(classification_reports, binary):\n",
    "\n",
    "    if binary:\n",
    "        # Your code for creating the DataFrame and adding the results\n",
    "        df = pd.DataFrame(columns=['label', 'f1_score_macro', #'precision_macro', 'recall_macro', 'support_macro',\n",
    "                                        'f1_score_class_0','support_class_0',\n",
    "                                        'f1_score_class_1', 'support_class_1'])\n",
    "\n",
    "        for label, cr in classification_reports.items():\n",
    "            try: \n",
    "                df = df.append({\n",
    "                    'label': label,\n",
    "                    'f1_score_macro': cr['macro avg']['f1-score'],\n",
    "                    #'precision_macro': cr['macro avg']['precision'],\n",
    "                    #'recall_macro': cr['macro avg']['recall'],\n",
    "                    #'support_macro': cr['macro avg']['support'],\n",
    "                    'f1_score_class_0': cr['0']['f1-score'],\n",
    "                    #'precision_class_0': cr['0']['precision'],\n",
    "                    #'recall_class_0': cr['0']['recall'],\n",
    "                    'support_class_0': cr['0']['support'],\n",
    "                    'f1_score_class_1': cr['1']['f1-score'],\n",
    "                    #'precision_class_1': cr['1']['precision'],\n",
    "                    #'recall_class_1': cr['1']['recall'],\n",
    "                    'support_class_1': cr['1']['support']\n",
    "                }, ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error for {label}: {e}\")\n",
    "                df = df.append({\n",
    "                    'label': label,\n",
    "                    'f1_score_macro': None,\n",
    "                    #'precision_macro': None,\n",
    "                    #'recall_macro': None,\n",
    "                    #'support_macro': None,\n",
    "                    'f1_score_class_0': None,\n",
    "                    #'precision_class_0': None,\n",
    "                    #'recall_class_0': None,\n",
    "                    'support_class_0': None,\n",
    "                    'f1_score_class_1': None,\n",
    "                    #'precision_class_1': None,\n",
    "                    #'recall_class_1': None,\n",
    "                    'support_class_1': None\n",
    "                }, ignore_index=True)\n",
    "                continue\n",
    "\n",
    "        # Display the results\n",
    "        return df\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Function to convert 'Classification: [0 or 1]' string to int value\n",
    "def extract_nth_character(classification_str, n, strip = False):\n",
    "    if strip and type(classification_str) == str:\n",
    "        classification_str = classification_str.strip()\n",
    "    #print(classification_str)\n",
    "    if pd.isna(classification_str):\n",
    "        return None\n",
    "    if type(classification_str) == float:\n",
    "        return classification_str\n",
    "    if type(classification_str) == int:\n",
    "        return classification_str\n",
    "    try:\n",
    "        classification_str = classification_str.strip()\n",
    "        #print(\"whole string: \", classification_str)\n",
    "        #print(\"only n\", classification_str[0])\n",
    "        class_value = int(classification_str[n])\n",
    "        if class_value != 0 and class_value != 1:\n",
    "            print(\"Class value not 0 or 1\")\n",
    "            print(\"---------------------\")\n",
    "            print(classification_str)\n",
    "            print(\"----------------------\")\n",
    "            return None\n",
    "        return class_value\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Function to assign 'Others' label if none of the prediction columns have a 1\n",
    "def assign_others_to_row(row, classes):\n",
    "    if not any(row[f\"{label}_pred\"] == 1 for label in classes):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def to_dataframe(average_reports, classes):\n",
    "    data = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1-score\": [],\n",
    "        \"support\": []\n",
    "    }\n",
    "    index = []\n",
    "\n",
    "    for i, average_report in enumerate(average_reports):\n",
    "        for class_name, metrics in average_report.items():\n",
    "            if class_name in {'micro avg', 'macro avg', 'weighted avg', 'accuracy'}:\n",
    "                continue\n",
    "            index.append(classes[i])\n",
    "            data[\"precision\"].append(metrics[\"0\"][\"precision\"])\n",
    "            data[\"recall\"].append(metrics[\"0\"][\"recall\"])\n",
    "            data[\"f1-score\"].append(metrics[\"0\"][\"f1-score\"])\n",
    "            data[\"support\"].append(metrics[\"0\"][\"support\"])\n",
    "\n",
    "    return pd.DataFrame(data, index=index)\n",
    "\n",
    "classes = [\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \n",
    "              \"Government/Public\", \"Health\", \"Immigration/Integration\", \n",
    "              \"Justice/Crime\", \"Labor/Employment\", \n",
    "              \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
    "    \n",
    "vicuna_full_classification_df = pd.read_csv(\"../data/vicuna_4bit/get_vicuna_prompt_without_context_only_classification_full_classification/test_generic_test_0.csv\")\n",
    "for class_ in classes:\n",
    "    vicuna_full_classification_df[f\"{class_}_pred\"] = vicuna_full_classification_df[f\"{class_}_pred\"].apply(lambda x: llm_utils.extract_using_class_token(x))\n",
    "\n",
    "print(vicuna_full_classification_df)\n",
    "vicuna_full_classification_df[\"Others_pred\"] = None\n",
    "for idx, row in vicuna_full_classification_df.iterrows():\n",
    "    vicuna_full_classification_df.at[idx, \"Others_pred\"] = assign_others_to_row(row, classes)\n",
    "\n",
    "classes.append(\"Others\")\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "vicuna_full_classification_df['annotations'] = vicuna_full_classification_df['annotations'].apply(ast.literal_eval)\n",
    "y_true = mlb.fit_transform(vicuna_full_classification_df['annotations'])\n",
    "vicuna_full_classification_df['response'] = vicuna_full_classification_df.apply(lambda row: [class_.replace('_pred', '') for class_ in classes if row[f\"{class_}_pred\"]], axis=1)\n",
    "y_pred = mlb.transform(vicuna_full_classification_df['response'])\n",
    "#print(vicuna_full_classification_df)\n",
    "report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "print(df_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
