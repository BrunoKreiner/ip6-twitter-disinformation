{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of filenames to load\n",
    "filenames = [\"../data/labeled_data/generic_test_0.json\"]\n",
    "\n",
    "# Load all JSON data and concatenate into one DataFrame\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data[\"train\"])\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, df, y):\n",
    "        self.input_ids = df['input_ids'].tolist()\n",
    "        self.attention_mask = df['attention_mask']\n",
    "        self.labels = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_mask[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\bruno\\anaconda3\\envs\\ip6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.2164692996710073, Test Loss: 0.15293932761996984, Precision Macro: 0.4879250176142039, Precision Micro: 0.8409893992932862, Recall Macro: 0.26616858451345393, Recall Micro: 0.544, F1 Macro: 0.3213357119180647, F1 Micro: 0.6606523247744622, Accuracy: 0.475, Time: 02:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bruno\\anaconda3\\envs\\ip6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.12726863578427583, Test Loss: 0.12193588002119213, Precision Macro: 0.8103344813242532, Precision Micro: 0.8491379310344828, Recall Macro: 0.46708588661627276, Recall Micro: 0.6754285714285714, F1 Macro: 0.5509046151097298, F1 Micro: 0.7523870146403564, Accuracy: 0.584375, Time: 02:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bruno\\anaconda3\\envs\\ip6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.08981120531097986, Test Loss: 0.10956695926142856, Precision Macro: 0.7683050502646296, Precision Micro: 0.8604972375690608, Recall Macro: 0.5786442966645003, Recall Micro: 0.712, F1 Macro: 0.6376842185362077, F1 Micro: 0.7792370231394622, Accuracy: 0.615625, Time: 02:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.06516935581021244, Test Loss: 0.1098371872853022, Precision Macro: 0.7795099011119713, Precision Micro: 0.8282828282828283, Recall Macro: 0.6208066901483922, Recall Micro: 0.7497142857142857, F1 Macro: 0.6744151080818109, F1 Micro: 0.7870425914817037, Accuracy: 0.63125, Time: 02:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.048519801546353845, Test Loss: 0.10636279932223261, Precision Macro: 0.7662071006245125, Precision Micro: 0.8245614035087719, Recall Macro: 0.6357917212226627, Recall Micro: 0.752, F1 Macro: 0.6754346680449225, F1 Micro: 0.7866108786610879, Accuracy: 0.63125, Time: 02:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.03402524955381523, Test Loss: 0.10633800378127489, Precision Macro: 0.7592187049500522, Precision Micro: 0.8111380145278451, Recall Macro: 0.6597960176486956, Recall Micro: 0.7657142857142857, F1 Macro: 0.6945940776849591, F1 Micro: 0.7877718988830099, Accuracy: 0.63125, Time: 02:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.026677896947876433, Test Loss: 0.11455364401626866, Precision Macro: 0.7690008411945205, Precision Micro: 0.8011904761904762, Recall Macro: 0.6408512267569427, Recall Micro: 0.7691428571428571, F1 Macro: 0.6740942998536028, F1 Micro: 0.7848396501457725, Accuracy: 0.6203125, Time: 02:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.020222024329268607, Test Loss: 0.12508483310084556, Precision Macro: 0.7577328093710255, Precision Micro: 0.8114143920595533, Recall Macro: 0.6332493756211833, Recall Micro: 0.7474285714285714, F1 Macro: 0.667265246489623, F1 Micro: 0.778108268887567, Accuracy: 0.625, Time: 02:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.019147554544179, Test Loss: 0.12257283843646291, Precision Macro: 0.738763109795947, Precision Micro: 0.7997698504027618, Recall Macro: 0.67241680357684, Recall Micro: 0.7942857142857143, F1 Macro: 0.6924258315791785, F1 Micro: 0.7970183486238532, Accuracy: 0.6390625, Time: 02:09\n",
      "Epoch 10/10, Train Loss: 0.019440196765572182, Test Loss: 0.1222905451519182, Precision Macro: 0.7500670449227063, Precision Micro: 0.8037383177570093, Recall Macro: 0.6765097267115059, Recall Micro: 0.7862857142857143, F1 Macro: 0.6993002125452678, F1 Micro: 0.7949162333911033, Accuracy: 0.6390625, Time: 02:08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_10200\\925989304.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Convert annotations column to a list of labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df_all['annotations'])\n",
    "\n",
    "# Load BERTweet model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\", normalization=True)\n",
    "model = AutoModel.from_pretrained(\"vinai/bertweet-large\")\n",
    "\n",
    "# Preprocess the text column by encoding the tweets and adding special tokens\n",
    "def preprocess_text(text):\n",
    "    return tokenizer.encode_plus(text, max_length=128, add_special_tokens=True, truncation=True, padding='max_length', return_attention_mask=True, return_tensors='pt')\n",
    "\n",
    "encoded_tweets = df_all['text'].apply(preprocess_text)\n",
    "input_ids = encoded_tweets.apply(lambda x: x['input_ids']).to_list()\n",
    "attention_mask = encoded_tweets.apply(lambda x: x['attention_mask']).to_list()\n",
    "df_encoded_tweets = pd.DataFrame({'input_ids': input_ids, 'attention_mask': attention_mask})\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "encoded_tweets_train, encoded_tweets_test, y_train, y_test = train_test_split(df_encoded_tweets, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define PyTorch dataset and dataloader for the training and testing sets\n",
    "train_dataset = TweetDataset(encoded_tweets_train.reset_index(), torch.tensor(y_train))\n",
    "test_dataset = TweetDataset(encoded_tweets_test.reset_index(), torch.tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Define the classifier model\n",
    "class TweetClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(TweetClassifier, self).__init__()\n",
    "        self.bertweet = AutoModel.from_pretrained(\"vinai/bertweet-large\")\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(self.bertweet.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bertweet(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = output.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.linear(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Train the classifier model using binary cross-entropy loss and the AdamW optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TweetClassifier(num_labels=len(mlb.classes_)).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "\n",
    "# Initialize dataframes for logging the losses and metrics\n",
    "metrics = pd.DataFrame(columns=['epoch', 'train_loss', 'test_loss', 'precision_macro', 'precision_micro', 'recall_macro', 'recall_micro', 'f1_macro', 'f1_micro', 'accuracy', 'time'])\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[0].to(device).squeeze(1)\n",
    "        attention_mask = batch[1].to(device).squeeze(1)\n",
    "        labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Casts operations to mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Compute metrics\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[0].to(device).squeeze(1)\n",
    "            attention_mask = batch[1].to(device).squeeze(1)\n",
    "            labels = batch[2].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            batch_pred = torch.sigmoid(outputs).cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            y_true.append(labels)\n",
    "            y_pred.append(batch_pred)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred > 0.5, average='macro')\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred > 0.5, average='micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred > 0.5)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "    time_str = f\"{int(minutes):02d}:{int(seconds):02d}\"\n",
    "\n",
    "    metrics = metrics.append({'epoch': epoch+1, 'train_loss': train_loss, 'test_loss': test_loss, 'precision_macro': precision_macro, 'precision_micro': precision_micro, 'recall_macro': recall_macro, 'recall_micro': recall_micro, 'f1_macro': f1_macro, 'f1_micro': f1_micro, 'accuracy': accuracy, 'time': time_str}, ignore_index=True)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss}, Test Loss: {test_loss}, Precision Macro: {precision_macro}, Precision Micro: {precision_micro}, Recall Macro: {recall_macro}, Recall Micro: {recall_micro}, F1 Macro: {f1_macro}, F1 Micro: {f1_micro}, Accuracy: {accuracy}, Time: {time_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.216469</td>\n",
       "      <td>0.152939</td>\n",
       "      <td>0.487925</td>\n",
       "      <td>0.840989</td>\n",
       "      <td>0.266169</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.321336</td>\n",
       "      <td>0.660652</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>02:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.127269</td>\n",
       "      <td>0.121936</td>\n",
       "      <td>0.810334</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>0.467086</td>\n",
       "      <td>0.675429</td>\n",
       "      <td>0.550905</td>\n",
       "      <td>0.752387</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.089811</td>\n",
       "      <td>0.109567</td>\n",
       "      <td>0.768305</td>\n",
       "      <td>0.860497</td>\n",
       "      <td>0.578644</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.637684</td>\n",
       "      <td>0.779237</td>\n",
       "      <td>0.615625</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.065169</td>\n",
       "      <td>0.109837</td>\n",
       "      <td>0.779510</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.620807</td>\n",
       "      <td>0.749714</td>\n",
       "      <td>0.674415</td>\n",
       "      <td>0.787043</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>02:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.048520</td>\n",
       "      <td>0.106363</td>\n",
       "      <td>0.766207</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.635792</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.675435</td>\n",
       "      <td>0.786611</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.034025</td>\n",
       "      <td>0.106338</td>\n",
       "      <td>0.759219</td>\n",
       "      <td>0.811138</td>\n",
       "      <td>0.659796</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.694594</td>\n",
       "      <td>0.787772</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.114554</td>\n",
       "      <td>0.769001</td>\n",
       "      <td>0.801190</td>\n",
       "      <td>0.640851</td>\n",
       "      <td>0.769143</td>\n",
       "      <td>0.674094</td>\n",
       "      <td>0.784840</td>\n",
       "      <td>0.620313</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.020222</td>\n",
       "      <td>0.125085</td>\n",
       "      <td>0.757733</td>\n",
       "      <td>0.811414</td>\n",
       "      <td>0.633249</td>\n",
       "      <td>0.747429</td>\n",
       "      <td>0.667265</td>\n",
       "      <td>0.778108</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>0.122573</td>\n",
       "      <td>0.738763</td>\n",
       "      <td>0.799770</td>\n",
       "      <td>0.672417</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.692426</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.639062</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>0.122291</td>\n",
       "      <td>0.750067</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.676510</td>\n",
       "      <td>0.786286</td>\n",
       "      <td>0.699300</td>\n",
       "      <td>0.794916</td>\n",
       "      <td>0.639062</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch  train_loss  test_loss  precision_macro  precision_micro  \\\n",
       "0     1    0.216469   0.152939         0.487925         0.840989   \n",
       "1     2    0.127269   0.121936         0.810334         0.849138   \n",
       "2     3    0.089811   0.109567         0.768305         0.860497   \n",
       "3     4    0.065169   0.109837         0.779510         0.828283   \n",
       "4     5    0.048520   0.106363         0.766207         0.824561   \n",
       "5     6    0.034025   0.106338         0.759219         0.811138   \n",
       "6     7    0.026678   0.114554         0.769001         0.801190   \n",
       "7     8    0.020222   0.125085         0.757733         0.811414   \n",
       "8     9    0.019148   0.122573         0.738763         0.799770   \n",
       "9    10    0.019440   0.122291         0.750067         0.803738   \n",
       "\n",
       "   recall_macro  recall_micro  f1_macro  f1_micro  accuracy   time  \n",
       "0      0.266169      0.544000  0.321336  0.660652  0.475000  02:12  \n",
       "1      0.467086      0.675429  0.550905  0.752387  0.584375  02:10  \n",
       "2      0.578644      0.712000  0.637684  0.779237  0.615625  02:09  \n",
       "3      0.620807      0.749714  0.674415  0.787043  0.631250  02:12  \n",
       "4      0.635792      0.752000  0.675435  0.786611  0.631250  02:09  \n",
       "5      0.659796      0.765714  0.694594  0.787772  0.631250  02:07  \n",
       "6      0.640851      0.769143  0.674094  0.784840  0.620313  02:07  \n",
       "7      0.633249      0.747429  0.667265  0.778108  0.625000  02:09  \n",
       "8      0.672417      0.794286  0.692426  0.797018  0.639062  02:09  \n",
       "9      0.676510      0.786286  0.699300  0.794916  0.639062  02:08  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../models\"\n",
    "model_name = \"bertweet_large_mlb.pt\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "torch.save(model.state_dict(), os.path.join(folder_path, model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
