{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 23:47:24.380833: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-17 23:47:25.835582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from typing import List, Dict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import prompt_utils\n",
    "import llm_utils\n",
    "from reproduce_model import normalizeTweet, reformat_json_binary_v01\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def model_summary(model):\n",
    "    print(\"Model summary:\")\n",
    "    print(\"---------------------------\")\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        param_count = param.numel()\n",
    "        total_params += param_count\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    \n",
    "\"\"\"def print_report(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=categories)\n",
    "    print(report)\n",
    "    sns.heatmap(cm, annot=True, xticklabels=categories, yticklabels=categories, fmt='g')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, x, y, mlb, tokenizer, fsl_strategy = None, binary = False):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mlb = mlb\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 128\n",
    "        self.encoded_tweets = self.preprocess_text(self.x, fsl_strategy)\n",
    "        self.binary = binary\n",
    "\n",
    "    def preprocess_text(self, X, fsl_strategy):\n",
    "        X = [normalizeTweet(tweet) for tweet in X]\n",
    "        \n",
    "        return self.tokenizer(X, return_attention_mask=True, return_tensors='pt', padding=True, truncation = True, max_length=self.max_length)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.binary:\n",
    "            label = self.y[idx].item()  # Convert tensor to a single integer value\n",
    "            return {\n",
    "                'input_ids': self.encoded_tweets['input_ids'][idx],\n",
    "                'attention_mask': self.encoded_tweets['attention_mask'][idx],\n",
    "                'label': torch.tensor(label)\n",
    "            }\n",
    "        else:\n",
    "            label = self.y[idx]\n",
    "            #print(label)\n",
    "            return {'input_ids': self.encoded_tweets['input_ids'][idx],\n",
    "                    'attention_mask': self.encoded_tweets['attention_mask'][idx],\n",
    "                    'label': torch.tensor(label, dtype=torch.float32)}\n",
    "                    #'label_ids': self.labels[idx]}\n",
    "        \n",
    "class MultiLabelDataCollator(DataCollatorWithPadding):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__(tokenizer)\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, torch.Tensor]]):\n",
    "        batch = super().__call__(features)\n",
    "        batch[\"labels\"] = torch.stack([feature[\"label\"] for feature in features])\n",
    "        return batch\n",
    "    \n",
    "def get_binary_classification_report(data_loader, model, class_name):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for batch in data_loader:\n",
    "        batch_inputs = {'input_ids': batch['input_ids'].to(device),\n",
    "                        'attention_mask': batch['attention_mask'].to(device)}\n",
    "        with torch.no_grad():\n",
    "            logits = model(**batch_inputs).logits\n",
    "        # Convert logits to 0 or 1 based on argmax\n",
    "        batch_predictions = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "        predictions.append(batch_predictions)\n",
    "        labels.append(batch['labels'].detach().cpu().numpy().astype(int))\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    labels = np.concatenate(labels, axis = 0)\n",
    "\n",
    "    dict_report = classification_report(labels, predictions, target_names=[class_name, \"not_\" + class_name], zero_division=0, output_dict=True)\n",
    "    report = classification_report(labels, predictions, target_names=[class_name, \"not_\" + class_name], zero_division=0)\n",
    "    return dict_report, report\n",
    "    \n",
    "def get_report_df(reports):\n",
    "    rows_tmp = []\n",
    "    for report in reports:\n",
    "        for label, metrics in report.items():\n",
    "            if \"not_\" in label or \"avg\" in label:\n",
    "                continue\n",
    "            if label == \"accuracy\":\n",
    "                continue  # Skip accuracy as it's a single value, not a dictionary\n",
    "            row = {\n",
    "                'label': label,\n",
    "                'f1_score_macro': report['macro avg']['f1-score'],\n",
    "                'precision_macro': report['macro avg']['precision'],\n",
    "                'recall_macro': report['macro avg']['recall'],\n",
    "                'support_macro': report['macro avg']['support'],\n",
    "                'f1_score_class_0': metrics['f1-score'],\n",
    "                'support_class_0': metrics['support'],\n",
    "                'precision_class_0': metrics['precision'],\n",
    "                'recall_class_0': metrics['recall'],\n",
    "            }\n",
    "            # Check if the \"not_\" label exists in the report\n",
    "            not_label = \"not_\" + label\n",
    "            if not_label in report:\n",
    "                row.update({\n",
    "                    'f1_score_class_1': report[not_label]['f1-score'],\n",
    "                    'support_class_1': report[not_label]['support'],\n",
    "                    'precision_class_1': report[not_label]['precision'],\n",
    "                    'recall_class_1': report[not_label]['recall']\n",
    "                })\n",
    "            rows_tmp.append(row)\n",
    "    return pd.DataFrame(rows_tmp)\n",
    "    \n",
    "\n",
    "def calculate_binary_metrics(task, class_names):\n",
    "    k = 5\n",
    "    print(task)\n",
    "    val_classification_reports = []\n",
    "    test_classification_reports = []\n",
    "\n",
    "    # Loop over each fold and load the corresponding model\n",
    "    for binary_task, class_name in zip(task, class_names):\n",
    "        model_path = f\"../models/{binary_task}_epochs_200_train_size_full_fold_0\"\n",
    "        # find the latest checkpoint file\n",
    "        #checkpoint_files = [f for f in os.listdir(model_path) if f.startswith(\"checkpoint\")]\n",
    "        latest_checkpoint = os.path.join(model_path, \"\")  # use \"\" for models that were manually saved after training. use sorted(checkpoint_files)[0] for the first automatically saved checkpoint \n",
    "        print(latest_checkpoint)\n",
    "        \n",
    "        # Load the model and tokenizer\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint)\n",
    "        model.to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n",
    "\n",
    "        filename = f\"../data/labeled_data/generic_test_0.json\"\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "        val_df = pd.DataFrame(data[\"valid\"])\n",
    "        test_df = pd.DataFrame(data[\"test\"])\n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(model_path, \"pytorch_model.bin\"))\n",
    "        model.load_state_dict(checkpoint)\n",
    "        \n",
    "        train_df, val_df = reformat_json_binary_v01(class_name, filename)\n",
    "        val_df['output'] = val_df['output'].astype(int)\n",
    "        test_df['output'] = test_df['annotations'].apply(lambda x: 1 if class_name in x else 0)\n",
    "\n",
    "    \n",
    "        val_dataset = TweetDataset(val_df['input'].to_list(), torch.tensor(val_df['output']), None, tokenizer, binary = True)\n",
    "        test_dataset = TweetDataset(test_df['text'].to_list(), torch.tensor(test_df['output']), None, tokenizer, binary = True)\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=256, shuffle=False, collate_fn=MultiLabelDataCollator(tokenizer)\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=256, shuffle=False, collate_fn=MultiLabelDataCollator(tokenizer)\n",
    "        )\n",
    "        \n",
    "        model.eval()\n",
    "        val_report_dict, val_report = get_binary_classification_report(val_loader, model, class_name)\n",
    "        test_report_dict, test_report = get_binary_classification_report(test_loader, model, class_name)\n",
    "        val_classification_reports.append(val_report_dict)\n",
    "        test_classification_reports.append(test_report_dict)\n",
    "\n",
    "    \n",
    "    print(val_classification_reports[0])\n",
    "    val_report_df = get_report_df(val_classification_reports)\n",
    "    test_report_df = get_report_df(test_classification_reports)\n",
    "    print(\"\\nAverage Validation Classification Report In DataFrame Format:\")\n",
    "    print(val_report_df) \n",
    "    print(\"\\nTest Classification Report In DataFrame Format:\")\n",
    "    print(test_report_df) \n",
    "    return val_report_df, test_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_war_terror_generic', 'binary_conspiracy_theory_generic', 'binary_education_generic', 'binary_election_campaign_generic', 'binary_environment_generic', 'binary_government_public_generic', 'binary_health_generic', 'binary_immigration_integration_generic', 'binary_justice_crime_generic', 'binary_labor_employment_generic', 'binary_macroeconomics_economic_regulation_generic', 'binary_media_journalism_generic', 'binary_religion_generic', 'binary_science_technology_generic', 'binary_others_generic']\n",
      "../models/binary_war_terror_generic_epochs_200_train_size_full_fold_0/\n",
      "---------------------\n",
      "Label: War/Terror\n",
      "Positive samples: 939\n",
      "Negative samples: 939\n",
      "Total samples: 1878\n",
      "Train samples: 1502\n",
      "Valid samples: 376\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/binary_conspiracy_theory_generic_epochs_200_train_size_full_fold_0/\n",
      "---------------------\n",
      "Label: Conspiracy Theory\n",
      "Positive samples: 254\n",
      "Negative samples: 254\n",
      "Total samples: 508\n",
      "Train samples: 406\n",
      "Valid samples: 102\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/binary_education_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Education\n",
      "Positive samples: 63\n",
      "Negative samples: 63\n",
      "Total samples: 126\n",
      "Train samples: 100\n",
      "Valid samples: 26\n",
      "---------------------\n",
      "../models/binary_election_campaign_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Election Campaign\n",
      "Positive samples: 133\n",
      "Negative samples: 133\n",
      "Total samples: 266\n",
      "Train samples: 212\n",
      "Valid samples: 54\n",
      "---------------------\n",
      "../models/binary_environment_generic_epochs_200_train_size_full_fold_0/\n",
      "---------------------\n",
      "Label: Environment\n",
      "Positive samples: 58\n",
      "Negative samples: 58\n",
      "Total samples: 116\n",
      "Train samples: 92\n",
      "Valid samples: 24\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/binary_government_public_generic_epochs_200_train_size_full_fold_0/\n",
      "---------------------\n",
      "Label: Government/Public\n",
      "Positive samples: 1248\n",
      "Negative samples: 1248\n",
      "Total samples: 2496\n",
      "Train samples: 1996\n",
      "Valid samples: 500\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/binary_health_generic_epochs_200_train_size_full_fold_0/\n",
      "---------------------\n",
      "Label: Health\n",
      "Positive samples: 214\n",
      "Negative samples: 214\n",
      "Total samples: 428\n",
      "Train samples: 342\n",
      "Valid samples: 86\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/binary_immigration_integration_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Immigration/Integration\n",
      "Positive samples: 201\n",
      "Negative samples: 201\n",
      "Total samples: 402\n",
      "Train samples: 321\n",
      "Valid samples: 81\n",
      "---------------------\n",
      "../models/binary_justice_crime_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Justice/Crime\n",
      "Positive samples: 572\n",
      "Negative samples: 572\n",
      "Total samples: 1144\n",
      "Train samples: 915\n",
      "Valid samples: 229\n",
      "---------------------\n",
      "../models/binary_labor_employment_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Labor/Employment\n",
      "Positive samples: 97\n",
      "Negative samples: 97\n",
      "Total samples: 194\n",
      "Train samples: 155\n",
      "Valid samples: 39\n",
      "---------------------\n",
      "../models/binary_macroeconomics_economic_regulation_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Macroeconomics/Economic Regulation\n",
      "Positive samples: 250\n",
      "Negative samples: 250\n",
      "Total samples: 500\n",
      "Train samples: 400\n",
      "Valid samples: 100\n",
      "---------------------\n",
      "../models/binary_media_journalism_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Media/Journalism\n",
      "Positive samples: 184\n",
      "Negative samples: 184\n",
      "Total samples: 368\n",
      "Train samples: 294\n",
      "Valid samples: 74\n",
      "---------------------\n",
      "../models/binary_religion_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Religion\n",
      "Positive samples: 71\n",
      "Negative samples: 71\n",
      "Total samples: 142\n",
      "Train samples: 113\n",
      "Valid samples: 29\n",
      "---------------------\n",
      "../models/binary_science_technology_generic_epochs_200_train_size_full_fold_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Label: Science/Technology\n",
      "Positive samples: 54\n",
      "Negative samples: 54\n",
      "Total samples: 108\n",
      "Train samples: 86\n",
      "Valid samples: 22\n",
      "---------------------\n",
      "../models/binary_others_generic_epochs_200_train_size_full_fold_0/\n",
      "---------------------\n",
      "Label: Others\n",
      "Positive samples: 1057\n",
      "Negative samples: 1057\n",
      "Total samples: 2114\n",
      "Train samples: 1691\n",
      "Valid samples: 423\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'War/Terror': {'precision': 0.9834254143646409, 'recall': 0.9270833333333334, 'f1-score': 0.9544235924932977, 'support': 192}, 'not_War/Terror': {'precision': 0.9282051282051282, 'recall': 0.9836956521739131, 'f1-score': 0.9551451187335093, 'support': 184}, 'accuracy': 0.9547872340425532, 'macro avg': {'precision': 0.9558152712848846, 'recall': 0.9553894927536233, 'f1-score': 0.9547843556134035, 'support': 376}, 'weighted avg': {'precision': 0.9564027211376455, 'recall': 0.9547872340425532, 'f1-score': 0.9547766798023373, 'support': 376}}\n",
      "\n",
      "Average Validation Classification Report In DataFrame Format:\n",
      "                                 label  f1_score_macro  precision_macro  recall_macro  support_macro  f1_score_class_0  support_class_0  precision_class_0  recall_class_0  f1_score_class_1  support_class_1  precision_class_1  recall_class_1\n",
      "0                           War/Terror        0.954784         0.955815      0.955389            376          0.954424              192           0.983425        0.927083          0.955145              184           0.928205        0.983696\n",
      "1                    Conspiracy Theory        0.872242         0.872685      0.871968            102          0.865979               49           0.875000        0.857143          0.878505               53           0.870370        0.886792\n",
      "2                            Education        0.921212         0.921212      0.921212             26          0.909091               11           0.909091        0.909091          0.933333               15           0.933333        0.933333\n",
      "3                    Election Campaign        0.962500         0.967742      0.960000             54          0.958333               25           1.000000        0.920000          0.966667               29           0.935484        1.000000\n",
      "4                          Environment        0.828571         0.828571      0.828571             24          0.800000               10           0.800000        0.800000          0.857143               14           0.857143        0.857143\n",
      "5                    Government/Public        0.883326         0.884159      0.882752            500          0.892193              266           0.882353        0.902256          0.874459              234           0.885965        0.863248\n",
      "6                               Health        0.940036         0.938333      0.942017             86          0.929577               35           0.916667        0.942857          0.950495               51           0.960000        0.941176\n",
      "7              Immigration/Integration        0.962759         0.961538      0.966667             81          0.960000               36           0.923077        1.000000          0.965517               45           1.000000        0.933333\n",
      "8                        Justice/Crime        0.942101         0.946897      0.939169            229          0.934010              102           0.968421        0.901961          0.950192              127           0.925373        0.976378\n",
      "9                     Labor/Employment        0.948684         0.950000      0.952381             39          0.950000               21           1.000000        0.904762          0.947368               18           0.900000        1.000000\n",
      "10  Macroeconomics/Economic Regulation        0.899960         0.902244      0.904187            100          0.901961               54           0.958333        0.851852          0.897959               46           0.846154        0.956522\n",
      "11                    Media/Journalism        0.890613         0.893601      0.888971             74          0.878788               34           0.906250        0.852941          0.902439               40           0.880952        0.925000\n",
      "12                            Religion        0.964848         0.970588      0.961538             29          0.960000               13           1.000000        0.923077          0.969697               16           0.941176        1.000000\n",
      "13                  Science/Technology        0.863354         0.863636      0.866667             22          0.869565               12           0.909091        0.833333          0.857143               10           0.818182        0.900000\n",
      "14                              Others        0.912528         0.912523      0.912542            423          0.912114              210           0.909953        0.914286          0.912941              213           0.915094        0.910798\n",
      "\n",
      "Test Classification Report In DataFrame Format:\n",
      "                                 label  f1_score_macro  precision_macro  recall_macro  support_macro  f1_score_class_0  support_class_0  precision_class_0  recall_class_0  f1_score_class_1  support_class_1  precision_class_1  recall_class_1\n",
      "0                           War/Terror        0.930956         0.914402      0.952770           1000          0.962095              745           0.988669        0.936913          0.899818              255           0.840136        0.968627\n",
      "1                    Conspiracy Theory        0.659844         0.621445      0.872077           1000          0.931629              955           0.992891        0.877487          0.388060               45           0.250000        0.866667\n",
      "2                            Education        0.591992         0.565000      0.955927           1000          0.953895              987           1.000000        0.911854          0.230088               13           0.130000        1.000000\n",
      "3                    Election Campaign        0.763544         0.695117      0.944878           1000          0.973517              967           0.997828        0.950362          0.553571               33           0.392405        0.939394\n",
      "4                          Environment        0.602754         0.571429      0.957404           1000          0.955508              986           1.000000        0.914807          0.250000               14           0.142857        1.000000\n",
      "5                    Government/Public        0.802953         0.790996      0.827655           1000          0.870343              709           0.922591        0.823695          0.735562              291           0.659401        0.831615\n",
      "6                               Health        0.750797         0.690600      0.911585           1000          0.962121              954           0.994407        0.931866          0.539474               46           0.386792        0.891304\n",
      "7              Immigration/Integration        0.782461         0.715482      0.936030           1000          0.975636              964           0.996753        0.955394          0.589286               36           0.434211        0.916667\n",
      "8                        Justice/Crime        0.809085         0.766076      0.916283           1000          0.927070              863           0.993377        0.869061          0.691099              137           0.538776        0.963504\n",
      "9                     Labor/Employment        0.641043         0.601599      0.897046           1000          0.946515              972           0.996587        0.901235          0.335570               28           0.206612        0.892857\n",
      "10  Macroeconomics/Economic Regulation        0.736519         0.682589      0.921968           1000          0.941507              938           0.996429        0.892324          0.531532               62           0.368750        0.951613\n",
      "11                    Media/Journalism        0.616339         0.598727      0.859681           1000          0.900632              952           0.993663        0.823529          0.332046               48           0.203791        0.895833\n",
      "12                            Religion        0.695482         0.627907      0.983822           1000          0.983556              989           1.000000        0.967644          0.407407               11           0.255814        1.000000\n",
      "13                  Science/Technology        0.493284         0.518303      0.736281           1000          0.908791              989           0.995187        0.836198          0.077778               11           0.041420        0.636364\n",
      "14                              Others        0.857143         0.841642      0.881762           1000          0.914286              729           0.953800        0.877915          0.800000              271           0.729483        0.885609\n"
     ]
    }
   ],
   "source": [
    "binary_tasks = [\n",
    "    \"binary_war_terror_generic\",\n",
    "    \"binary_conspiracy_theory_generic\",\n",
    "    \"binary_education_generic\",\n",
    "    \"binary_election_campaign_generic\",\n",
    "    \"binary_environment_generic\",\n",
    "    \"binary_government_public_generic\",\n",
    "    \"binary_health_generic\",\n",
    "    \"binary_immigration_integration_generic\",\n",
    "    \"binary_justice_crime_generic\",\n",
    "    \"binary_labor_employment_generic\",\n",
    "    \"binary_macroeconomics_economic_regulation_generic\",\n",
    "    \"binary_media_journalism_generic\",\n",
    "    \"binary_religion_generic\",\n",
    "    \"binary_science_technology_generic\",\n",
    "    \"binary_others_generic\",\n",
    "]\n",
    "class_names = prompt_utils.ALL_LABELS\n",
    "\n",
    "val_avg_report, test_avg_report = calculate_binary_metrics(binary_tasks, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>support_macro</th>\n",
       "      <th>f1_score_class_0</th>\n",
       "      <th>support_class_0</th>\n",
       "      <th>precision_class_0</th>\n",
       "      <th>recall_class_0</th>\n",
       "      <th>f1_score_class_1</th>\n",
       "      <th>support_class_1</th>\n",
       "      <th>precision_class_1</th>\n",
       "      <th>recall_class_1</th>\n",
       "      <th>TP_class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>War/Terror</td>\n",
       "      <td>0.930956</td>\n",
       "      <td>0.914402</td>\n",
       "      <td>0.952770</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.962095</td>\n",
       "      <td>745</td>\n",
       "      <td>0.988669</td>\n",
       "      <td>0.936913</td>\n",
       "      <td>0.899818</td>\n",
       "      <td>255</td>\n",
       "      <td>0.840136</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>291.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conspiracy Theory</td>\n",
       "      <td>0.659844</td>\n",
       "      <td>0.621445</td>\n",
       "      <td>0.872077</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.931629</td>\n",
       "      <td>955</td>\n",
       "      <td>0.992891</td>\n",
       "      <td>0.877487</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>45</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>-26.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.591992</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.955927</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.953895</td>\n",
       "      <td>987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911854</td>\n",
       "      <td>0.230088</td>\n",
       "      <td>13</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.283784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Election Campaign</td>\n",
       "      <td>0.763544</td>\n",
       "      <td>0.695117</td>\n",
       "      <td>0.944878</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.973517</td>\n",
       "      <td>967</td>\n",
       "      <td>0.997828</td>\n",
       "      <td>0.950362</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>33</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>-78.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Environment</td>\n",
       "      <td>0.602754</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.957404</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.955508</td>\n",
       "      <td>986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914807</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Government/Public</td>\n",
       "      <td>0.802953</td>\n",
       "      <td>0.790996</td>\n",
       "      <td>0.827655</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.870343</td>\n",
       "      <td>709</td>\n",
       "      <td>0.922591</td>\n",
       "      <td>0.823695</td>\n",
       "      <td>0.735562</td>\n",
       "      <td>291</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.831615</td>\n",
       "      <td>327.544186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Health</td>\n",
       "      <td>0.750797</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>954</td>\n",
       "      <td>0.994407</td>\n",
       "      <td>0.931866</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>46</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>-134.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immigration/Integration</td>\n",
       "      <td>0.782461</td>\n",
       "      <td>0.715482</td>\n",
       "      <td>0.936030</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.975636</td>\n",
       "      <td>964</td>\n",
       "      <td>0.996753</td>\n",
       "      <td>0.955394</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>36</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>-297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Justice/Crime</td>\n",
       "      <td>0.809085</td>\n",
       "      <td>0.766076</td>\n",
       "      <td>0.916283</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.927070</td>\n",
       "      <td>863</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.869061</td>\n",
       "      <td>0.691099</td>\n",
       "      <td>137</td>\n",
       "      <td>0.538776</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>623.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Labor/Employment</td>\n",
       "      <td>0.641043</td>\n",
       "      <td>0.601599</td>\n",
       "      <td>0.897046</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.946515</td>\n",
       "      <td>972</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.335570</td>\n",
       "      <td>28</td>\n",
       "      <td>0.206612</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>-10.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Macroeconomics/Economic Regulation</td>\n",
       "      <td>0.736519</td>\n",
       "      <td>0.682589</td>\n",
       "      <td>0.921968</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.941507</td>\n",
       "      <td>938</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.892324</td>\n",
       "      <td>0.531532</td>\n",
       "      <td>62</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>-101.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Media/Journalism</td>\n",
       "      <td>0.616339</td>\n",
       "      <td>0.598727</td>\n",
       "      <td>0.859681</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.900632</td>\n",
       "      <td>952</td>\n",
       "      <td>0.993663</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.332046</td>\n",
       "      <td>48</td>\n",
       "      <td>0.203791</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>-17.947826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Religion</td>\n",
       "      <td>0.695482</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.983822</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967644</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>11</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>0.493284</td>\n",
       "      <td>0.518303</td>\n",
       "      <td>0.736281</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.908791</td>\n",
       "      <td>989</td>\n",
       "      <td>0.995187</td>\n",
       "      <td>0.836198</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>11</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>-0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Others</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.841642</td>\n",
       "      <td>0.881762</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>729</td>\n",
       "      <td>0.953800</td>\n",
       "      <td>0.877915</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>271</td>\n",
       "      <td>0.729483</td>\n",
       "      <td>0.885609</td>\n",
       "      <td>305.352113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 label  f1_score_macro  precision_macro  recall_macro  support_macro  f1_score_class_0  support_class_0  precision_class_0  recall_class_0  f1_score_class_1  support_class_1  precision_class_1  recall_class_1  TP_class_1\n",
       "0                           War/Terror        0.930956         0.914402      0.952770           1000          0.962095              745           0.988669        0.936913          0.899818              255           0.840136        0.968627  291.597222\n",
       "1                    Conspiracy Theory        0.659844         0.621445      0.872077           1000          0.931629              955           0.992891        0.877487          0.388060               45           0.250000        0.866667  -26.590909\n",
       "2                            Education        0.591992         0.565000      0.955927           1000          0.953895              987           1.000000        0.911854          0.230088               13           0.130000        1.000000   -2.283784\n",
       "3                    Election Campaign        0.763544         0.695117      0.944878           1000          0.973517              967           0.997828        0.950362          0.553571               33           0.392405        0.939394  -78.692308\n",
       "4                          Environment        0.602754         0.571429      0.957404           1000          0.955508              986           1.000000        0.914807          0.250000               14           0.142857        1.000000   -2.800000\n",
       "5                    Government/Public        0.802953         0.790996      0.827655           1000          0.870343              709           0.922591        0.823695          0.735562              291           0.659401        0.831615  327.544186\n",
       "6                               Health        0.750797         0.690600      0.911585           1000          0.962121              954           0.994407        0.931866          0.539474               46           0.386792        0.891304 -134.714286\n",
       "7              Immigration/Integration        0.782461         0.715482      0.936030           1000          0.975636              964           0.996753        0.955394          0.589286               36           0.434211        0.916667 -297.000000\n",
       "8                        Justice/Crime        0.809085         0.766076      0.916283           1000          0.927070              863           0.993377        0.869061          0.691099              137           0.538776        0.963504  623.586207\n",
       "9                     Labor/Employment        0.641043         0.601599      0.897046           1000          0.946515              972           0.996587        0.901235          0.335570               28           0.206612        0.892857  -10.769231\n",
       "10  Macroeconomics/Economic Regulation        0.736519         0.682589      0.921968           1000          0.941507              938           0.996429        0.892324          0.531532               62           0.368750        0.951613 -101.611111\n",
       "11                    Media/Journalism        0.616339         0.598727      0.859681           1000          0.900632              952           0.993663        0.823529          0.332046               48           0.203791        0.895833  -17.947826\n",
       "12                            Religion        0.695482         0.627907      0.983822           1000          0.983556              989           1.000000        0.967644          0.407407               11           0.255814        1.000000   -5.761905\n",
       "13                  Science/Technology        0.493284         0.518303      0.736281           1000          0.908791              989           0.995187        0.836198          0.077778               11           0.041420        0.636364   -0.523810\n",
       "14                              Others        0.857143         0.841642      0.881762           1000          0.914286              729           0.953800        0.877915          0.800000              271           0.729483        0.885609  305.352113"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_avg_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 label  f1_score_macro  precision_macro  recall_macro  support_macro  f1_score_class_0  support_class_0  ...  f1_score_class_1  support_class_1  precision_class_1  recall_class_1  TP_class_1  FP_class_1  FN_class_1\n",
      "0                           War/Terror        0.930956         0.914402      0.952770           1000          0.962095              745  ...          0.899818              255           0.840136        0.968627       247.0        47.0         8.0\n",
      "1                    Conspiracy Theory        0.659844         0.621445      0.872077           1000          0.931629              955  ...          0.388060               45           0.250000        0.866667        39.0       117.0         6.0\n",
      "2                            Education        0.591992         0.565000      0.955927           1000          0.953895              987  ...          0.230088               13           0.130000        1.000000        13.0        87.0         0.0\n",
      "3                    Election Campaign        0.763544         0.695117      0.944878           1000          0.973517              967  ...          0.553571               33           0.392405        0.939394        31.0        48.0         2.0\n",
      "4                          Environment        0.602754         0.571429      0.957404           1000          0.955508              986  ...          0.250000               14           0.142857        1.000000        14.0        84.0         0.0\n",
      "5                    Government/Public        0.802953         0.790996      0.827655           1000          0.870343              709  ...          0.735562              291           0.659401        0.831615       242.0       125.0        49.0\n",
      "6                               Health        0.750797         0.690600      0.911585           1000          0.962121              954  ...          0.539474               46           0.386792        0.891304        41.0        65.0         5.0\n",
      "7              Immigration/Integration        0.782461         0.715482      0.936030           1000          0.975636              964  ...          0.589286               36           0.434211        0.916667        33.0        43.0         3.0\n",
      "8                        Justice/Crime        0.809085         0.766076      0.916283           1000          0.927070              863  ...          0.691099              137           0.538776        0.963504       132.0       113.0         5.0\n",
      "9                     Labor/Employment        0.641043         0.601599      0.897046           1000          0.946515              972  ...          0.335570               28           0.206612        0.892857        25.0        96.0         3.0\n",
      "10  Macroeconomics/Economic Regulation        0.736519         0.682589      0.921968           1000          0.941507              938  ...          0.531532               62           0.368750        0.951613        59.0       101.0         3.0\n",
      "11                    Media/Journalism        0.616339         0.598727      0.859681           1000          0.900632              952  ...          0.332046               48           0.203791        0.895833        43.0       168.0         5.0\n",
      "12                            Religion        0.695482         0.627907      0.983822           1000          0.983556              989  ...          0.407407               11           0.255814        1.000000        11.0        32.0         0.0\n",
      "13                  Science/Technology        0.493284         0.518303      0.736281           1000          0.908791              989  ...          0.077778               11           0.041420        0.636364         7.0       162.0         4.0\n",
      "14                              Others        0.857143         0.841642      0.881762           1000          0.914286              729  ...          0.800000              271           0.729483        0.885609       240.0        89.0        31.0\n",
      "\n",
      "[15 rows x 16 columns]\n",
      "0.4608457321848081\n",
      "0.6106355382619973\n"
     ]
    }
   ],
   "source": [
    "df = test_avg_report.copy()# Calculate TP, FP, and FN for class 1 for each label\n",
    "df['TP_class_1'] = df['recall_class_1'] * df['support_class_1']\n",
    "df['FP_class_1'] = (df['TP_class_1'] / df['precision_class_1']) - df['TP_class_1']\n",
    "df['FN_class_1'] = df['support_class_1'] - df['TP_class_1']\n",
    "\n",
    "print(df)\n",
    "# Calculate micro-average precision and recall for class 1\n",
    "precision_micro = df['TP_class_1'].sum() / (df['TP_class_1'].sum() + df['FP_class_1'].sum())\n",
    "recall_micro = df['TP_class_1'].sum() / (df['TP_class_1'].sum() + df['FN_class_1'].sum())\n",
    "\n",
    "print(precision_micro)\n",
    "# Calculate micro-average F1 score for class 1\n",
    "f1_micro = 2 * precision_micro * recall_micro / (precision_micro + recall_micro)\n",
    "\n",
    "print(f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4907528119869895"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"f1_score_class_1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['f1_score_macro', 'precision_macro', 'recall_macro', 'support_macro', 'f1_score_class_0', 'support_class_0', 'precision_class_0', 'recall_class_0', 'f1_score_class_1', 'support_class_1', 'precision_class_1', 'recall_class_1'], dtype='object')\n",
      "Index(['f1_score_macro', 'precision_macro', 'recall_macro', 'support_macro', 'f1_score_class_0', 'support_class_0', 'precision_class_0', 'recall_class_0', 'f1_score_class_1', 'support_class_1', 'precision_class_1', 'recall_class_1'], dtype='object')\n",
      "Index(['f1_score_macro', 'precision_macro', 'recall_macro', 'support_macro', 'f1_score_class_0', 'support_class_0', 'precision_class_0', 'recall_class_0', 'f1_score_class_1', 'support_class_1', 'precision_class_1', 'recall_class_1'], dtype='object')\n",
      "Index(['f1_score_macro', 'precision_macro', 'recall_macro', 'support_macro', 'f1_score_class_0', 'support_class_0', 'precision_class_0', 'recall_class_0', 'f1_score_class_1', 'support_class_1', 'precision_class_1', 'recall_class_1'], dtype='object')\n",
      "Index(['f1_score_macro', 'precision_macro', 'recall_macro', 'support_macro', 'f1_score_class_0', 'support_class_0', 'precision_class_0', 'recall_class_0', 'f1_score_class_1', 'support_class_1', 'precision_class_1', 'recall_class_1'], dtype='object')\n",
      "Index(['f1_score_macro', 'precision_macro', 'recall_macro', 'support_macro', 'f1_score_class_0', 'support_class_0', 'precision_class_0', 'recall_class_0', 'f1_score_class_1', 'support_class_1', 'precision_class_1', 'recall_class_1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "avg_f1_class_0, avg_f1_class_1, avg_f1_class_1_low, avg_f1_score, avg_accuracy, fbeta_score_class_0, fbeta_score_class_1, avg_fbeta_score, avg_fbeta_score_low, avg_fbeta_score_class_1_low_0_25 = llm_utils.calculate_metrics_streamlit(test_avg_report.iloc[0:-1], 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17935431218965814"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prompt_utils\n",
    "def calculate_fbeta_score(beta, precision, recall):\n",
    "    return (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "\n",
    "avg_fbeta_score_class_1_low_0_25 = 0\n",
    "try:\n",
    "    for class_ in prompt_utils.LOW_F1_LABELS:\n",
    "        avg_precision_class_1_low = df[df.label == class_][\"precision_class_1\"]\n",
    "        avg_recall_class_1_low = df[df.label == class_][\"recall_class_1\"]\n",
    "        avg_precision_class_1_low = avg_precision_class_1_low.values[0]\n",
    "        avg_recall_class_1_low = avg_recall_class_1_low.values[0]\n",
    "        avg_fbeta_score_class_1_low_0_25 += calculate_fbeta_score(0.25, avg_precision_class_1_low, avg_recall_class_1_low)\n",
    "except Exception as e:\n",
    "    print(\"Error\", e)\n",
    "avg_fbeta_score_class_1_low_0_25 = avg_fbeta_score_class_1_low_0_25/len(prompt_utils.LOW_F1_LABELS)\n",
    "avg_fbeta_score_class_1_low_0_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7055038660630035"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17935431218965814"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_fbeta_score_class_1_low_0_25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
