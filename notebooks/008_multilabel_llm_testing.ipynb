{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Define a list of filenames to load\n",
    "filenames = [\"../data/labeled_data/generic_test_0.json\"]\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_valid = pd.DataFrame()\n",
    "\n",
    "# Load all JSON data and concatenate into one DataFrame\n",
    "for filename in filenames:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    df_train = pd.DataFrame(data[\"train\"])\n",
    "    df_test = pd.DataFrame(data[\"test\"])\n",
    "    df_valid = pd.DataFrame(data[\"valid\"])\n",
    "\n",
    "def normalizeToken(token):\n",
    "    lowercased_token = token.lower()\n",
    "    if token.startswith(\"@\"):\n",
    "        return \"@USER\"\n",
    "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "        return \"[url]\"\n",
    "    elif len(token) == 1:\n",
    "        return demojize(token)\n",
    "    else:\n",
    "        if token == \"â€™\":\n",
    "            return \"'\"\n",
    "        elif token == \"â€¦\":\n",
    "            return \"...\"\n",
    "        else:\n",
    "            return token\n",
    "    \n",
    "def normalizeTweet(tweet):\n",
    "    tokens = TweetTokenizer().tokenize(tweet.replace(\"â€™\", \"'\"))\n",
    "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
    "\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"n 't\", \"n't\")\n",
    "            .replace(\"ca n't\", \"can't\")\n",
    "            .replace(\"ai n't\", \"ain't\")\n",
    "    )\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"p . m .\", \"pm\")\n",
    "            .replace(\"p . m\", \"pm\")\n",
    "            .replace(\"a . m .\", \"am\")\n",
    "            .replace(\"a . m\", \"am\")\n",
    "    )\n",
    "    return \" \".join(normTweet.split())\n",
    "\n",
    "def api(prompt):\n",
    "    import requests\n",
    "\n",
    "# For local streaming, the websockets are hosted without ssl - http://\n",
    "HOST = 'http://127.0.0.1:5000'\n",
    "URI = f'{HOST}/api/v1/generate'\n",
    "\n",
    "# For reverse-proxied streaming, the remote will likely host with ssl - https://\n",
    "# URI = 'https://your-uri-here.trycloudflare.com/api/v1/generate'\n",
    "\n",
    "def get_response(request_params, prompt, context):\n",
    "    request_params['prompt'] = prompt\n",
    "    request_params['context'] = context\n",
    "\n",
    "    response = requests.post(URI, json=request_params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()['results'][0]['text']\n",
    "        #print(prompt + result)\n",
    "        return result\n",
    "    else:\n",
    "    \tprint(response)\n",
    "\n",
    "def get_base_request_params(max_new_tokens = 200, stopping_strings = []):\n",
    "    return {\n",
    "        'prompt': None,\n",
    "        'context': None,\n",
    "        'max_new_tokens': 200,\n",
    "        'do_sample': True,\n",
    "        'temperature': 0.7,\n",
    "        'top_p': 0.1,\n",
    "        'typical_p': 1,\n",
    "        'repetition_penalty': 1.2,\n",
    "        'encoder_repetition_penalty': 1.0,\n",
    "        'top_k': 40,\n",
    "        'min_length': 0,\n",
    "        'no_repeat_ngram_size': 0,\n",
    "        'num_beams': 1,\n",
    "        'penalty_alpha': 0,\n",
    "        'length_penalty': 1,\n",
    "        'early_stopping': False,\n",
    "        'seed': -1,\n",
    "        #'add_bos_token': True,\n",
    "        #'truncation_length': 2048,\n",
    "        #'ban_eos_token': False,\n",
    "        #'skip_special_tokens': True,\n",
    "        'stopping_strings': stopping_strings\n",
    "    }\n",
    "\n",
    "def get_vicuna_multi_label_v01(tweet_text):\n",
    "    instruction = \"Assign multilabel labels to the following tweet. Choose out of the following list of labels where \\\"Others\\\" is only assigned if no other label fits: [\\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\", \\\"Others\\\"]\"\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{tweet_text}\\n\\n### Response:\\n\"\n",
    "    return prompt, \"\"\n",
    "\n",
    "#TODO: retrain with \"Others\"\n",
    "def get_vicuna_multi_label_v02(tweet_text):\n",
    "    instruction = \"Out of the following list of topics, choose topics that best fit the text in your opinion. Here are the rules:\\n- Use clear indicators for labeling.\\n- If unclear, output \\\"Others\\\". No speculation.\\n- Don't mix content from different operations.\\n- Refer to Oxford definitions for topics.\\n\\nTopics: \\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\"\"\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{tweet_text}\\n\\n### Response:\\n\"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_vicuna_binary_v01(label, tweet_text):\n",
    "    instruction = f\"Classify the input based on if it's about {label}. Use 1 (True) or 0 (False) as output.\"\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{tweet_text}\\n\\n### Response:\\n\"\n",
    "    return prompt, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model: vicuna_binary_war_v01\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 100/1000 [01:22<13:39,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 99\n",
      "Sample Tweet:  RT @USER : When you fight all your battles on your kness ( prayer ) , you will always win . #MenGather2020\n",
      "Sample Annotation:  ### Assistant: Based on the provided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 200/1000 [02:46<12:31,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 199\n",
      "Sample Tweet:  RT @USER : #TweetRequest | What music videos would you like to watch on MTV Base ? Tweet us NOW with the hashtag & name of vid :front-facing_baby_chick: htt â€¦\n",
      "Sample Annotation:  ### Assistant: As an AI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 300/1000 [04:10<07:50,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 299\n",
      "Sample Tweet:  However , the #Syrian troops repelled the offensive and retained the occupied lines . #Militants suffered losses and retreated .\n",
      "Sample Annotation:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 400/1000 [05:32<07:35,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 399\n",
      "Sample Tweet:  Militants of terrorist groups constantly arrange provocations by shelling the positions of Syrian government forces in western Aleppo . [url]\n",
      "Sample Annotation:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 500/1000 [06:52<06:40,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 499\n",
      "Sample Tweet:  RT @USER : A working person in Iraq is a working person is Texas is a working person in Berlin ; war is the desire to kill this tr â€¦\n",
      "Sample Annotation:  ### Assistant: Based on the given\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 600/1000 [08:13<05:33,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 599\n",
      "Sample Tweet:  The #US is completing the training of one more terrorist group at #AlTanf military base . #Syria heading for the next series of terrorist attacks very soon [url]\n",
      "Sample Annotation:  ### Assistant: Based on the information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 700/1000 [09:32<04:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 699\n",
      "Sample Tweet:  RT @USER : #SleepunderthenetUg Door to door distribution of mosquito nets in Buwambwa sub county , Namisindwa District . kick malaria â€¦\n",
      "Sample Annotation:  ### Assistant: Based on the information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 800/1000 [10:53<02:46,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 799\n",
      "Sample Tweet:  RT @USER =: ðŸ‡ºðŸ‡¸ #US military is being deployed to the #Greek Section ! Op-ed by @USER [url] #Turkey #Russia # U â€¦\n",
      "Sample Annotation:  ### Assistant: Based on the provided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 900/1000 [12:12<01:27,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 899\n",
      "Sample Tweet:  @USER Smashing it up Tomorrow Again @USER @USER #PremiereWednesday THE DAWN Kasanga [url]\n",
      "Sample Annotation:  ### Assistant: Based on the given\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [13:36<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 999\n",
      "Sample Tweet:  VIDEO : #Women'sMarch Linda Sarsour Told Maddow â€œ Islamic Children Are Executed In The U . S . â€ [url] [url]\n",
      "Sample Annotation:  ### Assistant: Based on the given\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_to_test_names = [\"vicuna_binary_war_v01\"]\n",
    "model_funcs = [get_vicuna_binary_v01]\n",
    "label = \"War/Terror\"\n",
    "dataframes = [df_test]\n",
    "dataframes_names = [\"test\"]\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "\n",
    "    for model_name, model_func in zip(models_to_test_names, model_funcs):\n",
    "        print(\"Starting with model: \" + model_name)\n",
    "        print(\"----------------------------------\")\n",
    "        df_tmp = df.copy()\n",
    "        df_tmp[\"prompt\"] = \"\"\n",
    "        df_tmp[\"context\"] = \"\"\n",
    "        new_column_name = dataframes_names[i] + model_name\n",
    "        output_folder = f\"../data/vicuna_4bit/lora/{model_name}/\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for idx, row in tqdm(df_tmp.iterrows(), total=df_tmp.shape[0]):\n",
    "\n",
    "            tweet_text = normalizeTweet(row[\"text\"])\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], 'normalized_tweet'] = tweet_text\n",
    "\n",
    "            prompt, context = model_func(label, tweet_text)\n",
    "            df_tmp.at[idx, \"prompt\"] = prompt\n",
    "            df_tmp.at[idx, \"context\"] = context\n",
    "\n",
    "            request_params = get_base_request_params()\n",
    "            request_params[\"stopping_strings\"] = [\"\\n\", \"### Human:\", \"Human:\", \"###\"]\n",
    "            request_params[\"max_new_tokens\"] = 10\n",
    "            response = get_response(request_params, prompt, \"\")\n",
    "\n",
    "            # Save the response in the 'api_results' column\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], new_column_name] = response\n",
    "            if (idx + 1) % 100 == 0:\n",
    "                output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "                df_tmp.to_csv(output_path, index=False)\n",
    "                print(f\"Saved progress at index {idx}\")\n",
    "                print(\"Sample Tweet: \", tweet_text)\n",
    "                print(\"Sample Annotation: \", response)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "        df_tmp.to_csv(output_path, index=False)        \n",
    "            # Save the request_params as a JSON file in the output folder\n",
    "        with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "            json.dump(request_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to count the number of rows in df_tmp where \"0\" is in the column test_vicuna_binary_war_v01\n",
    "df_tmp[df_tmp[\"testvicuna_binary_war_v01\"].str.contains(\"0\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nClassify the input based on if it's about War/Terror. Use 1 (True) or 0 (False) as output.\\n\\n### Input:\\n#Crimea : What to Expect from #Ukraine and the West [url] #russiainvadesukraine\\n\\n### Response:\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "df_tmp.to_csv(output_path, index=False)        \n",
    "    # Save the request_params as a JSON file in the output folder\n",
    "with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "    json.dump(request_params, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
