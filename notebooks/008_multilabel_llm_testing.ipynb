{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../src\")\n",
    "import prompt_utils\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Define a list of filenames to load\n",
    "filenames = [\"../data/labeled_data/generic_test_0.json\"]\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_valid = pd.DataFrame()\n",
    "\n",
    "# Load all JSON data and concatenate into one DataFrame\n",
    "for filename in filenames:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    df_train = pd.DataFrame(data[\"train\"])\n",
    "    df_test = pd.DataFrame(data[\"test\"])\n",
    "    df_valid = pd.DataFrame(data[\"valid\"])\n",
    "\n",
    "def normalizeToken(token):\n",
    "    lowercased_token = token.lower()\n",
    "    if token.startswith(\"@\"):\n",
    "        return \"@USER\"\n",
    "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "        return \"[url]\"\n",
    "    elif len(token) == 1:\n",
    "        return demojize(token)\n",
    "    else:\n",
    "        if token == \"‚Äô\":\n",
    "            return \"'\"\n",
    "        elif token == \"‚Ä¶\":\n",
    "            return \"...\"\n",
    "        else:\n",
    "            return token\n",
    "    \n",
    "def normalizeTweet(tweet):\n",
    "    tokens = TweetTokenizer().tokenize(tweet.replace(\"‚Äô\", \"'\"))\n",
    "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
    "\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"n 't\", \"n't\")\n",
    "            .replace(\"ca n't\", \"can't\")\n",
    "            .replace(\"ai n't\", \"ain't\")\n",
    "    )\n",
    "    normTweet = (\n",
    "        normTweet.replace(\"p . m .\", \"pm\")\n",
    "            .replace(\"p . m\", \"pm\")\n",
    "            .replace(\"a . m .\", \"am\")\n",
    "            .replace(\"a . m\", \"am\")\n",
    "    )\n",
    "    return \" \".join(normTweet.split())\n",
    "\n",
    "def api(prompt):\n",
    "    import requests\n",
    "\n",
    "# For local streaming, the websockets are hosted without ssl - http://\n",
    "HOST = 'http://127.0.0.1:5000'\n",
    "URI = f'{HOST}/api/v1/generate'\n",
    "\n",
    "# For reverse-proxied streaming, the remote will likely host with ssl - https://\n",
    "# URI = 'https://your-uri-here.trycloudflare.com/api/v1/generate'\n",
    "\n",
    "def get_response(request_params, prompt, context):\n",
    "    request_params['prompt'] = prompt\n",
    "    request_params['context'] = context\n",
    "\n",
    "    response = requests.post(URI, json=request_params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()['results'][0]['text']\n",
    "        #print(prompt + result)\n",
    "        return result\n",
    "    else:\n",
    "    \tprint(response)\n",
    "\n",
    "def get_base_request_params(max_new_tokens = 200, stopping_strings = []):\n",
    "    return {\n",
    "        'prompt': None,\n",
    "        'context': None,\n",
    "        'max_new_tokens': 200,\n",
    "        'do_sample': True,\n",
    "        'temperature': 0.7,\n",
    "        'top_p': 0.1,\n",
    "        'typical_p': 1,\n",
    "        'repetition_penalty': 1.2,\n",
    "        'encoder_repetition_penalty': 1.0,\n",
    "        'top_k': 40,\n",
    "        'min_length': 0,\n",
    "        'no_repeat_ngram_size': 0,\n",
    "        'num_beams': 1,\n",
    "        'penalty_alpha': 0,\n",
    "        'length_penalty': 1,\n",
    "        'early_stopping': False,\n",
    "        'seed': -1,\n",
    "        #'add_bos_token': True,\n",
    "        #'truncation_length': 2048,\n",
    "        #'ban_eos_token': False,\n",
    "        #'skip_special_tokens': True,\n",
    "        'stopping_strings': stopping_strings\n",
    "    }\n",
    "\n",
    "def get_vicuna_multi_label_no_fine_tune_v01_old(tweet_text):\n",
    "    instruction = \"### Human:\\nOut of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\\\"topic 1\\\", \\\"topic 2\\\", ...].\\n\\nTopics:\\n[\\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\"]\"\n",
    "    prompt = f\"{instruction}\\n\\nTweet: {tweet_text}\\n\\n### Assistant:\\nTopics in format [\\\"topic 1\\\", \\\"topic 2\\\", ...]: \\n[\\\"\"\n",
    "    return prompt, \"\"\n",
    "\n",
    "def get_vicuna_multi_label_no_fine_tune_v01(tweet_text):\n",
    "    instruction = \"### Human:\\nOut of the following list of topics, choose topics that best fit the tweet in your opinion.\\n\\nTopics:\\n\\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\"\"\n",
    "    prompt = f\"{instruction}\\n\\nTweet: {tweet_text}\\n\\n### Assistant:\\n[\\\"\"\n",
    "    \n",
    "    request_params = get_base_request_params()\n",
    "    request_params[\"stopping_strings\"] = [\"\\n\", \"Instruction:\", \"###\"]\n",
    "    request_params[\"max_new_tokens\"] = 200\n",
    "    return prompt, \"\", request_params\n",
    "\n",
    "def get_vicuna_multi_label_no_fine_tune_v02(tweet_text):\n",
    "    instruction = \"### Human:\\nOut of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\\\"a\\\", \\\"b\\\", ...].\\n\\nTopics:\\n\\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\"\"\n",
    "    prompt = f\"{instruction}\\n\\nTweet: {tweet_text}\\n\\n### Assistant: \"\n",
    "    \n",
    "    request_params = get_base_request_params()\n",
    "    request_params[\"stopping_strings\"] = [\"\\n\", \"Instruction:\", \"###\"]\n",
    "    request_params[\"max_new_tokens\"] = 200\n",
    "    return prompt, \"\", request_params\n",
    "\n",
    "def get_vicuna_multi_label_few_shot_prompt_only_classification_n_random_example(tweet_text, example_tweets):\n",
    "    example_tweets_str = \"\"\n",
    "    for example_tweet in example_tweets:\n",
    "        replaced_topic = str(example_tweet[1]).replace('\\'', '\"')\n",
    "        example_tweets_str += f\"\\nTweet: {prompt_utils.normalize_tweet_simplified(example_tweet[0])}\\nTopics: {replaced_topic}\\n\"\n",
    "\n",
    "    prompt = f\"### Human:\\nOut of the following list of topics, choose topics that best fit the tweet in your opinion.\\n\\n\\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\"\\n{example_tweets_str}\\nTweet: {tweet_text}\\n###Assistant:\"\n",
    "    request_params = get_base_request_params()\n",
    "    request_params[\"max_new_tokens\"] = 400\n",
    "    request_params[\"stopping_strings\"] = [\"\\n\", \"### Human:\", \"Human:\", \"###\"]\n",
    "    return prompt, \"\", request_params\n",
    "\n",
    "def get_vicuna_multi_label_no_fine_tune_explanation_first_v01(tweet_text):\n",
    "    instruction = \"### Human:\\nOut of the following list of topics, choose topics that best fit the text in your opinion. Start your response with \\\"Explanation:\\\" and end it with the list of chosen topics \\\"Topics:\\\".\\n\\nTopics:\\n\\\"War/Terror\\\", \\\"Conspiracy Theory\\\", \\\"Education\\\", \\\"Election Campaign\\\", \\\"Environment\\\", \\\"Government/Public\\\", \\\"Health\\\", \\\"Immigration/Integration\\\", \\\"Justice/Crime\\\", \\\"Labor/Employment\\\", \\\"Macroeconomics/Economic Regulation\\\", \\\"Media/Journalism\\\", \\\"Religion\\\", \\\"Science/Technology\\\"\"\n",
    "    prompt = f\"{instruction}\\n\\nTweet: {tweet_text}\\n\\n### Assistant:\\nExplanation: \\n\"\n",
    "    request_params = get_base_request_params()\n",
    "    request_params[\"max_new_tokens\"] = 400\n",
    "    request_params[\"stopping_strings\"] = [\"### Human:\", \"Human:\", \"###\"]\n",
    "    return prompt, \"\", request_params\n",
    "\n",
    "def get_vicuna_multi_label_v01_no_alpaca_format(tweet_text):\n",
    "    instruction = \"Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\\\"a\\\", \\\"b\\\", ...].\\n\\nTopics:\\n['War/Terror', 'Conspiracy Theory', 'Education', 'Election Campaign', 'Environment', 'Government/Public', 'Health', 'Immigration/Integration', 'Justice/Crime', 'Labor/Employment', 'Macroeconomics/Economic Regulation', 'Media/Journalism', 'Religion', 'Science/Technology']\"\n",
    "    prompt = f\"### Human:\\n{instruction}\\n\\nTweet: {tweet_text}\\n\\n### Assistant:\\n\"\n",
    "\n",
    "    request_params = get_base_request_params()\n",
    "    request_params[\"stopping_strings\"] = [\"Human:\", \"Assistant:\"]\n",
    "    return prompt, \"\", request_params\n",
    "\n",
    "def get_vicuna_multi_label_v01(tweet_text):\n",
    "    instruction = \"Assign multilabel labels to the following tweet. Choose out of the following list of labels where 'Others' is only assigned if no other label fits: ['War/Terror', 'Conspiracy Theory', Education', 'Election Campaign', 'Environment', 'Government/Public', 'Health', 'Immigration/Integration', 'Justice/Crime', 'Labor/Employment', 'Macroeconomics/Economic Regulation', 'Media/Journalism', 'Religion', 'Science/Technology', 'Others']\"\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{tweet_text}\\n\\n### Response:\\n\"\n",
    "    request_params = get_base_request_params()\n",
    "    request_params[\"stopping_strings\"] = [\"Instruction:\", \"###\"]\n",
    "    request_params[\"max_new_tokens\"] = 200\n",
    "    return prompt, \"\", request_params\n",
    "\n",
    "#TODO: retrain with \"Others\", rules arent formatted correctly\n",
    "def get_vicuna_multi_label_v02(tweet_text):\n",
    "    instruction = \"Out of the following list of topics, choose topics that best fit the text in your opinion. Here are the rules:\\n- Use clear indicators for labeling.\\n- If unclear, output 'Others'. \\n- No speculation.\\n- Don't mix content from different operations.\\n- Refer to Oxford definitions for topics.\\n\\nTopics: 'War/Terror', 'Conspiracy Theory', 'Education', 'Election Campaign', 'Environment', 'Government/Public', 'Health', 'Immigration/Integration', 'Justice/Crime', 'Labor/Employment', 'Macroeconomics/Economic Regulation', 'Media/Journalism', 'Religion', 'Science/Technology'\"\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{tweet_text}\\n\\n### Response:\\n\"\n",
    "    request_params = get_base_request_params()\n",
    "    request_params[\"stopping_strings\"] = [\"Instruction:\", \"###\"]\n",
    "    request_params[\"max_new_tokens\"] = 200\n",
    "    return prompt, \"\", request_params\n",
    "\n",
    "def get_vicuna_binary_v01(label, tweet_text):\n",
    "    instruction = f\"Classify the input based on if it's about {label}. Use 1 or 0 as output.\"\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{tweet_text}\\n\\n### Response:\\n\"\n",
    "    \n",
    "    request_params = get_base_request_params()\n",
    "    request_params[\"stopping_strings\"] = [\"Instruction:\", \"###\"]\n",
    "    request_params[\"max_new_tokens\"] = 30\n",
    "    return prompt, \"\", request_params\n",
    "\n",
    "def get_random_examples(df, label, exclude_tweet, n, random_state = 42):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (pd.dataframe): df to retrieve random examples\n",
    "        label (str): label to check random examples with, if set to \"multilabel\", it will return the true label in string format of the random tweets\n",
    "        exclude_tweet (str): text of tweet to be excluded from returned list\n",
    "        n (int): amount of random tweets retrieved\n",
    "\n",
    "    Returns:\n",
    "        list(tuple): returns a list of tuples of format (tweet_text, 1/0 depending on whether it pertains to the label) \n",
    "    \"\"\"\n",
    "    # Exclude the specific tweet\n",
    "    df = df[df['text'] != exclude_tweet]\n",
    "    \n",
    "    # Sample n random examples\n",
    "    sampled_df = df.sample(n=n, random_state=random_state)\n",
    "\n",
    "    values = sampled_df['text'].values\n",
    "    if label == \"multilabel\":\n",
    "        labels = sampled_df['annotations'].values\n",
    "    else:\n",
    "        labels = sampled_df['annotations'].apply(lambda x: int(label in x)).values\n",
    "    \n",
    "    # Return a list of tuples, each containing the tweet text and its annotations\n",
    "    return list(zip(values, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('### Human:\\nOut of the following list of topics, choose topics that best fit the tweet in your opinion.\\n\\n\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"\\n\\nTweet: A 53 - year-old Zambian national Willie Oliver Ndembela who served as Special Assistant to the African Union Commissioner of Trade and Industry of His Excellency Albert Muchanga has passed away in Addis Ababa , Ethiopia . [url]\\nTopics: [\"Others\"]\\n\\nTweet: ‚Äú Black Lives Matter ‚Äù Issues Revolting Anti-Christian Message on Christmas [url] [url]\\nTopics: [\"Government/Public\", \"Religion\"]\\n\\nTweet: RT @USER : Remind them of the #ArmyCommander who never finished the #LRA rebellion but instead fled the war front . [url]\\nTopics: [\"Government/Public\", \"War/Terror\"]\\n\\nTweet: awdawd\\n###Assistant:',\n",
       " '',\n",
       " {'prompt': None,\n",
       "  'context': None,\n",
       "  'max_new_tokens': 400,\n",
       "  'do_sample': True,\n",
       "  'temperature': 0.7,\n",
       "  'top_p': 0.1,\n",
       "  'typical_p': 1,\n",
       "  'repetition_penalty': 1.2,\n",
       "  'encoder_repetition_penalty': 1.0,\n",
       "  'top_k': 40,\n",
       "  'min_length': 0,\n",
       "  'no_repeat_ngram_size': 0,\n",
       "  'num_beams': 1,\n",
       "  'penalty_alpha': 0,\n",
       "  'length_penalty': 1,\n",
       "  'early_stopping': False,\n",
       "  'seed': -1,\n",
       "  'stopping_strings': ['\\n', '### Human:', 'Human:', '###']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vicuna_multi_label_few_shot_prompt_only_classification_n_random_example(\"awdawd\", get_random_examples(df_train, \"multilabel\", \"awdawdawd\", 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Others']\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(get_random_examples(df_train, \"multilabel\", \"awdawdawd\", 3)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model: binary_others_v01\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 100/1000 [00:49<06:45,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 99\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "RT @USER : When you fight all your battles on your kness ( prayer ) , you will always win . #MenGather2020\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 200/1000 [01:28<04:39,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 199\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "RT @USER : #TweetRequest | What music videos would you like to watch on MTV Base ? Tweet us NOW with the hashtag & name of vid :front-facing_baby_chick: htt ‚Ä¶\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 300/1000 [02:13<05:05,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 299\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "However , the #Syrian troops repelled the offensive and retained the occupied lines . #Militants suffered losses and retreated .\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 400/1000 [02:51<02:46,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 399\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "Militants of terrorist groups constantly arrange provocations by shelling the positions of Syrian government forces in western Aleppo . [url]\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 500/1000 [03:35<03:41,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 499\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "RT @USER : A working person in Iraq is a working person is Texas is a working person in Berlin ; war is the desire to kill this tr ‚Ä¶\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 600/1000 [04:15<01:50,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 599\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "The #US is completing the training of one more terrorist group at #AlTanf military base . #Syria heading for the next series of terrorist attacks very soon [url]\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 700/1000 [04:57<02:10,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 699\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "RT @USER : #SleepunderthenetUg Door to door distribution of mosquito nets in Buwambwa sub county , Namisindwa District . kick malaria ‚Ä¶\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 800/1000 [05:37<00:55,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 799\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "RT @USER =: üá∫üá∏ #US military is being deployed to the #Greek Section ! Op-ed by @USER [url] #Turkey #Russia # U ‚Ä¶\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 900/1000 [06:19<00:44,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 899\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "@USER Smashing it up Tomorrow Again @USER @USER #PremiereWednesday THE DAWN Kasanga [url]\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [07:00<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 999\n",
      "Sample Prompt:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the input based on if it's about Others. Use 1 or 0 as output.\n",
      "\n",
      "### Input:\n",
      "VIDEO : #Women'sMarch Linda Sarsour Told Maddow ‚Äú Islamic Children Are Executed In The U . S . ‚Äù [url] [url]\n",
      "\n",
      "### Response:\n",
      "\n",
      "Sample Annotation:  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_to_test_names = [\"binary_others_v01\"]\n",
    "model_funcs = [get_vicuna_binary_v01]\n",
    "label = \"Others\"\n",
    "dataframes = [df_test]\n",
    "lora = True\n",
    "dataframes_names = [\"test\"]\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "\n",
    "    for model_name, model_func in zip(models_to_test_names, model_funcs):\n",
    "        print(\"Starting with model: \" + model_name)\n",
    "        print(\"----------------------------------\")\n",
    "        df_tmp = df.copy()\n",
    "        df_tmp[\"prompt\"] = \"\"\n",
    "        df_tmp[\"context\"] = \"\"\n",
    "        new_column_name = \"response\"\n",
    "        if lora:\n",
    "            model_name = \"lora/\" + model_name\n",
    "        output_folder = f\"../data/vicuna_4bit/{model_name}/\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for idx, row in tqdm(df_tmp.iterrows(), total=df_tmp.shape[0]):\n",
    "\n",
    "            tweet_text = normalizeTweet(row[\"text\"])\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], 'normalized_tweet'] = tweet_text\n",
    "\n",
    "            if label != \"\":\n",
    "                prompt, context, request_params = model_func(label, tweet_text)\n",
    "            else:\n",
    "                prompt, context, request_params = model_func(tweet_text)\n",
    "            df_tmp.at[idx, \"prompt\"] = prompt\n",
    "            df_tmp.at[idx, \"context\"] = context\n",
    "\n",
    "            response = get_response(request_params, prompt, \"\")\n",
    "\n",
    "            # Save the response in the 'api_results' column\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], new_column_name] = response\n",
    "            if (idx + 1) % 100 == 0:\n",
    "                output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "                df_tmp.to_csv(output_path, index=False)\n",
    "                print(f\"Saved progress at index {idx}\")\n",
    "                print(\"Sample Prompt: \", prompt)\n",
    "                print(\"Sample Annotation: \", response)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "        df_tmp.to_csv(output_path, index=False)        \n",
    "            # Save the request_params as a JSON file in the output folder\n",
    "        with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "            json.dump(request_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model: multilabel_no_fine_tune_v01_3\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 100/1000 [02:08<19:56,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 99\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: RT @USER : When you fight all your battles on your kness ( prayer ) , you will always win . #MenGather2020\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  üôèüèΩ‚ù§Ô∏è‚Äçüí™ Out of respect for our diverse audience and to adhere to ethical guidelines, please refrain from promoting religious content or political agendas. Let's focus on uniting people through positive messages & everyday life experiences! #SocialMediaPeace pic.twitter.com/Yuq3V89QlP\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 200/1000 [04:14<16:47,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 199\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: RT @USER : #TweetRequest | What music videos would you like to watch on MTV Base ? Tweet us NOW with the hashtag & name of vid :front-facing_baby_chick: htt ‚Ä¶\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  üé∂ Music Videos üì∫üëÄ Which ones do YOU want to see?! ü§î Use #MTVBaseVideoFest & tag @user to request your favs! Let's make this a party! üéâüí• #MTVBase #MusicVideos #PartyTime\n",
      "\n",
      "‚ùå NOTE: This response is not an accurate reflection of the original prompt and should be disregarded. Please ignore if you came across it by accident. If you are experiencing issues or have any questions, please reach out to me for assistance. Thank you.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 300/1000 [06:23<08:28,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 299\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: However , the #Syrian troops repelled the offensive and retained the occupied lines . #Militants suffered losses and retreated .\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  ‚Äã\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 400/1000 [08:22<06:45,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 399\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: Militants of terrorist groups constantly arrange provocations by shelling the positions of Syrian government forces in western Aleppo . [url]\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  ‚Äã\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 500/1000 [10:43<15:27,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 499\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: RT @USER : A working person in Iraq is a working person is Texas is a working person in Berlin ; war is the desire to kill this tr ‚Ä¶\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  ‚Ä£ War/Terror\n",
      "‚Ä£ Justice/Crime\n",
      "‚Ä£ Government/Public\n",
      "‚Ä£ Labor/Employment\n",
      "‚Ä£ Macroeconomics/Economic Regulation\n",
      "‚Ä£ Media/Journalism\n",
      "‚Ä£ Immigration/Integration\n",
      "‚Ä£ Science/Technology\n",
      "‚Ä£ Environment\n",
      "‚Ä£ Health\n",
      "‚Ä£ Education\n",
      "‚Ä£ Election Campaign\n",
      "‚Ä£ Religion\n",
      "‚Ä£ Conspiracy Theory\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 600/1000 [12:44<07:17,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 599\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: The #US is completing the training of one more terrorist group at #AlTanf military base . #Syria heading for the next series of terrorist attacks very soon [url]\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  ‚Äã\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 700/1000 [14:44<01:59,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 699\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: RT @USER : #SleepunderthenetUg Door to door distribution of mosquito nets in Buwambwa sub county , Namisindwa District . kick malaria ‚Ä¶\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  ‚Äã\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 800/1000 [16:54<02:53,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 799\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: RT @USER =: üá∫üá∏ #US military is being deployed to the #Greek Section ! Op-ed by @USER [url] #Turkey #Russia # U ‚Ä¶\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  ‚Äã\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 900/1000 [18:28<01:44,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 899\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: @USER Smashing it up Tomorrow Again @USER @USER #PremiereWednesday THE DAWN Kasanga [url]\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  ‚Äã\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [20:10<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at index 999\n",
      "Sample Prompt:  ### Human:\n",
      "Out of the following list of topics, choose topics that best fit the tweet in your opinion. Output in format [\"a\", \"b\", ...].\n",
      "\n",
      "Topics:\n",
      "[\"War/Terror\", \"Conspiracy Theory\", \"Education\", \"Election Campaign\", \"Environment\", \"Government/Public\", \"Health\", \"Immigration/Integration\", \"Justice/Crime\", \"Labor/Employment\", \"Macroeconomics/Economic Regulation\", \"Media/Journalism\", \"Religion\", \"Science/Technology\"]\n",
      "\n",
      "Tweet: VIDEO : #Women'sMarch Linda Sarsour Told Maddow ‚Äú Islamic Children Are Executed In The U . S . ‚Äù [url] [url]\n",
      "\n",
      "### Assistant: \n",
      "Sample Annotation:  ‚Äã\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_to_test_names = [\"multilabel_no_fine_tune_v01_3\"]\n",
    "model_funcs = [get_vicuna_multi_label_no_fine_tune_v01_3]\n",
    "label = \"\"\n",
    "dataframes = [df_test]\n",
    "lora = False\n",
    "dataframes_names = [\"test\"]\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "\n",
    "    for model_name, model_func in zip(models_to_test_names, model_funcs):\n",
    "        print(\"Starting with model: \" + model_name)\n",
    "        print(\"----------------------------------\")\n",
    "        df_tmp = df.copy()\n",
    "        df_tmp[\"prompt\"] = \"\"\n",
    "        df_tmp[\"context\"] = \"\"\n",
    "        new_column_name = \"response\"\n",
    "        if lora:\n",
    "            model_name = \"lora/\" + model_name\n",
    "        output_folder = f\"../data/vicuna_4bit/{model_name}/\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for idx, row in tqdm(df_tmp.iterrows(), total=df_tmp.shape[0]):\n",
    "\n",
    "            tweet_text = normalizeTweet(row[\"text\"])\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], 'normalized_tweet'] = tweet_text\n",
    "\n",
    "            if label != \"\":\n",
    "                prompt, context, request_params = model_func(label, tweet_text)\n",
    "            else:\n",
    "                prompt, context, request_params = model_func(tweet_text)\n",
    "            df_tmp.at[idx, \"prompt\"] = prompt\n",
    "            df_tmp.at[idx, \"context\"] = context\n",
    "\n",
    "            response = get_response(request_params, prompt, \"\")\n",
    "\n",
    "            # Save the response in the 'api_results' column\n",
    "            df_tmp.loc[lambda df: df['id'] == row[\"id\"], new_column_name] = response\n",
    "            if (idx + 1) % 100 == 0:\n",
    "                output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "                df_tmp.to_csv(output_path, index=False)\n",
    "                print(f\"Saved progress at index {idx}\")\n",
    "                print(\"Sample Prompt: \", prompt)\n",
    "                print(\"Sample Annotation: \", response)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "        df_tmp.to_csv(output_path, index=False)        \n",
    "            # Save the request_params as a JSON file in the output folder\n",
    "        with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "            json.dump(request_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to count the number of rows in df_tmp where \"0\" is in the column test_vicuna_binary_war_v01\n",
    "df_tmp[df_tmp[\"testvicuna_binary_war_v01\"].str.contains(\"0\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_path = os.path.join(output_folder, f'{dataframes_names[i]}_generic_test_0.csv')\n",
    "df_tmp.to_csv(output_path, index=False)        \n",
    "    # Save the request_params as a JSON file in the output folder\n",
    "with open(os.path.join(output_folder, 'request_params.json'), 'w') as f:\n",
    "    json.dump(request_params, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
