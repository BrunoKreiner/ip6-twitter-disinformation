{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import prompt_utils\n",
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "# vicuna \n",
    "# with rules classification only (beta 0.5: 0.76, beta 0.25: 0.86) (0.7-0.8s per prompt)\n",
    "vicuna_base_path = \"../data/vicuna_4bit/\"\n",
    "vicuna_with_rules_classification_only_name = \"generic_prompt_with_rules_only_classification\"\n",
    "vicuna_with_rules_classification_only_func = prompt_utils.get_vicuna_prompt_with_rules_only_classification\n",
    "\n",
    "# OA LLAMA\n",
    "# Classification Only V03 (bta 0.5: 0.81, beta 0.25: 0.83)\n",
    "# With Rules Classification only (beta 0.5: 0.8, beta 0.25: 0.89)\n",
    "# With 3 Random Examples Classification only (beta 0.5: 0.78, beta 0.25: 0.88)\n",
    "oa_base_path = \"../data/openassistant_llama_30b_4bit/\"\n",
    "oa_classification_only_v03_name = \"generic_prompt_without_context_only_classification_v03\"\n",
    "oa_classification_only_v03_func = prompt_utils.get_openassistant_llama_30b_4bit_without_context_only_classification_v03 #\n",
    "oa_with_rules_classification_only_name = \"generic_prompt_with_rules_only_classification\"\n",
    "oa_with_rules_classification_only_func = prompt_utils.get_openassistant_llama_30b_4bit_with_rules_only_classification\n",
    "oa_with_3_random_examples_classification_only_name = \"generic_prompt_few_shot_prompt_only_classification_3_random_example\"\n",
    "oa_with_3_random_examples_classification_only_func = prompt_utils.get_openassistant_llama_30b_4bit_few_shot_prompt_only_classification_n_random_example\n",
    "\n",
    "# Text Davinci\n",
    "# Elaboration First V04 (beta 0.5: 0.87, beta 0.25: 0.93)\n",
    "davinci_base_path = \"../data/openai_text_davinci_003/\"\n",
    "davinci_elaboration_first_v04_name = \"generic_prompt_without_context_elaboration_first_v04\"\n",
    "davinci_elaboration_first_v04_func = prompt_utils.get_openai_prompt_without_context_elaboration_first_v04\n",
    "\n",
    "# Define a list of filenames to load\n",
    "labeled_data_filename = \"../data/labeled_data/generic_test_0.json\"\n",
    "\n",
    "dfs = []\n",
    "with open(labeled_data_filename) as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data[\"train\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"test\"])\n",
    "dfs.append(df)\n",
    "df = pd.DataFrame(data[\"valid\"])\n",
    "dfs.append(df)\n",
    "df_all = pd.concat(dfs)\n",
    "ALL_LABELS = prompt_utils.ALL_LABELS[:-1]\n",
    "LOW_F1_LABELS = prompt_utils.LOW_F1_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39387/3870156020.py:22: DtypeWarning: Columns (0,1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,22,23,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eng_tweets = pd.read_csv(f\"{output_folder}/{model_name}.csv\")\n"
     ]
    }
   ],
   "source": [
    "def initialize_eng_dataframe():\n",
    "    unlabeled_dataset = prompt_utils.generate_unlabeled_dataset()\n",
    "    return unlabeled_dataset.loc[unlabeled_dataset.tweet_language == \"en\"].sample(frac=1, random_state = 42).reset_index()\n",
    "\n",
    "def find_start_index(df: pd.DataFrame, new_column_names: List[str]) -> int:\n",
    "    # Find first row where all weak labels are NaN\n",
    "    try:\n",
    "        start_index = df[new_column_names].isna().all(axis=1).idxmax()\n",
    "        # If no NaN found in any of new_column_names, start from beginning\n",
    "        if pd.isna(start_index):\n",
    "            start_index = 0\n",
    "        return start_index\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "output_folder = f\"{oa_base_path}/{oa_with_3_random_examples_classification_only_name}\"\n",
    "model_name = \"low_f1_labels_weak_labeling\"\n",
    "prompt_func = oa_with_3_random_examples_classification_only_func\n",
    "idx_of_rules_of_low_f1_labels = [1, 2, 4, 9, 12, 13]\n",
    "\n",
    "if os.path.isfile(f\"{output_folder}/{model_name}.csv\"):\n",
    "    eng_tweets = pd.read_csv(f\"{output_folder}/{model_name}.csv\")\n",
    "else:\n",
    "    eng_tweets = initialize_eng_dataframe()\n",
    "    eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mask_conspiracy \u001b[39m=\u001b[39m eng_tweets[\u001b[39m'\u001b[39m\u001b[39mConspiracy Theory_pred\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m, na\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m mask_education \u001b[39m=\u001b[39m eng_tweets[\u001b[39m'\u001b[39m\u001b[39mEducation_pred\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m, na\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m mask_environment \u001b[39m=\u001b[39m eng_tweets[\u001b[39m'\u001b[39m\u001b[39mEnvironment_pred\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m, na\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/pandas/core/accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[0;32m--> 182\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor(obj)\n\u001b[1;32m    183\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/pandas/core/strings/accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(data)\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_categorical \u001b[39m=\u001b[39m is_categorical_dtype(data\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_string \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(data\u001b[39m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/media/bruno/0d2f61d2-2b9c-4043-9a46-8e4dfe74fc95/bruno/anaconda3/envs/my_env/lib/python3.11/site-packages/pandas/core/strings/accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    232\u001b[0m inferred_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39minfer_dtype(values, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m inferred_dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .str accessor with string values!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "mask_conspiracy = eng_tweets['Conspiracy Theory_pred'].str.contains('0', na=False)\n",
    "mask_education = eng_tweets['Education_pred'].str.contains('0', na=False)\n",
    "mask_environment = eng_tweets['Environment_pred'].str.contains('0', na=False)\n",
    "mask_labor = eng_tweets['Labor/Employment_pred'].str.contains('0', na=False)\n",
    "mask_religion = eng_tweets['Religion_pred'].str.contains('0', na=False)\n",
    "mask_science = eng_tweets['Science/Technology_pred'].str.contains('0', na=False)\n",
    "\n",
    "conspiracy_preds = eng_tweets[eng_tweets['Conspiracy Theory_pred'].str.contains('1', na=False)]\n",
    "print(\"Length Conspiracy Theory predictions: \", len(conspiracy_preds))\n",
    "\n",
    "only_conspiracy_predicted = eng_tweets[eng_tweets['Conspiracy Theory_pred'].str.contains('1', na=False) & mask_education & mask_environment & mask_labor & mask_religion & mask_science]\n",
    "print(\"Length Conspiracy Theory predictions with all other predictions being 0: \", len(only_conspiracy_predicted))\n",
    "\n",
    "education_preds = eng_tweets[eng_tweets['Education_pred'].str.contains('1', na=False)]\n",
    "print(\"Length Education predictions: \", len(education_preds))\n",
    "\n",
    "only_education_predicted = eng_tweets[eng_tweets['Education_pred'].str.contains('1', na=False) & mask_conspiracy & mask_environment & mask_labor & mask_religion & mask_science]\n",
    "print(\"Length Education predictions with all other predictions being 0: \", len(only_education_predicted))\n",
    "\n",
    "environment_preds = eng_tweets[eng_tweets['Environment_pred'].str.contains('1', na=False)]\n",
    "print(\"Length Environment predictions: \", len(environment_preds))\n",
    "\n",
    "only_environment_predicted = eng_tweets[eng_tweets['Environment_pred'].str.contains('1', na=False) & mask_conspiracy & mask_education & mask_labor & mask_religion & mask_science]\n",
    "print(\"Length Environment predictions with all other predictions being 0: \", len(only_environment_predicted))\n",
    "\n",
    "labor_preds = eng_tweets[eng_tweets['Labor/Employment_pred'].str.contains('1', na=False)]\n",
    "print(\"Length Labor/Employment predictions: \", len(labor_preds))\n",
    "\n",
    "only_labor_predicted = eng_tweets[eng_tweets['Labor/Employment_pred'].str.contains('1', na=False) & mask_conspiracy & mask_education & mask_environment & mask_religion & mask_science]\n",
    "print(\"Length Labor/Employment predictions with all other predictions being 0: \", len(only_labor_predicted))\n",
    "\n",
    "religion_pred = eng_tweets[eng_tweets['Religion_pred'].str.contains('1', na=False)]\n",
    "print(\"Length Religion predictions: \", len(religion_pred))\n",
    "\n",
    "only_religion_predicted = eng_tweets[eng_tweets['Religion_pred'].str.contains('1', na=False) & mask_conspiracy & mask_education & mask_environment & mask_labor & mask_science]\n",
    "print(\"Length Religion predictions with all other predictions being 0: \", len(only_religion_predicted))\n",
    "\n",
    "science_pred = eng_tweets[eng_tweets['Science/Technology_pred'].str.contains('1', na=False)]\n",
    "print(\"Length Science/Technology predictions: \", len(science_pred))\n",
    "\n",
    "only_science_predicted = eng_tweets[eng_tweets['Science/Technology_pred'].str.contains('1', na=False) & mask_conspiracy & mask_education & mask_environment & mask_labor & mask_religion]\n",
    "print(\"Length Science/Technology predictions: \", len(only_science_predicted))\n",
    "\n",
    "science_pred[[\"tweet_text\", \"Conspiracy Theory_pred\", \"Education_pred\", \"Environment_pred\", \"Labor/Employment_pred\", \"Religion_pred\", \"Science/Technology_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is it safe to take melatonin for jet lag? https://t.co/WKwC3auEA5 https://t.co/PLEaZ0J7xx'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_science_predicted.iloc[4].tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [8:49:57<00:00, 17.67s/it]  \n"
     ]
    }
   ],
   "source": [
    "LOW_F1_LABELS_COLUMNS = [i + \"_pred\" for i in LOW_F1_LABELS]\n",
    "start_index = find_start_index(eng_tweets, LOW_F1_LABELS_COLUMNS)\n",
    "print(\"Starting at index:\", start_index)\n",
    "for i in tqdm(range(start_index, 2000), total = 2000-start_index):\n",
    "    for label, rule_idx in zip(LOW_F1_LABELS, idx_of_rules_of_low_f1_labels):\n",
    "        try:\n",
    "            new_column_name = f'{label}_pred'\n",
    "            tweet_text = prompt_utils.normalize_tweet_simplified(eng_tweets.iloc[i]['tweet_text'])\n",
    "            #print(tweet_text)\n",
    "            prompt, followup, request_params = prompt_func(tweet_text, label, prompt_utils.RULES[rule_idx], prompt_utils.get_base_request_params())\n",
    "            \n",
    "            response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "            #response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "            #response = prompt_utils.get_response_wip(prompt, \"openai-davinci\", max_tokens = 400, openai_model = \"davinci\")\n",
    "            eng_tweets.loc[i, new_column_name] = response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error at index:\", i)\n",
    "            print(\"Label:\", label)\n",
    "            eng_tweets.loc[i, new_column_name] = \"ERROR\"\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)\n",
    "\n",
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eng_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eng_tweets\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00moutput_folder\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eng_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39387/1362994991.py:7: DtypeWarning: Columns (0,1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,22,23,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eng_tweets = pd.read_csv(f\"{output_folder}/{model_name}.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [9:26:01<00:00, 16.98s/it]  \n"
     ]
    }
   ],
   "source": [
    "output_folder = f\"{oa_base_path}/{oa_with_3_random_examples_classification_only_name}\"\n",
    "model_name = \"low_f1_labels_weak_labeling\"\n",
    "prompt_func = oa_with_3_random_examples_classification_only_func\n",
    "idx_of_rules_of_low_f1_labels = [1, 2, 4, 9, 12, 13]\n",
    "\n",
    "if os.path.isfile(f\"{output_folder}/{model_name}.csv\"):\n",
    "    eng_tweets = pd.read_csv(f\"{output_folder}/{model_name}.csv\")\n",
    "else:\n",
    "    eng_tweets = initialize_eng_dataframe()\n",
    "    eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)\n",
    "\n",
    "df_train = dfs[0]\n",
    "\n",
    "LOW_F1_LABELS_COLUMNS = [i + \"_pred\" for i in LOW_F1_LABELS]\n",
    "start_index = find_start_index(eng_tweets, LOW_F1_LABELS_COLUMNS)\n",
    "print(\"Starting at index:\", start_index)\n",
    "for i in tqdm(range(start_index, 2000), total = 2000-start_index):\n",
    "    for label, rule_idx in zip(LOW_F1_LABELS, idx_of_rules_of_low_f1_labels):\n",
    "        try:\n",
    "            new_column_name = f'{label}_pred'\n",
    "            tweet_text = eng_tweets.iloc[i]['tweet_text']\n",
    "            example_tweets = prompt_utils.get_random_examples(df_train, label, tweet_text, 3)\n",
    "            tweet_text = prompt_utils.normalize_tweet_simplified(tweet_text)\n",
    "            #print(tweet_text)\n",
    "            prompt, followup, request_params = prompt_func(tweet_text, label, example_tweets, prompt_utils.get_base_request_params())\n",
    "            \n",
    "            response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "            #response = prompt_utils.get_response(request_params, prompt, \"\")\n",
    "            #response = prompt_utils.get_response_wip(prompt, \"openai-davinci\", max_tokens = 400, openai_model = \"davinci\")\n",
    "            eng_tweets.loc[i, new_column_name] = response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error at index:\", i)\n",
    "            print(\"Label:\", label)\n",
    "            eng_tweets.loc[i, new_column_name] = \"ERROR\"\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)\n",
    "\n",
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tweets.to_csv(f\"{output_folder}/{model_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
